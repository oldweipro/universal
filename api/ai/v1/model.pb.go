// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.8
// 	protoc        v6.32.0
// source: api/ai/v1/model.proto

package v1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// 模型提供商信息
type Provider struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	Id             int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                                                                                                                        // 提供商ID
	Name           string                 `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`                                                                                                                     // 提供商名称 (openai/anthropic/local/etc)
	DisplayName    string                 `protobuf:"bytes,3,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`                                                                                    // 显示名称
	Description    string                 `protobuf:"bytes,4,opt,name=description,proto3" json:"description,omitempty"`                                                                                                       // 提供商描述
	ApiBaseUrl     string                 `protobuf:"bytes,5,opt,name=api_base_url,json=apiBaseUrl,proto3" json:"api_base_url,omitempty"`                                                                                     // API基础URL
	DefaultApiKey  string                 `protobuf:"bytes,6,opt,name=default_api_key,json=defaultApiKey,proto3" json:"default_api_key,omitempty"`                                                                            // 默认API密钥
	DefaultHeaders map[string]string      `protobuf:"bytes,7,rep,name=default_headers,json=defaultHeaders,proto3" json:"default_headers,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 默认请求头
	Config         map[string]string      `protobuf:"bytes,8,rep,name=config,proto3" json:"config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`                                       // 提供商特定配置
	Status         int32                  `protobuf:"varint,9,opt,name=status,proto3" json:"status,omitempty"`                                                                                                                // 状态 (0:启用, 1:禁用, 2:维护中)
	CreatedAt      *timestamppb.Timestamp `protobuf:"bytes,10,opt,name=created_at,json=createdAt,proto3" json:"created_at,omitempty"`                                                                                         // 创建时间
	UpdatedAt      *timestamppb.Timestamp `protobuf:"bytes,11,opt,name=updated_at,json=updatedAt,proto3" json:"updated_at,omitempty"`                                                                                         // 更新时间
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *Provider) Reset() {
	*x = Provider{}
	mi := &file_api_ai_v1_model_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Provider) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Provider) ProtoMessage() {}

func (x *Provider) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Provider.ProtoReflect.Descriptor instead.
func (*Provider) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{0}
}

func (x *Provider) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *Provider) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Provider) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *Provider) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Provider) GetApiBaseUrl() string {
	if x != nil {
		return x.ApiBaseUrl
	}
	return ""
}

func (x *Provider) GetDefaultApiKey() string {
	if x != nil {
		return x.DefaultApiKey
	}
	return ""
}

func (x *Provider) GetDefaultHeaders() map[string]string {
	if x != nil {
		return x.DefaultHeaders
	}
	return nil
}

func (x *Provider) GetConfig() map[string]string {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *Provider) GetStatus() int32 {
	if x != nil {
		return x.Status
	}
	return 0
}

func (x *Provider) GetCreatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.CreatedAt
	}
	return nil
}

func (x *Provider) GetUpdatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdatedAt
	}
	return nil
}

// AI模型信息
type ModelInfo struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                                                                                                                      // 模型ID
	ProviderId    int64                  `protobuf:"varint,2,opt,name=provider_id,json=providerId,proto3" json:"provider_id,omitempty"`                                                                                    // 提供商ID
	Name          string                 `protobuf:"bytes,3,opt,name=name,proto3" json:"name,omitempty"`                                                                                                                   // 模型名称
	DisplayName   string                 `protobuf:"bytes,4,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`                                                                                  // 显示名称
	Description   string                 `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`                                                                                                     // 模型描述
	Version       string                 `protobuf:"bytes,6,opt,name=version,proto3" json:"version,omitempty"`                                                                                                             // 模型版本
	Capabilities  *ModelCapabilities     `protobuf:"bytes,7,opt,name=capabilities,proto3" json:"capabilities,omitempty"`                                                                                                   // 模型能力
	Limits        *ModelLimits           `protobuf:"bytes,8,opt,name=limits,proto3" json:"limits,omitempty"`                                                                                                               // 模型限制
	Pricing       *ModelPricing          `protobuf:"bytes,9,opt,name=pricing,proto3" json:"pricing,omitempty"`                                                                                                             // 定价信息
	DefaultParams map[string]string      `protobuf:"bytes,10,rep,name=default_params,json=defaultParams,proto3" json:"default_params,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 默认参数
	Status        int32                  `protobuf:"varint,11,opt,name=status,proto3" json:"status,omitempty"`                                                                                                             // 状态 (0:可用, 1:不可用, 2:维护中)
	CreatedAt     *timestamppb.Timestamp `protobuf:"bytes,12,opt,name=created_at,json=createdAt,proto3" json:"created_at,omitempty"`                                                                                       // 创建时间
	UpdatedAt     *timestamppb.Timestamp `protobuf:"bytes,13,opt,name=updated_at,json=updatedAt,proto3" json:"updated_at,omitempty"`                                                                                       // 更新时间
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelInfo) Reset() {
	*x = ModelInfo{}
	mi := &file_api_ai_v1_model_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelInfo) ProtoMessage() {}

func (x *ModelInfo) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelInfo.ProtoReflect.Descriptor instead.
func (*ModelInfo) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{1}
}

func (x *ModelInfo) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *ModelInfo) GetProviderId() int64 {
	if x != nil {
		return x.ProviderId
	}
	return 0
}

func (x *ModelInfo) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ModelInfo) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *ModelInfo) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *ModelInfo) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *ModelInfo) GetCapabilities() *ModelCapabilities {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *ModelInfo) GetLimits() *ModelLimits {
	if x != nil {
		return x.Limits
	}
	return nil
}

func (x *ModelInfo) GetPricing() *ModelPricing {
	if x != nil {
		return x.Pricing
	}
	return nil
}

func (x *ModelInfo) GetDefaultParams() map[string]string {
	if x != nil {
		return x.DefaultParams
	}
	return nil
}

func (x *ModelInfo) GetStatus() int32 {
	if x != nil {
		return x.Status
	}
	return 0
}

func (x *ModelInfo) GetCreatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.CreatedAt
	}
	return nil
}

func (x *ModelInfo) GetUpdatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdatedAt
	}
	return nil
}

// 模型能力
type ModelCapabilities struct {
	state              protoimpl.MessageState `protogen:"open.v1"`
	SupportsChat       bool                   `protobuf:"varint,1,opt,name=supports_chat,json=supportsChat,proto3" json:"supports_chat,omitempty"`                   // 支持对话
	SupportsCompletion bool                   `protobuf:"varint,2,opt,name=supports_completion,json=supportsCompletion,proto3" json:"supports_completion,omitempty"` // 支持文本补全
	SupportsEmbedding  bool                   `protobuf:"varint,3,opt,name=supports_embedding,json=supportsEmbedding,proto3" json:"supports_embedding,omitempty"`    // 支持向量化
	SupportsTools      bool                   `protobuf:"varint,4,opt,name=supports_tools,json=supportsTools,proto3" json:"supports_tools,omitempty"`                // 支持工具调用
	SupportsVision     bool                   `protobuf:"varint,5,opt,name=supports_vision,json=supportsVision,proto3" json:"supports_vision,omitempty"`             // 支持图像输入
	SupportsAudio      bool                   `protobuf:"varint,6,opt,name=supports_audio,json=supportsAudio,proto3" json:"supports_audio,omitempty"`                // 支持音频输入
	SupportsStreaming  bool                   `protobuf:"varint,7,opt,name=supports_streaming,json=supportsStreaming,proto3" json:"supports_streaming,omitempty"`    // 支持流式输出
	SupportedFormats   []string               `protobuf:"bytes,8,rep,name=supported_formats,json=supportedFormats,proto3" json:"supported_formats,omitempty"`        // 支持的输入格式
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *ModelCapabilities) Reset() {
	*x = ModelCapabilities{}
	mi := &file_api_ai_v1_model_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelCapabilities) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelCapabilities) ProtoMessage() {}

func (x *ModelCapabilities) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelCapabilities.ProtoReflect.Descriptor instead.
func (*ModelCapabilities) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{2}
}

func (x *ModelCapabilities) GetSupportsChat() bool {
	if x != nil {
		return x.SupportsChat
	}
	return false
}

func (x *ModelCapabilities) GetSupportsCompletion() bool {
	if x != nil {
		return x.SupportsCompletion
	}
	return false
}

func (x *ModelCapabilities) GetSupportsEmbedding() bool {
	if x != nil {
		return x.SupportsEmbedding
	}
	return false
}

func (x *ModelCapabilities) GetSupportsTools() bool {
	if x != nil {
		return x.SupportsTools
	}
	return false
}

func (x *ModelCapabilities) GetSupportsVision() bool {
	if x != nil {
		return x.SupportsVision
	}
	return false
}

func (x *ModelCapabilities) GetSupportsAudio() bool {
	if x != nil {
		return x.SupportsAudio
	}
	return false
}

func (x *ModelCapabilities) GetSupportsStreaming() bool {
	if x != nil {
		return x.SupportsStreaming
	}
	return false
}

func (x *ModelCapabilities) GetSupportedFormats() []string {
	if x != nil {
		return x.SupportedFormats
	}
	return nil
}

// 模型限制
type ModelLimits struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	MaxTokens            int32                  `protobuf:"varint,1,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`                                      // 最大token数
	MaxInputTokens       int32                  `protobuf:"varint,2,opt,name=max_input_tokens,json=maxInputTokens,proto3" json:"max_input_tokens,omitempty"`                     // 最大输入token数
	MaxOutputTokens      int32                  `protobuf:"varint,3,opt,name=max_output_tokens,json=maxOutputTokens,proto3" json:"max_output_tokens,omitempty"`                  // 最大输出token数
	ContextWindow        int32                  `protobuf:"varint,4,opt,name=context_window,json=contextWindow,proto3" json:"context_window,omitempty"`                          // 上下文窗口大小
	MaxTemperature       float64                `protobuf:"fixed64,5,opt,name=max_temperature,json=maxTemperature,proto3" json:"max_temperature,omitempty"`                      // 最大温度值
	MinTemperature       float64                `protobuf:"fixed64,6,opt,name=min_temperature,json=minTemperature,proto3" json:"min_temperature,omitempty"`                      // 最小温度值
	MaxRequestsPerMinute int32                  `protobuf:"varint,7,opt,name=max_requests_per_minute,json=maxRequestsPerMinute,proto3" json:"max_requests_per_minute,omitempty"` // 每分钟最大请求数
	MaxTokensPerMinute   int32                  `protobuf:"varint,8,opt,name=max_tokens_per_minute,json=maxTokensPerMinute,proto3" json:"max_tokens_per_minute,omitempty"`       // 每分钟最大token数
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *ModelLimits) Reset() {
	*x = ModelLimits{}
	mi := &file_api_ai_v1_model_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelLimits) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelLimits) ProtoMessage() {}

func (x *ModelLimits) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelLimits.ProtoReflect.Descriptor instead.
func (*ModelLimits) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{3}
}

func (x *ModelLimits) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *ModelLimits) GetMaxInputTokens() int32 {
	if x != nil {
		return x.MaxInputTokens
	}
	return 0
}

func (x *ModelLimits) GetMaxOutputTokens() int32 {
	if x != nil {
		return x.MaxOutputTokens
	}
	return 0
}

func (x *ModelLimits) GetContextWindow() int32 {
	if x != nil {
		return x.ContextWindow
	}
	return 0
}

func (x *ModelLimits) GetMaxTemperature() float64 {
	if x != nil {
		return x.MaxTemperature
	}
	return 0
}

func (x *ModelLimits) GetMinTemperature() float64 {
	if x != nil {
		return x.MinTemperature
	}
	return 0
}

func (x *ModelLimits) GetMaxRequestsPerMinute() int32 {
	if x != nil {
		return x.MaxRequestsPerMinute
	}
	return 0
}

func (x *ModelLimits) GetMaxTokensPerMinute() int32 {
	if x != nil {
		return x.MaxTokensPerMinute
	}
	return 0
}

// 定价信息
type ModelPricing struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	InputPricePerToken  float64                `protobuf:"fixed64,1,opt,name=input_price_per_token,json=inputPricePerToken,proto3" json:"input_price_per_token,omitempty"`    // 输入token单价
	OutputPricePerToken float64                `protobuf:"fixed64,2,opt,name=output_price_per_token,json=outputPricePerToken,proto3" json:"output_price_per_token,omitempty"` // 输出token单价
	Currency            string                 `protobuf:"bytes,3,opt,name=currency,proto3" json:"currency,omitempty"`                                                        // 货币单位
	BatchDiscount       float64                `protobuf:"fixed64,4,opt,name=batch_discount,json=batchDiscount,proto3" json:"batch_discount,omitempty"`                       // 批量折扣
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *ModelPricing) Reset() {
	*x = ModelPricing{}
	mi := &file_api_ai_v1_model_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelPricing) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelPricing) ProtoMessage() {}

func (x *ModelPricing) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelPricing.ProtoReflect.Descriptor instead.
func (*ModelPricing) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{4}
}

func (x *ModelPricing) GetInputPricePerToken() float64 {
	if x != nil {
		return x.InputPricePerToken
	}
	return 0
}

func (x *ModelPricing) GetOutputPricePerToken() float64 {
	if x != nil {
		return x.OutputPricePerToken
	}
	return 0
}

func (x *ModelPricing) GetCurrency() string {
	if x != nil {
		return x.Currency
	}
	return ""
}

func (x *ModelPricing) GetBatchDiscount() float64 {
	if x != nil {
		return x.BatchDiscount
	}
	return 0
}

// 用户配额信息
type UserQuota struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	UserId              int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                           // 用户ID
	ModelId             int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                                        // 模型ID
	DailyTokenLimit     int64                  `protobuf:"varint,3,opt,name=daily_token_limit,json=dailyTokenLimit,proto3" json:"daily_token_limit,omitempty"`              // 每日token限制
	MonthlyTokenLimit   int64                  `protobuf:"varint,4,opt,name=monthly_token_limit,json=monthlyTokenLimit,proto3" json:"monthly_token_limit,omitempty"`        // 每月token限制
	DailyRequestLimit   int64                  `protobuf:"varint,5,opt,name=daily_request_limit,json=dailyRequestLimit,proto3" json:"daily_request_limit,omitempty"`        // 每日请求限制
	MonthlyRequestLimit int64                  `protobuf:"varint,6,opt,name=monthly_request_limit,json=monthlyRequestLimit,proto3" json:"monthly_request_limit,omitempty"`  // 每月请求限制
	DailyTokensUsed     int64                  `protobuf:"varint,7,opt,name=daily_tokens_used,json=dailyTokensUsed,proto3" json:"daily_tokens_used,omitempty"`              // 今日已用token
	MonthlyTokensUsed   int64                  `protobuf:"varint,8,opt,name=monthly_tokens_used,json=monthlyTokensUsed,proto3" json:"monthly_tokens_used,omitempty"`        // 本月已用token
	DailyRequestsUsed   int64                  `protobuf:"varint,9,opt,name=daily_requests_used,json=dailyRequestsUsed,proto3" json:"daily_requests_used,omitempty"`        // 今日已用请求
	MonthlyRequestsUsed int64                  `protobuf:"varint,10,opt,name=monthly_requests_used,json=monthlyRequestsUsed,proto3" json:"monthly_requests_used,omitempty"` // 本月已用请求
	ResetDailyAt        *timestamppb.Timestamp `protobuf:"bytes,11,opt,name=reset_daily_at,json=resetDailyAt,proto3" json:"reset_daily_at,omitempty"`                       // 每日重置时间
	ResetMonthlyAt      *timestamppb.Timestamp `protobuf:"bytes,12,opt,name=reset_monthly_at,json=resetMonthlyAt,proto3" json:"reset_monthly_at,omitempty"`                 // 每月重置时间
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *UserQuota) Reset() {
	*x = UserQuota{}
	mi := &file_api_ai_v1_model_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UserQuota) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UserQuota) ProtoMessage() {}

func (x *UserQuota) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UserQuota.ProtoReflect.Descriptor instead.
func (*UserQuota) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{5}
}

func (x *UserQuota) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *UserQuota) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *UserQuota) GetDailyTokenLimit() int64 {
	if x != nil {
		return x.DailyTokenLimit
	}
	return 0
}

func (x *UserQuota) GetMonthlyTokenLimit() int64 {
	if x != nil {
		return x.MonthlyTokenLimit
	}
	return 0
}

func (x *UserQuota) GetDailyRequestLimit() int64 {
	if x != nil {
		return x.DailyRequestLimit
	}
	return 0
}

func (x *UserQuota) GetMonthlyRequestLimit() int64 {
	if x != nil {
		return x.MonthlyRequestLimit
	}
	return 0
}

func (x *UserQuota) GetDailyTokensUsed() int64 {
	if x != nil {
		return x.DailyTokensUsed
	}
	return 0
}

func (x *UserQuota) GetMonthlyTokensUsed() int64 {
	if x != nil {
		return x.MonthlyTokensUsed
	}
	return 0
}

func (x *UserQuota) GetDailyRequestsUsed() int64 {
	if x != nil {
		return x.DailyRequestsUsed
	}
	return 0
}

func (x *UserQuota) GetMonthlyRequestsUsed() int64 {
	if x != nil {
		return x.MonthlyRequestsUsed
	}
	return 0
}

func (x *UserQuota) GetResetDailyAt() *timestamppb.Timestamp {
	if x != nil {
		return x.ResetDailyAt
	}
	return nil
}

func (x *UserQuota) GetResetMonthlyAt() *timestamppb.Timestamp {
	if x != nil {
		return x.ResetMonthlyAt
	}
	return nil
}

// 使用统计
type UsageStats struct {
	state              protoimpl.MessageState `protogen:"open.v1"`
	UserId             int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                     // 用户ID
	ModelId            int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                                  // 模型ID
	Date               string                 `protobuf:"bytes,3,opt,name=date,proto3" json:"date,omitempty"`                                                        // 统计日期
	TotalRequests      int64                  `protobuf:"varint,4,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"`                // 总请求数
	SuccessfulRequests int64                  `protobuf:"varint,5,opt,name=successful_requests,json=successfulRequests,proto3" json:"successful_requests,omitempty"` // 成功请求数
	FailedRequests     int64                  `protobuf:"varint,6,opt,name=failed_requests,json=failedRequests,proto3" json:"failed_requests,omitempty"`             // 失败请求数
	TotalTokens        int64                  `protobuf:"varint,7,opt,name=total_tokens,json=totalTokens,proto3" json:"total_tokens,omitempty"`                      // 总token数
	InputTokens        int64                  `protobuf:"varint,8,opt,name=input_tokens,json=inputTokens,proto3" json:"input_tokens,omitempty"`                      // 输入token数
	OutputTokens       int64                  `protobuf:"varint,9,opt,name=output_tokens,json=outputTokens,proto3" json:"output_tokens,omitempty"`                   // 输出token数
	TotalCost          float64                `protobuf:"fixed64,10,opt,name=total_cost,json=totalCost,proto3" json:"total_cost,omitempty"`                          // 总成本
	AvgResponseTime    float64                `protobuf:"fixed64,11,opt,name=avg_response_time,json=avgResponseTime,proto3" json:"avg_response_time,omitempty"`      // 平均响应时间(毫秒)
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *UsageStats) Reset() {
	*x = UsageStats{}
	mi := &file_api_ai_v1_model_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UsageStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UsageStats) ProtoMessage() {}

func (x *UsageStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UsageStats.ProtoReflect.Descriptor instead.
func (*UsageStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{6}
}

func (x *UsageStats) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *UsageStats) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *UsageStats) GetDate() string {
	if x != nil {
		return x.Date
	}
	return ""
}

func (x *UsageStats) GetTotalRequests() int64 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *UsageStats) GetSuccessfulRequests() int64 {
	if x != nil {
		return x.SuccessfulRequests
	}
	return 0
}

func (x *UsageStats) GetFailedRequests() int64 {
	if x != nil {
		return x.FailedRequests
	}
	return 0
}

func (x *UsageStats) GetTotalTokens() int64 {
	if x != nil {
		return x.TotalTokens
	}
	return 0
}

func (x *UsageStats) GetInputTokens() int64 {
	if x != nil {
		return x.InputTokens
	}
	return 0
}

func (x *UsageStats) GetOutputTokens() int64 {
	if x != nil {
		return x.OutputTokens
	}
	return 0
}

func (x *UsageStats) GetTotalCost() float64 {
	if x != nil {
		return x.TotalCost
	}
	return 0
}

func (x *UsageStats) GetAvgResponseTime() float64 {
	if x != nil {
		return x.AvgResponseTime
	}
	return 0
}

// 限流配置
type RateLimitConfig struct {
	state              protoimpl.MessageState `protogen:"open.v1"`
	Id                 int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                                                           // 配置ID
	ModelId            int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                                  // 模型ID
	UserLevel          string                 `protobuf:"bytes,3,opt,name=user_level,json=userLevel,proto3" json:"user_level,omitempty"`                             // 用户等级 (free/pro/enterprise)
	RequestsPerMinute  int32                  `protobuf:"varint,4,opt,name=requests_per_minute,json=requestsPerMinute,proto3" json:"requests_per_minute,omitempty"`  // 每分钟请求限制
	RequestsPerHour    int32                  `protobuf:"varint,5,opt,name=requests_per_hour,json=requestsPerHour,proto3" json:"requests_per_hour,omitempty"`        // 每小时请求限制
	RequestsPerDay     int32                  `protobuf:"varint,6,opt,name=requests_per_day,json=requestsPerDay,proto3" json:"requests_per_day,omitempty"`           // 每天请求限制
	TokensPerMinute    int32                  `protobuf:"varint,7,opt,name=tokens_per_minute,json=tokensPerMinute,proto3" json:"tokens_per_minute,omitempty"`        // 每分钟token限制
	ConcurrentRequests int32                  `protobuf:"varint,8,opt,name=concurrent_requests,json=concurrentRequests,proto3" json:"concurrent_requests,omitempty"` // 并发请求限制
	BurstLimit         int32                  `protobuf:"varint,9,opt,name=burst_limit,json=burstLimit,proto3" json:"burst_limit,omitempty"`                         // 突发请求限制
	CreatedAt          *timestamppb.Timestamp `protobuf:"bytes,10,opt,name=created_at,json=createdAt,proto3" json:"created_at,omitempty"`                            // 创建时间
	UpdatedAt          *timestamppb.Timestamp `protobuf:"bytes,11,opt,name=updated_at,json=updatedAt,proto3" json:"updated_at,omitempty"`                            // 更新时间
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *RateLimitConfig) Reset() {
	*x = RateLimitConfig{}
	mi := &file_api_ai_v1_model_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RateLimitConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RateLimitConfig) ProtoMessage() {}

func (x *RateLimitConfig) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RateLimitConfig.ProtoReflect.Descriptor instead.
func (*RateLimitConfig) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{7}
}

func (x *RateLimitConfig) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *RateLimitConfig) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *RateLimitConfig) GetUserLevel() string {
	if x != nil {
		return x.UserLevel
	}
	return ""
}

func (x *RateLimitConfig) GetRequestsPerMinute() int32 {
	if x != nil {
		return x.RequestsPerMinute
	}
	return 0
}

func (x *RateLimitConfig) GetRequestsPerHour() int32 {
	if x != nil {
		return x.RequestsPerHour
	}
	return 0
}

func (x *RateLimitConfig) GetRequestsPerDay() int32 {
	if x != nil {
		return x.RequestsPerDay
	}
	return 0
}

func (x *RateLimitConfig) GetTokensPerMinute() int32 {
	if x != nil {
		return x.TokensPerMinute
	}
	return 0
}

func (x *RateLimitConfig) GetConcurrentRequests() int32 {
	if x != nil {
		return x.ConcurrentRequests
	}
	return 0
}

func (x *RateLimitConfig) GetBurstLimit() int32 {
	if x != nil {
		return x.BurstLimit
	}
	return 0
}

func (x *RateLimitConfig) GetCreatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.CreatedAt
	}
	return nil
}

func (x *RateLimitConfig) GetUpdatedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdatedAt
	}
	return nil
}

// 模型健康状态
type ModelHealth struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	ModelId        int64                  `protobuf:"varint,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                      // 模型ID
	IsHealthy      bool                   `protobuf:"varint,2,opt,name=is_healthy,json=isHealthy,proto3" json:"is_healthy,omitempty"`                // 是否健康
	ResponseTime   float64                `protobuf:"fixed64,3,opt,name=response_time,json=responseTime,proto3" json:"response_time,omitempty"`      // 响应时间(毫秒)
	SuccessRate    float64                `protobuf:"fixed64,4,opt,name=success_rate,json=successRate,proto3" json:"success_rate,omitempty"`         // 成功率(0-1)
	TotalRequests  int64                  `protobuf:"varint,5,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"`    // 总请求数
	FailedRequests int64                  `protobuf:"varint,6,opt,name=failed_requests,json=failedRequests,proto3" json:"failed_requests,omitempty"` // 失败请求数
	ErrorMessage   string                 `protobuf:"bytes,7,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`        // 错误信息
	LastCheck      *timestamppb.Timestamp `protobuf:"bytes,8,opt,name=last_check,json=lastCheck,proto3" json:"last_check,omitempty"`                 // 最后检查时间
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ModelHealth) Reset() {
	*x = ModelHealth{}
	mi := &file_api_ai_v1_model_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelHealth) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelHealth) ProtoMessage() {}

func (x *ModelHealth) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelHealth.ProtoReflect.Descriptor instead.
func (*ModelHealth) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{8}
}

func (x *ModelHealth) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *ModelHealth) GetIsHealthy() bool {
	if x != nil {
		return x.IsHealthy
	}
	return false
}

func (x *ModelHealth) GetResponseTime() float64 {
	if x != nil {
		return x.ResponseTime
	}
	return 0
}

func (x *ModelHealth) GetSuccessRate() float64 {
	if x != nil {
		return x.SuccessRate
	}
	return 0
}

func (x *ModelHealth) GetTotalRequests() int64 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *ModelHealth) GetFailedRequests() int64 {
	if x != nil {
		return x.FailedRequests
	}
	return 0
}

func (x *ModelHealth) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

func (x *ModelHealth) GetLastCheck() *timestamppb.Timestamp {
	if x != nil {
		return x.LastCheck
	}
	return nil
}

// 创建提供商
type CreateProviderRequest struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	Name           string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`                                                                                                                     // 提供商名称
	DisplayName    string                 `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`                                                                                    // 显示名称
	Description    string                 `protobuf:"bytes,3,opt,name=description,proto3" json:"description,omitempty"`                                                                                                       // 描述
	ApiBaseUrl     string                 `protobuf:"bytes,4,opt,name=api_base_url,json=apiBaseUrl,proto3" json:"api_base_url,omitempty"`                                                                                     // API基础URL
	DefaultApiKey  string                 `protobuf:"bytes,5,opt,name=default_api_key,json=defaultApiKey,proto3" json:"default_api_key,omitempty"`                                                                            // 默认API密钥
	DefaultHeaders map[string]string      `protobuf:"bytes,6,rep,name=default_headers,json=defaultHeaders,proto3" json:"default_headers,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 默认请求头
	Config         map[string]string      `protobuf:"bytes,7,rep,name=config,proto3" json:"config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`                                       // 配置参数
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *CreateProviderRequest) Reset() {
	*x = CreateProviderRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CreateProviderRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateProviderRequest) ProtoMessage() {}

func (x *CreateProviderRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateProviderRequest.ProtoReflect.Descriptor instead.
func (*CreateProviderRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{9}
}

func (x *CreateProviderRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *CreateProviderRequest) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *CreateProviderRequest) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *CreateProviderRequest) GetApiBaseUrl() string {
	if x != nil {
		return x.ApiBaseUrl
	}
	return ""
}

func (x *CreateProviderRequest) GetDefaultApiKey() string {
	if x != nil {
		return x.DefaultApiKey
	}
	return ""
}

func (x *CreateProviderRequest) GetDefaultHeaders() map[string]string {
	if x != nil {
		return x.DefaultHeaders
	}
	return nil
}

func (x *CreateProviderRequest) GetConfig() map[string]string {
	if x != nil {
		return x.Config
	}
	return nil
}

type CreateProviderReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Provider      *Provider              `protobuf:"bytes,1,opt,name=provider,proto3" json:"provider,omitempty"` // 创建的提供商
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CreateProviderReply) Reset() {
	*x = CreateProviderReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CreateProviderReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateProviderReply) ProtoMessage() {}

func (x *CreateProviderReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateProviderReply.ProtoReflect.Descriptor instead.
func (*CreateProviderReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{10}
}

func (x *CreateProviderReply) GetProvider() *Provider {
	if x != nil {
		return x.Provider
	}
	return nil
}

// 更新提供商
type UpdateProviderRequest struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	Id             int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                                                                                                                        // 提供商ID
	DisplayName    string                 `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`                                                                                    // 显示名称
	Description    string                 `protobuf:"bytes,3,opt,name=description,proto3" json:"description,omitempty"`                                                                                                       // 描述
	ApiBaseUrl     string                 `protobuf:"bytes,4,opt,name=api_base_url,json=apiBaseUrl,proto3" json:"api_base_url,omitempty"`                                                                                     // API基础URL
	DefaultApiKey  string                 `protobuf:"bytes,5,opt,name=default_api_key,json=defaultApiKey,proto3" json:"default_api_key,omitempty"`                                                                            // 默认API密钥
	DefaultHeaders map[string]string      `protobuf:"bytes,6,rep,name=default_headers,json=defaultHeaders,proto3" json:"default_headers,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 默认请求头
	Config         map[string]string      `protobuf:"bytes,7,rep,name=config,proto3" json:"config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`                                       // 配置参数
	Status         int32                  `protobuf:"varint,8,opt,name=status,proto3" json:"status,omitempty"`                                                                                                                // 状态
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *UpdateProviderRequest) Reset() {
	*x = UpdateProviderRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateProviderRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateProviderRequest) ProtoMessage() {}

func (x *UpdateProviderRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateProviderRequest.ProtoReflect.Descriptor instead.
func (*UpdateProviderRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{11}
}

func (x *UpdateProviderRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *UpdateProviderRequest) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *UpdateProviderRequest) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *UpdateProviderRequest) GetApiBaseUrl() string {
	if x != nil {
		return x.ApiBaseUrl
	}
	return ""
}

func (x *UpdateProviderRequest) GetDefaultApiKey() string {
	if x != nil {
		return x.DefaultApiKey
	}
	return ""
}

func (x *UpdateProviderRequest) GetDefaultHeaders() map[string]string {
	if x != nil {
		return x.DefaultHeaders
	}
	return nil
}

func (x *UpdateProviderRequest) GetConfig() map[string]string {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *UpdateProviderRequest) GetStatus() int32 {
	if x != nil {
		return x.Status
	}
	return 0
}

type UpdateProviderReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Provider      *Provider              `protobuf:"bytes,1,opt,name=provider,proto3" json:"provider,omitempty"` // 更新后的提供商
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpdateProviderReply) Reset() {
	*x = UpdateProviderReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateProviderReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateProviderReply) ProtoMessage() {}

func (x *UpdateProviderReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateProviderReply.ProtoReflect.Descriptor instead.
func (*UpdateProviderReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{12}
}

func (x *UpdateProviderReply) GetProvider() *Provider {
	if x != nil {
		return x.Provider
	}
	return nil
}

// 删除提供商
type DeleteProviderRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"` // 提供商ID
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteProviderRequest) Reset() {
	*x = DeleteProviderRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteProviderRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteProviderRequest) ProtoMessage() {}

func (x *DeleteProviderRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteProviderRequest.ProtoReflect.Descriptor instead.
func (*DeleteProviderRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{13}
}

func (x *DeleteProviderRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

type DeleteProviderReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteProviderReply) Reset() {
	*x = DeleteProviderReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteProviderReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteProviderReply) ProtoMessage() {}

func (x *DeleteProviderReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteProviderReply.ProtoReflect.Descriptor instead.
func (*DeleteProviderReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{14}
}

// 列出提供商
type ListProvidersRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        int32                  `protobuf:"varint,1,opt,name=status,proto3" json:"status,omitempty"`                     // 状态过滤(-1:全部, 0:启用, 1:禁用)
	Page          int32                  `protobuf:"varint,2,opt,name=page,proto3" json:"page,omitempty"`                         // 页码
	PageSize      int32                  `protobuf:"varint,3,opt,name=page_size,json=pageSize,proto3" json:"page_size,omitempty"` // 页面大小
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListProvidersRequest) Reset() {
	*x = ListProvidersRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListProvidersRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListProvidersRequest) ProtoMessage() {}

func (x *ListProvidersRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListProvidersRequest.ProtoReflect.Descriptor instead.
func (*ListProvidersRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{15}
}

func (x *ListProvidersRequest) GetStatus() int32 {
	if x != nil {
		return x.Status
	}
	return 0
}

func (x *ListProvidersRequest) GetPage() int32 {
	if x != nil {
		return x.Page
	}
	return 0
}

func (x *ListProvidersRequest) GetPageSize() int32 {
	if x != nil {
		return x.PageSize
	}
	return 0
}

type ListProvidersReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Providers     []*Provider            `protobuf:"bytes,1,rep,name=providers,proto3" json:"providers,omitempty"` // 提供商列表
	Total         int64                  `protobuf:"varint,2,opt,name=total,proto3" json:"total,omitempty"`        // 总数
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListProvidersReply) Reset() {
	*x = ListProvidersReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListProvidersReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListProvidersReply) ProtoMessage() {}

func (x *ListProvidersReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListProvidersReply.ProtoReflect.Descriptor instead.
func (*ListProvidersReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{16}
}

func (x *ListProvidersReply) GetProviders() []*Provider {
	if x != nil {
		return x.Providers
	}
	return nil
}

func (x *ListProvidersReply) GetTotal() int64 {
	if x != nil {
		return x.Total
	}
	return 0
}

// 测试提供商
type TestProviderRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                      // 提供商ID
	ApiKey        string                 `protobuf:"bytes,2,opt,name=api_key,json=apiKey,proto3" json:"api_key,omitempty"` // 测试用API密钥(可选)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TestProviderRequest) Reset() {
	*x = TestProviderRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TestProviderRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TestProviderRequest) ProtoMessage() {}

func (x *TestProviderRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TestProviderRequest.ProtoReflect.Descriptor instead.
func (*TestProviderRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{17}
}

func (x *TestProviderRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *TestProviderRequest) GetApiKey() string {
	if x != nil {
		return x.ApiKey
	}
	return ""
}

type TestProviderReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	IsAvailable   bool                   `protobuf:"varint,1,opt,name=is_available,json=isAvailable,proto3" json:"is_available,omitempty"`     // 是否可用
	ResponseTime  float64                `protobuf:"fixed64,2,opt,name=response_time,json=responseTime,proto3" json:"response_time,omitempty"` // 响应时间(毫秒)
	ErrorMessage  string                 `protobuf:"bytes,3,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`   // 错误信息
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TestProviderReply) Reset() {
	*x = TestProviderReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TestProviderReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TestProviderReply) ProtoMessage() {}

func (x *TestProviderReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TestProviderReply.ProtoReflect.Descriptor instead.
func (*TestProviderReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{18}
}

func (x *TestProviderReply) GetIsAvailable() bool {
	if x != nil {
		return x.IsAvailable
	}
	return false
}

func (x *TestProviderReply) GetResponseTime() float64 {
	if x != nil {
		return x.ResponseTime
	}
	return 0
}

func (x *TestProviderReply) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

// 创建模型
type CreateModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ProviderId    int64                  `protobuf:"varint,1,opt,name=provider_id,json=providerId,proto3" json:"provider_id,omitempty"`                                                                                   // 提供商ID
	Name          string                 `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`                                                                                                                  // 模型名称
	DisplayName   string                 `protobuf:"bytes,3,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`                                                                                 // 显示名称
	Description   string                 `protobuf:"bytes,4,opt,name=description,proto3" json:"description,omitempty"`                                                                                                    // 描述
	Version       string                 `protobuf:"bytes,5,opt,name=version,proto3" json:"version,omitempty"`                                                                                                            // 版本
	Capabilities  *ModelCapabilities     `protobuf:"bytes,6,opt,name=capabilities,proto3" json:"capabilities,omitempty"`                                                                                                  // 能力配置
	Limits        *ModelLimits           `protobuf:"bytes,7,opt,name=limits,proto3" json:"limits,omitempty"`                                                                                                              // 限制配置
	Pricing       *ModelPricing          `protobuf:"bytes,8,opt,name=pricing,proto3" json:"pricing,omitempty"`                                                                                                            // 定价配置
	DefaultParams map[string]string      `protobuf:"bytes,9,rep,name=default_params,json=defaultParams,proto3" json:"default_params,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 默认参数
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CreateModelRequest) Reset() {
	*x = CreateModelRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CreateModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelRequest) ProtoMessage() {}

func (x *CreateModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelRequest.ProtoReflect.Descriptor instead.
func (*CreateModelRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{19}
}

func (x *CreateModelRequest) GetProviderId() int64 {
	if x != nil {
		return x.ProviderId
	}
	return 0
}

func (x *CreateModelRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *CreateModelRequest) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *CreateModelRequest) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *CreateModelRequest) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *CreateModelRequest) GetCapabilities() *ModelCapabilities {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *CreateModelRequest) GetLimits() *ModelLimits {
	if x != nil {
		return x.Limits
	}
	return nil
}

func (x *CreateModelRequest) GetPricing() *ModelPricing {
	if x != nil {
		return x.Pricing
	}
	return nil
}

func (x *CreateModelRequest) GetDefaultParams() map[string]string {
	if x != nil {
		return x.DefaultParams
	}
	return nil
}

type CreateModelReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *ModelInfo             `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"` // 创建的模型
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CreateModelReply) Reset() {
	*x = CreateModelReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CreateModelReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelReply) ProtoMessage() {}

func (x *CreateModelReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelReply.ProtoReflect.Descriptor instead.
func (*CreateModelReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{20}
}

func (x *CreateModelReply) GetModel() *ModelInfo {
	if x != nil {
		return x.Model
	}
	return nil
}

// 更新模型
type UpdateModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                                                                                                                     // 模型ID
	DisplayName   string                 `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`                                                                                 // 显示名称
	Description   string                 `protobuf:"bytes,3,opt,name=description,proto3" json:"description,omitempty"`                                                                                                    // 描述
	Capabilities  *ModelCapabilities     `protobuf:"bytes,4,opt,name=capabilities,proto3" json:"capabilities,omitempty"`                                                                                                  // 能力配置
	Limits        *ModelLimits           `protobuf:"bytes,5,opt,name=limits,proto3" json:"limits,omitempty"`                                                                                                              // 限制配置
	Pricing       *ModelPricing          `protobuf:"bytes,6,opt,name=pricing,proto3" json:"pricing,omitempty"`                                                                                                            // 定价配置
	DefaultParams map[string]string      `protobuf:"bytes,7,rep,name=default_params,json=defaultParams,proto3" json:"default_params,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 默认参数
	Status        int32                  `protobuf:"varint,8,opt,name=status,proto3" json:"status,omitempty"`                                                                                                             // 状态
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpdateModelRequest) Reset() {
	*x = UpdateModelRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateModelRequest) ProtoMessage() {}

func (x *UpdateModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateModelRequest.ProtoReflect.Descriptor instead.
func (*UpdateModelRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{21}
}

func (x *UpdateModelRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *UpdateModelRequest) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *UpdateModelRequest) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *UpdateModelRequest) GetCapabilities() *ModelCapabilities {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *UpdateModelRequest) GetLimits() *ModelLimits {
	if x != nil {
		return x.Limits
	}
	return nil
}

func (x *UpdateModelRequest) GetPricing() *ModelPricing {
	if x != nil {
		return x.Pricing
	}
	return nil
}

func (x *UpdateModelRequest) GetDefaultParams() map[string]string {
	if x != nil {
		return x.DefaultParams
	}
	return nil
}

func (x *UpdateModelRequest) GetStatus() int32 {
	if x != nil {
		return x.Status
	}
	return 0
}

type UpdateModelReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *ModelInfo             `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"` // 更新后的模型
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpdateModelReply) Reset() {
	*x = UpdateModelReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateModelReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateModelReply) ProtoMessage() {}

func (x *UpdateModelReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateModelReply.ProtoReflect.Descriptor instead.
func (*UpdateModelReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{22}
}

func (x *UpdateModelReply) GetModel() *ModelInfo {
	if x != nil {
		return x.Model
	}
	return nil
}

// 删除模型
type DeleteModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"` // 模型ID
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteModelRequest) Reset() {
	*x = DeleteModelRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteModelRequest) ProtoMessage() {}

func (x *DeleteModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteModelRequest.ProtoReflect.Descriptor instead.
func (*DeleteModelRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{23}
}

func (x *DeleteModelRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

type DeleteModelReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteModelReply) Reset() {
	*x = DeleteModelReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteModelReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteModelReply) ProtoMessage() {}

func (x *DeleteModelReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteModelReply.ProtoReflect.Descriptor instead.
func (*DeleteModelReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{24}
}

// 列出模型
type ListModelsRequest struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	ProviderId           int64                  `protobuf:"varint,1,opt,name=provider_id,json=providerId,proto3" json:"provider_id,omitempty"`                              // 提供商过滤
	Status               int32                  `protobuf:"varint,2,opt,name=status,proto3" json:"status,omitempty"`                                                        // 状态过滤(-1:全部, 0:可用, 1:不可用)
	HasCapabilities      bool                   `protobuf:"varint,3,opt,name=has_capabilities,json=hasCapabilities,proto3" json:"has_capabilities,omitempty"`               // 按能力过滤
	RequiredCapabilities []string               `protobuf:"bytes,4,rep,name=required_capabilities,json=requiredCapabilities,proto3" json:"required_capabilities,omitempty"` // 必需的能力列表
	Page                 int32                  `protobuf:"varint,5,opt,name=page,proto3" json:"page,omitempty"`                                                            // 页码
	PageSize             int32                  `protobuf:"varint,6,opt,name=page_size,json=pageSize,proto3" json:"page_size,omitempty"`                                    // 页面大小
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{25}
}

func (x *ListModelsRequest) GetProviderId() int64 {
	if x != nil {
		return x.ProviderId
	}
	return 0
}

func (x *ListModelsRequest) GetStatus() int32 {
	if x != nil {
		return x.Status
	}
	return 0
}

func (x *ListModelsRequest) GetHasCapabilities() bool {
	if x != nil {
		return x.HasCapabilities
	}
	return false
}

func (x *ListModelsRequest) GetRequiredCapabilities() []string {
	if x != nil {
		return x.RequiredCapabilities
	}
	return nil
}

func (x *ListModelsRequest) GetPage() int32 {
	if x != nil {
		return x.Page
	}
	return 0
}

func (x *ListModelsRequest) GetPageSize() int32 {
	if x != nil {
		return x.PageSize
	}
	return 0
}

type ListModelsReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []*ModelInfo           `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"` // 模型列表
	Total         int64                  `protobuf:"varint,2,opt,name=total,proto3" json:"total,omitempty"`  // 总数
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsReply) Reset() {
	*x = ListModelsReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsReply) ProtoMessage() {}

func (x *ListModelsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsReply.ProtoReflect.Descriptor instead.
func (*ListModelsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{26}
}

func (x *ListModelsReply) GetModels() []*ModelInfo {
	if x != nil {
		return x.Models
	}
	return nil
}

func (x *ListModelsReply) GetTotal() int64 {
	if x != nil {
		return x.Total
	}
	return 0
}

// 获取模型
type GetModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"` // 模型ID
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelRequest) Reset() {
	*x = GetModelRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelRequest) ProtoMessage() {}

func (x *GetModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelRequest.ProtoReflect.Descriptor instead.
func (*GetModelRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{27}
}

func (x *GetModelRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

type GetModelReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Model         *ModelInfo             `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"` // 模型信息
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelReply) Reset() {
	*x = GetModelReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelReply) ProtoMessage() {}

func (x *GetModelReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelReply.ProtoReflect.Descriptor instead.
func (*GetModelReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{28}
}

func (x *GetModelReply) GetModel() *ModelInfo {
	if x != nil {
		return x.Model
	}
	return nil
}

// 切换模型
type SwitchModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`    // 用户ID
	ModelId       int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"` // 新的默认模型ID
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SwitchModelRequest) Reset() {
	*x = SwitchModelRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[29]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SwitchModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SwitchModelRequest) ProtoMessage() {}

func (x *SwitchModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[29]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SwitchModelRequest.ProtoReflect.Descriptor instead.
func (*SwitchModelRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{29}
}

func (x *SwitchModelRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *SwitchModelRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

type SwitchModelReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"` // 是否成功
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SwitchModelReply) Reset() {
	*x = SwitchModelReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[30]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SwitchModelReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SwitchModelReply) ProtoMessage() {}

func (x *SwitchModelReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[30]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SwitchModelReply.ProtoReflect.Descriptor instead.
func (*SwitchModelReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{30}
}

func (x *SwitchModelReply) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

// 获取用户配额
type GetUserQuotaRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`    // 用户ID
	ModelId       int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"` // 模型ID(可选，为空返回所有模型配额)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetUserQuotaRequest) Reset() {
	*x = GetUserQuotaRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[31]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetUserQuotaRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetUserQuotaRequest) ProtoMessage() {}

func (x *GetUserQuotaRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[31]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetUserQuotaRequest.ProtoReflect.Descriptor instead.
func (*GetUserQuotaRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{31}
}

func (x *GetUserQuotaRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *GetUserQuotaRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

type GetUserQuotaReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Quotas        []*UserQuota           `protobuf:"bytes,1,rep,name=quotas,proto3" json:"quotas,omitempty"` // 配额列表
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetUserQuotaReply) Reset() {
	*x = GetUserQuotaReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[32]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetUserQuotaReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetUserQuotaReply) ProtoMessage() {}

func (x *GetUserQuotaReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[32]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetUserQuotaReply.ProtoReflect.Descriptor instead.
func (*GetUserQuotaReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{32}
}

func (x *GetUserQuotaReply) GetQuotas() []*UserQuota {
	if x != nil {
		return x.Quotas
	}
	return nil
}

// 更新用户配额
type UpdateUserQuotaRequest struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	UserId              int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                          // 用户ID
	ModelId             int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                                       // 模型ID
	DailyTokenLimit     int64                  `protobuf:"varint,3,opt,name=daily_token_limit,json=dailyTokenLimit,proto3" json:"daily_token_limit,omitempty"`             // 每日token限制
	MonthlyTokenLimit   int64                  `protobuf:"varint,4,opt,name=monthly_token_limit,json=monthlyTokenLimit,proto3" json:"monthly_token_limit,omitempty"`       // 每月token限制
	DailyRequestLimit   int64                  `protobuf:"varint,5,opt,name=daily_request_limit,json=dailyRequestLimit,proto3" json:"daily_request_limit,omitempty"`       // 每日请求限制
	MonthlyRequestLimit int64                  `protobuf:"varint,6,opt,name=monthly_request_limit,json=monthlyRequestLimit,proto3" json:"monthly_request_limit,omitempty"` // 每月请求限制
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *UpdateUserQuotaRequest) Reset() {
	*x = UpdateUserQuotaRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[33]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateUserQuotaRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateUserQuotaRequest) ProtoMessage() {}

func (x *UpdateUserQuotaRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[33]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateUserQuotaRequest.ProtoReflect.Descriptor instead.
func (*UpdateUserQuotaRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{33}
}

func (x *UpdateUserQuotaRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *UpdateUserQuotaRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *UpdateUserQuotaRequest) GetDailyTokenLimit() int64 {
	if x != nil {
		return x.DailyTokenLimit
	}
	return 0
}

func (x *UpdateUserQuotaRequest) GetMonthlyTokenLimit() int64 {
	if x != nil {
		return x.MonthlyTokenLimit
	}
	return 0
}

func (x *UpdateUserQuotaRequest) GetDailyRequestLimit() int64 {
	if x != nil {
		return x.DailyRequestLimit
	}
	return 0
}

func (x *UpdateUserQuotaRequest) GetMonthlyRequestLimit() int64 {
	if x != nil {
		return x.MonthlyRequestLimit
	}
	return 0
}

type UpdateUserQuotaReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Quota         *UserQuota             `protobuf:"bytes,1,opt,name=quota,proto3" json:"quota,omitempty"` // 更新后的配额
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpdateUserQuotaReply) Reset() {
	*x = UpdateUserQuotaReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[34]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateUserQuotaReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateUserQuotaReply) ProtoMessage() {}

func (x *UpdateUserQuotaReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[34]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateUserQuotaReply.ProtoReflect.Descriptor instead.
func (*UpdateUserQuotaReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{34}
}

func (x *UpdateUserQuotaReply) GetQuota() *UserQuota {
	if x != nil {
		return x.Quota
	}
	return nil
}

// 获取使用统计
type GetUsageStatsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`         // 用户ID(可选)
	ModelId       int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`      // 模型ID(可选)
	StartDate     string                 `protobuf:"bytes,3,opt,name=start_date,json=startDate,proto3" json:"start_date,omitempty"` // 开始日期
	EndDate       string                 `protobuf:"bytes,4,opt,name=end_date,json=endDate,proto3" json:"end_date,omitempty"`       // 结束日期
	GroupBy       string                 `protobuf:"bytes,5,opt,name=group_by,json=groupBy,proto3" json:"group_by,omitempty"`       // 分组方式(day/month/user/model)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetUsageStatsRequest) Reset() {
	*x = GetUsageStatsRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[35]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetUsageStatsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetUsageStatsRequest) ProtoMessage() {}

func (x *GetUsageStatsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[35]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetUsageStatsRequest.ProtoReflect.Descriptor instead.
func (*GetUsageStatsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{35}
}

func (x *GetUsageStatsRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *GetUsageStatsRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *GetUsageStatsRequest) GetStartDate() string {
	if x != nil {
		return x.StartDate
	}
	return ""
}

func (x *GetUsageStatsRequest) GetEndDate() string {
	if x != nil {
		return x.EndDate
	}
	return ""
}

func (x *GetUsageStatsRequest) GetGroupBy() string {
	if x != nil {
		return x.GroupBy
	}
	return ""
}

type GetUsageStatsReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Stats         []*UsageStats          `protobuf:"bytes,1,rep,name=stats,proto3" json:"stats,omitempty"`                                       // 统计数据
	TotalRequests int64                  `protobuf:"varint,2,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"` // 总请求数
	TotalTokens   int64                  `protobuf:"varint,3,opt,name=total_tokens,json=totalTokens,proto3" json:"total_tokens,omitempty"`       // 总token数
	TotalCost     float64                `protobuf:"fixed64,4,opt,name=total_cost,json=totalCost,proto3" json:"total_cost,omitempty"`            // 总成本
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetUsageStatsReply) Reset() {
	*x = GetUsageStatsReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[36]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetUsageStatsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetUsageStatsReply) ProtoMessage() {}

func (x *GetUsageStatsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[36]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetUsageStatsReply.ProtoReflect.Descriptor instead.
func (*GetUsageStatsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{36}
}

func (x *GetUsageStatsReply) GetStats() []*UsageStats {
	if x != nil {
		return x.Stats
	}
	return nil
}

func (x *GetUsageStatsReply) GetTotalRequests() int64 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *GetUsageStatsReply) GetTotalTokens() int64 {
	if x != nil {
		return x.TotalTokens
	}
	return 0
}

func (x *GetUsageStatsReply) GetTotalCost() float64 {
	if x != nil {
		return x.TotalCost
	}
	return 0
}

// 重置使用量
type ResetUsageRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`         // 用户ID(可选，为空重置所有用户)
	ModelId       int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`      // 模型ID(可选，为空重置所有模型)
	ResetType     string                 `protobuf:"bytes,3,opt,name=reset_type,json=resetType,proto3" json:"reset_type,omitempty"` // 重置类型(daily/monthly/all)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResetUsageRequest) Reset() {
	*x = ResetUsageRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[37]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResetUsageRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResetUsageRequest) ProtoMessage() {}

func (x *ResetUsageRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[37]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResetUsageRequest.ProtoReflect.Descriptor instead.
func (*ResetUsageRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{37}
}

func (x *ResetUsageRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *ResetUsageRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *ResetUsageRequest) GetResetType() string {
	if x != nil {
		return x.ResetType
	}
	return ""
}

type ResetUsageReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`                                  // 是否成功
	AffectedUsers int64                  `protobuf:"varint,2,opt,name=affected_users,json=affectedUsers,proto3" json:"affected_users,omitempty"` // 影响的用户数
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResetUsageReply) Reset() {
	*x = ResetUsageReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[38]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResetUsageReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResetUsageReply) ProtoMessage() {}

func (x *ResetUsageReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[38]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResetUsageReply.ProtoReflect.Descriptor instead.
func (*ResetUsageReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{38}
}

func (x *ResetUsageReply) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *ResetUsageReply) GetAffectedUsers() int64 {
	if x != nil {
		return x.AffectedUsers
	}
	return 0
}

// 检查限流
type CheckRateLimitRequest struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	UserId          int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                            // 用户ID
	ModelId         int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                         // 模型ID
	RequestedTokens int32                  `protobuf:"varint,3,opt,name=requested_tokens,json=requestedTokens,proto3" json:"requested_tokens,omitempty"` // 请求的token数
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *CheckRateLimitRequest) Reset() {
	*x = CheckRateLimitRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[39]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CheckRateLimitRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CheckRateLimitRequest) ProtoMessage() {}

func (x *CheckRateLimitRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[39]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CheckRateLimitRequest.ProtoReflect.Descriptor instead.
func (*CheckRateLimitRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{39}
}

func (x *CheckRateLimitRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *CheckRateLimitRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *CheckRateLimitRequest) GetRequestedTokens() int32 {
	if x != nil {
		return x.RequestedTokens
	}
	return 0
}

type CheckRateLimitReply struct {
	state             protoimpl.MessageState `protogen:"open.v1"`
	Allowed           bool                   `protobuf:"varint,1,opt,name=allowed,proto3" json:"allowed,omitempty"`                                                // 是否允许
	Reason            string                 `protobuf:"bytes,2,opt,name=reason,proto3" json:"reason,omitempty"`                                                   // 拒绝原因
	RetryAfterSeconds int32                  `protobuf:"varint,3,opt,name=retry_after_seconds,json=retryAfterSeconds,proto3" json:"retry_after_seconds,omitempty"` // 重试等待时间
	RemainingRequests int32                  `protobuf:"varint,4,opt,name=remaining_requests,json=remainingRequests,proto3" json:"remaining_requests,omitempty"`   // 剩余请求数
	RemainingTokens   int32                  `protobuf:"varint,5,opt,name=remaining_tokens,json=remainingTokens,proto3" json:"remaining_tokens,omitempty"`         // 剩余token数
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *CheckRateLimitReply) Reset() {
	*x = CheckRateLimitReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[40]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CheckRateLimitReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CheckRateLimitReply) ProtoMessage() {}

func (x *CheckRateLimitReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[40]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CheckRateLimitReply.ProtoReflect.Descriptor instead.
func (*CheckRateLimitReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{40}
}

func (x *CheckRateLimitReply) GetAllowed() bool {
	if x != nil {
		return x.Allowed
	}
	return false
}

func (x *CheckRateLimitReply) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

func (x *CheckRateLimitReply) GetRetryAfterSeconds() int32 {
	if x != nil {
		return x.RetryAfterSeconds
	}
	return 0
}

func (x *CheckRateLimitReply) GetRemainingRequests() int32 {
	if x != nil {
		return x.RemainingRequests
	}
	return 0
}

func (x *CheckRateLimitReply) GetRemainingTokens() int32 {
	if x != nil {
		return x.RemainingTokens
	}
	return 0
}

// 获取限流配置
type GetRateLimitConfigRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelId       int64                  `protobuf:"varint,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`      // 模型ID(可选)
	UserLevel     string                 `protobuf:"bytes,2,opt,name=user_level,json=userLevel,proto3" json:"user_level,omitempty"` // 用户等级(可选)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetRateLimitConfigRequest) Reset() {
	*x = GetRateLimitConfigRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[41]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetRateLimitConfigRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetRateLimitConfigRequest) ProtoMessage() {}

func (x *GetRateLimitConfigRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[41]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetRateLimitConfigRequest.ProtoReflect.Descriptor instead.
func (*GetRateLimitConfigRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{41}
}

func (x *GetRateLimitConfigRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *GetRateLimitConfigRequest) GetUserLevel() string {
	if x != nil {
		return x.UserLevel
	}
	return ""
}

type GetRateLimitConfigReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Configs       []*RateLimitConfig     `protobuf:"bytes,1,rep,name=configs,proto3" json:"configs,omitempty"` // 限流配置列表
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetRateLimitConfigReply) Reset() {
	*x = GetRateLimitConfigReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[42]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetRateLimitConfigReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetRateLimitConfigReply) ProtoMessage() {}

func (x *GetRateLimitConfigReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[42]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetRateLimitConfigReply.ProtoReflect.Descriptor instead.
func (*GetRateLimitConfigReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{42}
}

func (x *GetRateLimitConfigReply) GetConfigs() []*RateLimitConfig {
	if x != nil {
		return x.Configs
	}
	return nil
}

// 更新限流配置
type UpdateRateLimitConfigRequest struct {
	state              protoimpl.MessageState `protogen:"open.v1"`
	Id                 int64                  `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`                                                           // 配置ID
	ModelId            int64                  `protobuf:"varint,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                                  // 模型ID
	UserLevel          string                 `protobuf:"bytes,3,opt,name=user_level,json=userLevel,proto3" json:"user_level,omitempty"`                             // 用户等级
	RequestsPerMinute  int32                  `protobuf:"varint,4,opt,name=requests_per_minute,json=requestsPerMinute,proto3" json:"requests_per_minute,omitempty"`  // 每分钟请求限制
	RequestsPerHour    int32                  `protobuf:"varint,5,opt,name=requests_per_hour,json=requestsPerHour,proto3" json:"requests_per_hour,omitempty"`        // 每小时请求限制
	RequestsPerDay     int32                  `protobuf:"varint,6,opt,name=requests_per_day,json=requestsPerDay,proto3" json:"requests_per_day,omitempty"`           // 每天请求限制
	TokensPerMinute    int32                  `protobuf:"varint,7,opt,name=tokens_per_minute,json=tokensPerMinute,proto3" json:"tokens_per_minute,omitempty"`        // 每分钟token限制
	ConcurrentRequests int32                  `protobuf:"varint,8,opt,name=concurrent_requests,json=concurrentRequests,proto3" json:"concurrent_requests,omitempty"` // 并发请求限制
	BurstLimit         int32                  `protobuf:"varint,9,opt,name=burst_limit,json=burstLimit,proto3" json:"burst_limit,omitempty"`                         // 突发请求限制
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *UpdateRateLimitConfigRequest) Reset() {
	*x = UpdateRateLimitConfigRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[43]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateRateLimitConfigRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateRateLimitConfigRequest) ProtoMessage() {}

func (x *UpdateRateLimitConfigRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[43]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateRateLimitConfigRequest.ProtoReflect.Descriptor instead.
func (*UpdateRateLimitConfigRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{43}
}

func (x *UpdateRateLimitConfigRequest) GetId() int64 {
	if x != nil {
		return x.Id
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetUserLevel() string {
	if x != nil {
		return x.UserLevel
	}
	return ""
}

func (x *UpdateRateLimitConfigRequest) GetRequestsPerMinute() int32 {
	if x != nil {
		return x.RequestsPerMinute
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetRequestsPerHour() int32 {
	if x != nil {
		return x.RequestsPerHour
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetRequestsPerDay() int32 {
	if x != nil {
		return x.RequestsPerDay
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetTokensPerMinute() int32 {
	if x != nil {
		return x.TokensPerMinute
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetConcurrentRequests() int32 {
	if x != nil {
		return x.ConcurrentRequests
	}
	return 0
}

func (x *UpdateRateLimitConfigRequest) GetBurstLimit() int32 {
	if x != nil {
		return x.BurstLimit
	}
	return 0
}

type UpdateRateLimitConfigReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Config        *RateLimitConfig       `protobuf:"bytes,1,opt,name=config,proto3" json:"config,omitempty"` // 更新后的配置
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpdateRateLimitConfigReply) Reset() {
	*x = UpdateRateLimitConfigReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[44]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpdateRateLimitConfigReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpdateRateLimitConfigReply) ProtoMessage() {}

func (x *UpdateRateLimitConfigReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[44]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpdateRateLimitConfigReply.ProtoReflect.Descriptor instead.
func (*UpdateRateLimitConfigReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{44}
}

func (x *UpdateRateLimitConfigReply) GetConfig() *RateLimitConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

// 健康检查
type HealthCheckRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelId       int64                  `protobuf:"varint,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"` // 模型ID(可选，为空检查所有模型)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckRequest) Reset() {
	*x = HealthCheckRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[45]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckRequest) ProtoMessage() {}

func (x *HealthCheckRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[45]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckRequest.ProtoReflect.Descriptor instead.
func (*HealthCheckRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{45}
}

func (x *HealthCheckRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

type HealthCheckReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	HealthStatus  []*ModelHealth         `protobuf:"bytes,1,rep,name=health_status,json=healthStatus,proto3" json:"health_status,omitempty"` // 健康状态列表
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckReply) Reset() {
	*x = HealthCheckReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[46]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckReply) ProtoMessage() {}

func (x *HealthCheckReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[46]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckReply.ProtoReflect.Descriptor instead.
func (*HealthCheckReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{46}
}

func (x *HealthCheckReply) GetHealthStatus() []*ModelHealth {
	if x != nil {
		return x.HealthStatus
	}
	return nil
}

// 获取模型指标
type GetModelMetricsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelId       int64                  `protobuf:"varint,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`      // 模型ID
	StartTime     string                 `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"` // 开始时间
	EndTime       string                 `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`       // 结束时间
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelMetricsRequest) Reset() {
	*x = GetModelMetricsRequest{}
	mi := &file_api_ai_v1_model_proto_msgTypes[47]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelMetricsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelMetricsRequest) ProtoMessage() {}

func (x *GetModelMetricsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[47]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelMetricsRequest.ProtoReflect.Descriptor instead.
func (*GetModelMetricsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{47}
}

func (x *GetModelMetricsRequest) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *GetModelMetricsRequest) GetStartTime() string {
	if x != nil {
		return x.StartTime
	}
	return ""
}

func (x *GetModelMetricsRequest) GetEndTime() string {
	if x != nil {
		return x.EndTime
	}
	return ""
}

type GetModelMetricsReply struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	ModelId         int64                  `protobuf:"varint,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                            // 模型ID
	AvgResponseTime float64                `protobuf:"fixed64,2,opt,name=avg_response_time,json=avgResponseTime,proto3" json:"avg_response_time,omitempty"` // 平均响应时间
	SuccessRate     float64                `protobuf:"fixed64,3,opt,name=success_rate,json=successRate,proto3" json:"success_rate,omitempty"`               // 成功率
	TotalRequests   int64                  `protobuf:"varint,4,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"`          // 总请求数
	ErrorCount      int64                  `protobuf:"varint,5,opt,name=error_count,json=errorCount,proto3" json:"error_count,omitempty"`                   // 错误数量
	TopErrors       []string               `protobuf:"bytes,6,rep,name=top_errors,json=topErrors,proto3" json:"top_errors,omitempty"`                       // 主要错误类型
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *GetModelMetricsReply) Reset() {
	*x = GetModelMetricsReply{}
	mi := &file_api_ai_v1_model_proto_msgTypes[48]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelMetricsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelMetricsReply) ProtoMessage() {}

func (x *GetModelMetricsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_model_proto_msgTypes[48]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelMetricsReply.ProtoReflect.Descriptor instead.
func (*GetModelMetricsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_model_proto_rawDescGZIP(), []int{48}
}

func (x *GetModelMetricsReply) GetModelId() int64 {
	if x != nil {
		return x.ModelId
	}
	return 0
}

func (x *GetModelMetricsReply) GetAvgResponseTime() float64 {
	if x != nil {
		return x.AvgResponseTime
	}
	return 0
}

func (x *GetModelMetricsReply) GetSuccessRate() float64 {
	if x != nil {
		return x.SuccessRate
	}
	return 0
}

func (x *GetModelMetricsReply) GetTotalRequests() int64 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *GetModelMetricsReply) GetErrorCount() int64 {
	if x != nil {
		return x.ErrorCount
	}
	return 0
}

func (x *GetModelMetricsReply) GetTopErrors() []string {
	if x != nil {
		return x.TopErrors
	}
	return nil
}

var File_api_ai_v1_model_proto protoreflect.FileDescriptor

const file_api_ai_v1_model_proto_rawDesc = "" +
	"\n" +
	"\x15api/ai/v1/model.proto\x12\tapi.ai.v1\x1a\x1fgoogle/protobuf/timestamp.proto\"\xd4\x04\n" +
	"\bProvider\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x03 \x01(\tR\vdisplayName\x12 \n" +
	"\vdescription\x18\x04 \x01(\tR\vdescription\x12 \n" +
	"\fapi_base_url\x18\x05 \x01(\tR\n" +
	"apiBaseUrl\x12&\n" +
	"\x0fdefault_api_key\x18\x06 \x01(\tR\rdefaultApiKey\x12P\n" +
	"\x0fdefault_headers\x18\a \x03(\v2'.api.ai.v1.Provider.DefaultHeadersEntryR\x0edefaultHeaders\x127\n" +
	"\x06config\x18\b \x03(\v2\x1f.api.ai.v1.Provider.ConfigEntryR\x06config\x12\x16\n" +
	"\x06status\x18\t \x01(\x05R\x06status\x129\n" +
	"\n" +
	"created_at\x18\n" +
	" \x01(\v2\x1a.google.protobuf.TimestampR\tcreatedAt\x129\n" +
	"\n" +
	"updated_at\x18\v \x01(\v2\x1a.google.protobuf.TimestampR\tupdatedAt\x1aA\n" +
	"\x13DefaultHeadersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a9\n" +
	"\vConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xf4\x04\n" +
	"\tModelInfo\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12\x1f\n" +
	"\vprovider_id\x18\x02 \x01(\x03R\n" +
	"providerId\x12\x12\n" +
	"\x04name\x18\x03 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x04 \x01(\tR\vdisplayName\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12\x18\n" +
	"\aversion\x18\x06 \x01(\tR\aversion\x12@\n" +
	"\fcapabilities\x18\a \x01(\v2\x1c.api.ai.v1.ModelCapabilitiesR\fcapabilities\x12.\n" +
	"\x06limits\x18\b \x01(\v2\x16.api.ai.v1.ModelLimitsR\x06limits\x121\n" +
	"\apricing\x18\t \x01(\v2\x17.api.ai.v1.ModelPricingR\apricing\x12N\n" +
	"\x0edefault_params\x18\n" +
	" \x03(\v2'.api.ai.v1.ModelInfo.DefaultParamsEntryR\rdefaultParams\x12\x16\n" +
	"\x06status\x18\v \x01(\x05R\x06status\x129\n" +
	"\n" +
	"created_at\x18\f \x01(\v2\x1a.google.protobuf.TimestampR\tcreatedAt\x129\n" +
	"\n" +
	"updated_at\x18\r \x01(\v2\x1a.google.protobuf.TimestampR\tupdatedAt\x1a@\n" +
	"\x12DefaultParamsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xeb\x02\n" +
	"\x11ModelCapabilities\x12#\n" +
	"\rsupports_chat\x18\x01 \x01(\bR\fsupportsChat\x12/\n" +
	"\x13supports_completion\x18\x02 \x01(\bR\x12supportsCompletion\x12-\n" +
	"\x12supports_embedding\x18\x03 \x01(\bR\x11supportsEmbedding\x12%\n" +
	"\x0esupports_tools\x18\x04 \x01(\bR\rsupportsTools\x12'\n" +
	"\x0fsupports_vision\x18\x05 \x01(\bR\x0esupportsVision\x12%\n" +
	"\x0esupports_audio\x18\x06 \x01(\bR\rsupportsAudio\x12-\n" +
	"\x12supports_streaming\x18\a \x01(\bR\x11supportsStreaming\x12+\n" +
	"\x11supported_formats\x18\b \x03(\tR\x10supportedFormats\"\xe5\x02\n" +
	"\vModelLimits\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x01 \x01(\x05R\tmaxTokens\x12(\n" +
	"\x10max_input_tokens\x18\x02 \x01(\x05R\x0emaxInputTokens\x12*\n" +
	"\x11max_output_tokens\x18\x03 \x01(\x05R\x0fmaxOutputTokens\x12%\n" +
	"\x0econtext_window\x18\x04 \x01(\x05R\rcontextWindow\x12'\n" +
	"\x0fmax_temperature\x18\x05 \x01(\x01R\x0emaxTemperature\x12'\n" +
	"\x0fmin_temperature\x18\x06 \x01(\x01R\x0eminTemperature\x125\n" +
	"\x17max_requests_per_minute\x18\a \x01(\x05R\x14maxRequestsPerMinute\x121\n" +
	"\x15max_tokens_per_minute\x18\b \x01(\x05R\x12maxTokensPerMinute\"\xb9\x01\n" +
	"\fModelPricing\x121\n" +
	"\x15input_price_per_token\x18\x01 \x01(\x01R\x12inputPricePerToken\x123\n" +
	"\x16output_price_per_token\x18\x02 \x01(\x01R\x13outputPricePerToken\x12\x1a\n" +
	"\bcurrency\x18\x03 \x01(\tR\bcurrency\x12%\n" +
	"\x0ebatch_discount\x18\x04 \x01(\x01R\rbatchDiscount\"\xc7\x04\n" +
	"\tUserQuota\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12*\n" +
	"\x11daily_token_limit\x18\x03 \x01(\x03R\x0fdailyTokenLimit\x12.\n" +
	"\x13monthly_token_limit\x18\x04 \x01(\x03R\x11monthlyTokenLimit\x12.\n" +
	"\x13daily_request_limit\x18\x05 \x01(\x03R\x11dailyRequestLimit\x122\n" +
	"\x15monthly_request_limit\x18\x06 \x01(\x03R\x13monthlyRequestLimit\x12*\n" +
	"\x11daily_tokens_used\x18\a \x01(\x03R\x0fdailyTokensUsed\x12.\n" +
	"\x13monthly_tokens_used\x18\b \x01(\x03R\x11monthlyTokensUsed\x12.\n" +
	"\x13daily_requests_used\x18\t \x01(\x03R\x11dailyRequestsUsed\x122\n" +
	"\x15monthly_requests_used\x18\n" +
	" \x01(\x03R\x13monthlyRequestsUsed\x12@\n" +
	"\x0ereset_daily_at\x18\v \x01(\v2\x1a.google.protobuf.TimestampR\fresetDailyAt\x12D\n" +
	"\x10reset_monthly_at\x18\f \x01(\v2\x1a.google.protobuf.TimestampR\x0eresetMonthlyAt\"\x8b\x03\n" +
	"\n" +
	"UsageStats\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12\x12\n" +
	"\x04date\x18\x03 \x01(\tR\x04date\x12%\n" +
	"\x0etotal_requests\x18\x04 \x01(\x03R\rtotalRequests\x12/\n" +
	"\x13successful_requests\x18\x05 \x01(\x03R\x12successfulRequests\x12'\n" +
	"\x0ffailed_requests\x18\x06 \x01(\x03R\x0efailedRequests\x12!\n" +
	"\ftotal_tokens\x18\a \x01(\x03R\vtotalTokens\x12!\n" +
	"\finput_tokens\x18\b \x01(\x03R\vinputTokens\x12#\n" +
	"\routput_tokens\x18\t \x01(\x03R\foutputTokens\x12\x1d\n" +
	"\n" +
	"total_cost\x18\n" +
	" \x01(\x01R\ttotalCost\x12*\n" +
	"\x11avg_response_time\x18\v \x01(\x01R\x0favgResponseTime\"\xd5\x03\n" +
	"\x0fRateLimitConfig\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"user_level\x18\x03 \x01(\tR\tuserLevel\x12.\n" +
	"\x13requests_per_minute\x18\x04 \x01(\x05R\x11requestsPerMinute\x12*\n" +
	"\x11requests_per_hour\x18\x05 \x01(\x05R\x0frequestsPerHour\x12(\n" +
	"\x10requests_per_day\x18\x06 \x01(\x05R\x0erequestsPerDay\x12*\n" +
	"\x11tokens_per_minute\x18\a \x01(\x05R\x0ftokensPerMinute\x12/\n" +
	"\x13concurrent_requests\x18\b \x01(\x05R\x12concurrentRequests\x12\x1f\n" +
	"\vburst_limit\x18\t \x01(\x05R\n" +
	"burstLimit\x129\n" +
	"\n" +
	"created_at\x18\n" +
	" \x01(\v2\x1a.google.protobuf.TimestampR\tcreatedAt\x129\n" +
	"\n" +
	"updated_at\x18\v \x01(\v2\x1a.google.protobuf.TimestampR\tupdatedAt\"\xbf\x02\n" +
	"\vModelHealth\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"is_healthy\x18\x02 \x01(\bR\tisHealthy\x12#\n" +
	"\rresponse_time\x18\x03 \x01(\x01R\fresponseTime\x12!\n" +
	"\fsuccess_rate\x18\x04 \x01(\x01R\vsuccessRate\x12%\n" +
	"\x0etotal_requests\x18\x05 \x01(\x03R\rtotalRequests\x12'\n" +
	"\x0ffailed_requests\x18\x06 \x01(\x03R\x0efailedRequests\x12#\n" +
	"\rerror_message\x18\a \x01(\tR\ferrorMessage\x129\n" +
	"\n" +
	"last_check\x18\b \x01(\v2\x1a.google.protobuf.TimestampR\tlastCheck\"\xdd\x03\n" +
	"\x15CreateProviderRequest\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12 \n" +
	"\vdescription\x18\x03 \x01(\tR\vdescription\x12 \n" +
	"\fapi_base_url\x18\x04 \x01(\tR\n" +
	"apiBaseUrl\x12&\n" +
	"\x0fdefault_api_key\x18\x05 \x01(\tR\rdefaultApiKey\x12]\n" +
	"\x0fdefault_headers\x18\x06 \x03(\v24.api.ai.v1.CreateProviderRequest.DefaultHeadersEntryR\x0edefaultHeaders\x12D\n" +
	"\x06config\x18\a \x03(\v2,.api.ai.v1.CreateProviderRequest.ConfigEntryR\x06config\x1aA\n" +
	"\x13DefaultHeadersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a9\n" +
	"\vConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"F\n" +
	"\x13CreateProviderReply\x12/\n" +
	"\bprovider\x18\x01 \x01(\v2\x13.api.ai.v1.ProviderR\bprovider\"\xf1\x03\n" +
	"\x15UpdateProviderRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12 \n" +
	"\vdescription\x18\x03 \x01(\tR\vdescription\x12 \n" +
	"\fapi_base_url\x18\x04 \x01(\tR\n" +
	"apiBaseUrl\x12&\n" +
	"\x0fdefault_api_key\x18\x05 \x01(\tR\rdefaultApiKey\x12]\n" +
	"\x0fdefault_headers\x18\x06 \x03(\v24.api.ai.v1.UpdateProviderRequest.DefaultHeadersEntryR\x0edefaultHeaders\x12D\n" +
	"\x06config\x18\a \x03(\v2,.api.ai.v1.UpdateProviderRequest.ConfigEntryR\x06config\x12\x16\n" +
	"\x06status\x18\b \x01(\x05R\x06status\x1aA\n" +
	"\x13DefaultHeadersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a9\n" +
	"\vConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"F\n" +
	"\x13UpdateProviderReply\x12/\n" +
	"\bprovider\x18\x01 \x01(\v2\x13.api.ai.v1.ProviderR\bprovider\"'\n" +
	"\x15DeleteProviderRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\"\x15\n" +
	"\x13DeleteProviderReply\"_\n" +
	"\x14ListProvidersRequest\x12\x16\n" +
	"\x06status\x18\x01 \x01(\x05R\x06status\x12\x12\n" +
	"\x04page\x18\x02 \x01(\x05R\x04page\x12\x1b\n" +
	"\tpage_size\x18\x03 \x01(\x05R\bpageSize\"]\n" +
	"\x12ListProvidersReply\x121\n" +
	"\tproviders\x18\x01 \x03(\v2\x13.api.ai.v1.ProviderR\tproviders\x12\x14\n" +
	"\x05total\x18\x02 \x01(\x03R\x05total\">\n" +
	"\x13TestProviderRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12\x17\n" +
	"\aapi_key\x18\x02 \x01(\tR\x06apiKey\"\x80\x01\n" +
	"\x11TestProviderReply\x12!\n" +
	"\fis_available\x18\x01 \x01(\bR\visAvailable\x12#\n" +
	"\rresponse_time\x18\x02 \x01(\x01R\fresponseTime\x12#\n" +
	"\rerror_message\x18\x03 \x01(\tR\ferrorMessage\"\xe8\x03\n" +
	"\x12CreateModelRequest\x12\x1f\n" +
	"\vprovider_id\x18\x01 \x01(\x03R\n" +
	"providerId\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x03 \x01(\tR\vdisplayName\x12 \n" +
	"\vdescription\x18\x04 \x01(\tR\vdescription\x12\x18\n" +
	"\aversion\x18\x05 \x01(\tR\aversion\x12@\n" +
	"\fcapabilities\x18\x06 \x01(\v2\x1c.api.ai.v1.ModelCapabilitiesR\fcapabilities\x12.\n" +
	"\x06limits\x18\a \x01(\v2\x16.api.ai.v1.ModelLimitsR\x06limits\x121\n" +
	"\apricing\x18\b \x01(\v2\x17.api.ai.v1.ModelPricingR\apricing\x12W\n" +
	"\x0edefault_params\x18\t \x03(\v20.api.ai.v1.CreateModelRequest.DefaultParamsEntryR\rdefaultParams\x1a@\n" +
	"\x12DefaultParamsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\">\n" +
	"\x10CreateModelReply\x12*\n" +
	"\x05model\x18\x01 \x01(\v2\x14.api.ai.v1.ModelInfoR\x05model\"\xc1\x03\n" +
	"\x12UpdateModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12 \n" +
	"\vdescription\x18\x03 \x01(\tR\vdescription\x12@\n" +
	"\fcapabilities\x18\x04 \x01(\v2\x1c.api.ai.v1.ModelCapabilitiesR\fcapabilities\x12.\n" +
	"\x06limits\x18\x05 \x01(\v2\x16.api.ai.v1.ModelLimitsR\x06limits\x121\n" +
	"\apricing\x18\x06 \x01(\v2\x17.api.ai.v1.ModelPricingR\apricing\x12W\n" +
	"\x0edefault_params\x18\a \x03(\v20.api.ai.v1.UpdateModelRequest.DefaultParamsEntryR\rdefaultParams\x12\x16\n" +
	"\x06status\x18\b \x01(\x05R\x06status\x1a@\n" +
	"\x12DefaultParamsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\">\n" +
	"\x10UpdateModelReply\x12*\n" +
	"\x05model\x18\x01 \x01(\v2\x14.api.ai.v1.ModelInfoR\x05model\"$\n" +
	"\x12DeleteModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\"\x12\n" +
	"\x10DeleteModelReply\"\xdd\x01\n" +
	"\x11ListModelsRequest\x12\x1f\n" +
	"\vprovider_id\x18\x01 \x01(\x03R\n" +
	"providerId\x12\x16\n" +
	"\x06status\x18\x02 \x01(\x05R\x06status\x12)\n" +
	"\x10has_capabilities\x18\x03 \x01(\bR\x0fhasCapabilities\x123\n" +
	"\x15required_capabilities\x18\x04 \x03(\tR\x14requiredCapabilities\x12\x12\n" +
	"\x04page\x18\x05 \x01(\x05R\x04page\x12\x1b\n" +
	"\tpage_size\x18\x06 \x01(\x05R\bpageSize\"U\n" +
	"\x0fListModelsReply\x12,\n" +
	"\x06models\x18\x01 \x03(\v2\x14.api.ai.v1.ModelInfoR\x06models\x12\x14\n" +
	"\x05total\x18\x02 \x01(\x03R\x05total\"!\n" +
	"\x0fGetModelRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\";\n" +
	"\rGetModelReply\x12*\n" +
	"\x05model\x18\x01 \x01(\v2\x14.api.ai.v1.ModelInfoR\x05model\"H\n" +
	"\x12SwitchModelRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\",\n" +
	"\x10SwitchModelReply\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\"I\n" +
	"\x13GetUserQuotaRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\"A\n" +
	"\x11GetUserQuotaReply\x12,\n" +
	"\x06quotas\x18\x01 \x03(\v2\x14.api.ai.v1.UserQuotaR\x06quotas\"\x8c\x02\n" +
	"\x16UpdateUserQuotaRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12*\n" +
	"\x11daily_token_limit\x18\x03 \x01(\x03R\x0fdailyTokenLimit\x12.\n" +
	"\x13monthly_token_limit\x18\x04 \x01(\x03R\x11monthlyTokenLimit\x12.\n" +
	"\x13daily_request_limit\x18\x05 \x01(\x03R\x11dailyRequestLimit\x122\n" +
	"\x15monthly_request_limit\x18\x06 \x01(\x03R\x13monthlyRequestLimit\"B\n" +
	"\x14UpdateUserQuotaReply\x12*\n" +
	"\x05quota\x18\x01 \x01(\v2\x14.api.ai.v1.UserQuotaR\x05quota\"\x9f\x01\n" +
	"\x14GetUsageStatsRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"start_date\x18\x03 \x01(\tR\tstartDate\x12\x19\n" +
	"\bend_date\x18\x04 \x01(\tR\aendDate\x12\x19\n" +
	"\bgroup_by\x18\x05 \x01(\tR\agroupBy\"\xaa\x01\n" +
	"\x12GetUsageStatsReply\x12+\n" +
	"\x05stats\x18\x01 \x03(\v2\x15.api.ai.v1.UsageStatsR\x05stats\x12%\n" +
	"\x0etotal_requests\x18\x02 \x01(\x03R\rtotalRequests\x12!\n" +
	"\ftotal_tokens\x18\x03 \x01(\x03R\vtotalTokens\x12\x1d\n" +
	"\n" +
	"total_cost\x18\x04 \x01(\x01R\ttotalCost\"f\n" +
	"\x11ResetUsageRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"reset_type\x18\x03 \x01(\tR\tresetType\"R\n" +
	"\x0fResetUsageReply\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12%\n" +
	"\x0eaffected_users\x18\x02 \x01(\x03R\raffectedUsers\"v\n" +
	"\x15CheckRateLimitRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12)\n" +
	"\x10requested_tokens\x18\x03 \x01(\x05R\x0frequestedTokens\"\xd1\x01\n" +
	"\x13CheckRateLimitReply\x12\x18\n" +
	"\aallowed\x18\x01 \x01(\bR\aallowed\x12\x16\n" +
	"\x06reason\x18\x02 \x01(\tR\x06reason\x12.\n" +
	"\x13retry_after_seconds\x18\x03 \x01(\x05R\x11retryAfterSeconds\x12-\n" +
	"\x12remaining_requests\x18\x04 \x01(\x05R\x11remainingRequests\x12)\n" +
	"\x10remaining_tokens\x18\x05 \x01(\x05R\x0fremainingTokens\"U\n" +
	"\x19GetRateLimitConfigRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"user_level\x18\x02 \x01(\tR\tuserLevel\"O\n" +
	"\x17GetRateLimitConfigReply\x124\n" +
	"\aconfigs\x18\x01 \x03(\v2\x1a.api.ai.v1.RateLimitConfigR\aconfigs\"\xec\x02\n" +
	"\x1cUpdateRateLimitConfigRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\x03R\x02id\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"user_level\x18\x03 \x01(\tR\tuserLevel\x12.\n" +
	"\x13requests_per_minute\x18\x04 \x01(\x05R\x11requestsPerMinute\x12*\n" +
	"\x11requests_per_hour\x18\x05 \x01(\x05R\x0frequestsPerHour\x12(\n" +
	"\x10requests_per_day\x18\x06 \x01(\x05R\x0erequestsPerDay\x12*\n" +
	"\x11tokens_per_minute\x18\a \x01(\x05R\x0ftokensPerMinute\x12/\n" +
	"\x13concurrent_requests\x18\b \x01(\x05R\x12concurrentRequests\x12\x1f\n" +
	"\vburst_limit\x18\t \x01(\x05R\n" +
	"burstLimit\"P\n" +
	"\x1aUpdateRateLimitConfigReply\x122\n" +
	"\x06config\x18\x01 \x01(\v2\x1a.api.ai.v1.RateLimitConfigR\x06config\"/\n" +
	"\x12HealthCheckRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\x03R\amodelId\"O\n" +
	"\x10HealthCheckReply\x12;\n" +
	"\rhealth_status\x18\x01 \x03(\v2\x16.api.ai.v1.ModelHealthR\fhealthStatus\"m\n" +
	"\x16GetModelMetricsRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\x03R\amodelId\x12\x1d\n" +
	"\n" +
	"start_time\x18\x02 \x01(\tR\tstartTime\x12\x19\n" +
	"\bend_time\x18\x03 \x01(\tR\aendTime\"\xe7\x01\n" +
	"\x14GetModelMetricsReply\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\x03R\amodelId\x12*\n" +
	"\x11avg_response_time\x18\x02 \x01(\x01R\x0favgResponseTime\x12!\n" +
	"\fsuccess_rate\x18\x03 \x01(\x01R\vsuccessRate\x12%\n" +
	"\x0etotal_requests\x18\x04 \x01(\x03R\rtotalRequests\x12\x1f\n" +
	"\verror_count\x18\x05 \x01(\x03R\n" +
	"errorCount\x12\x1d\n" +
	"\n" +
	"top_errors\x18\x06 \x03(\tR\ttopErrors2\xd5\f\n" +
	"\x05Model\x12R\n" +
	"\x0eCreateProvider\x12 .api.ai.v1.CreateProviderRequest\x1a\x1e.api.ai.v1.CreateProviderReply\x12R\n" +
	"\x0eUpdateProvider\x12 .api.ai.v1.UpdateProviderRequest\x1a\x1e.api.ai.v1.UpdateProviderReply\x12R\n" +
	"\x0eDeleteProvider\x12 .api.ai.v1.DeleteProviderRequest\x1a\x1e.api.ai.v1.DeleteProviderReply\x12O\n" +
	"\rListProviders\x12\x1f.api.ai.v1.ListProvidersRequest\x1a\x1d.api.ai.v1.ListProvidersReply\x12L\n" +
	"\fTestProvider\x12\x1e.api.ai.v1.TestProviderRequest\x1a\x1c.api.ai.v1.TestProviderReply\x12I\n" +
	"\vCreateModel\x12\x1d.api.ai.v1.CreateModelRequest\x1a\x1b.api.ai.v1.CreateModelReply\x12I\n" +
	"\vUpdateModel\x12\x1d.api.ai.v1.UpdateModelRequest\x1a\x1b.api.ai.v1.UpdateModelReply\x12I\n" +
	"\vDeleteModel\x12\x1d.api.ai.v1.DeleteModelRequest\x1a\x1b.api.ai.v1.DeleteModelReply\x12F\n" +
	"\n" +
	"ListModels\x12\x1c.api.ai.v1.ListModelsRequest\x1a\x1a.api.ai.v1.ListModelsReply\x12@\n" +
	"\bGetModel\x12\x1a.api.ai.v1.GetModelRequest\x1a\x18.api.ai.v1.GetModelReply\x12I\n" +
	"\vSwitchModel\x12\x1d.api.ai.v1.SwitchModelRequest\x1a\x1b.api.ai.v1.SwitchModelReply\x12L\n" +
	"\fGetUserQuota\x12\x1e.api.ai.v1.GetUserQuotaRequest\x1a\x1c.api.ai.v1.GetUserQuotaReply\x12U\n" +
	"\x0fUpdateUserQuota\x12!.api.ai.v1.UpdateUserQuotaRequest\x1a\x1f.api.ai.v1.UpdateUserQuotaReply\x12O\n" +
	"\rGetUsageStats\x12\x1f.api.ai.v1.GetUsageStatsRequest\x1a\x1d.api.ai.v1.GetUsageStatsReply\x12F\n" +
	"\n" +
	"ResetUsage\x12\x1c.api.ai.v1.ResetUsageRequest\x1a\x1a.api.ai.v1.ResetUsageReply\x12R\n" +
	"\x0eCheckRateLimit\x12 .api.ai.v1.CheckRateLimitRequest\x1a\x1e.api.ai.v1.CheckRateLimitReply\x12^\n" +
	"\x12GetRateLimitConfig\x12$.api.ai.v1.GetRateLimitConfigRequest\x1a\".api.ai.v1.GetRateLimitConfigReply\x12g\n" +
	"\x15UpdateRateLimitConfig\x12'.api.ai.v1.UpdateRateLimitConfigRequest\x1a%.api.ai.v1.UpdateRateLimitConfigReply\x12I\n" +
	"\vHealthCheck\x12\x1d.api.ai.v1.HealthCheckRequest\x1a\x1b.api.ai.v1.HealthCheckReply\x12U\n" +
	"\x0fGetModelMetrics\x12!.api.ai.v1.GetModelMetricsRequest\x1a\x1f.api.ai.v1.GetModelMetricsReplyBH\n" +
	"\x1ecom.oldwei.universal.api.ai.v1B\fModelProtoV1P\x01Z\x16universal/api/ai/v1;v1b\x06proto3"

var (
	file_api_ai_v1_model_proto_rawDescOnce sync.Once
	file_api_ai_v1_model_proto_rawDescData []byte
)

func file_api_ai_v1_model_proto_rawDescGZIP() []byte {
	file_api_ai_v1_model_proto_rawDescOnce.Do(func() {
		file_api_ai_v1_model_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_ai_v1_model_proto_rawDesc), len(file_api_ai_v1_model_proto_rawDesc)))
	})
	return file_api_ai_v1_model_proto_rawDescData
}

var file_api_ai_v1_model_proto_msgTypes = make([]protoimpl.MessageInfo, 58)
var file_api_ai_v1_model_proto_goTypes = []any{
	(*Provider)(nil),                     // 0: api.ai.v1.Provider
	(*ModelInfo)(nil),                    // 1: api.ai.v1.ModelInfo
	(*ModelCapabilities)(nil),            // 2: api.ai.v1.ModelCapabilities
	(*ModelLimits)(nil),                  // 3: api.ai.v1.ModelLimits
	(*ModelPricing)(nil),                 // 4: api.ai.v1.ModelPricing
	(*UserQuota)(nil),                    // 5: api.ai.v1.UserQuota
	(*UsageStats)(nil),                   // 6: api.ai.v1.UsageStats
	(*RateLimitConfig)(nil),              // 7: api.ai.v1.RateLimitConfig
	(*ModelHealth)(nil),                  // 8: api.ai.v1.ModelHealth
	(*CreateProviderRequest)(nil),        // 9: api.ai.v1.CreateProviderRequest
	(*CreateProviderReply)(nil),          // 10: api.ai.v1.CreateProviderReply
	(*UpdateProviderRequest)(nil),        // 11: api.ai.v1.UpdateProviderRequest
	(*UpdateProviderReply)(nil),          // 12: api.ai.v1.UpdateProviderReply
	(*DeleteProviderRequest)(nil),        // 13: api.ai.v1.DeleteProviderRequest
	(*DeleteProviderReply)(nil),          // 14: api.ai.v1.DeleteProviderReply
	(*ListProvidersRequest)(nil),         // 15: api.ai.v1.ListProvidersRequest
	(*ListProvidersReply)(nil),           // 16: api.ai.v1.ListProvidersReply
	(*TestProviderRequest)(nil),          // 17: api.ai.v1.TestProviderRequest
	(*TestProviderReply)(nil),            // 18: api.ai.v1.TestProviderReply
	(*CreateModelRequest)(nil),           // 19: api.ai.v1.CreateModelRequest
	(*CreateModelReply)(nil),             // 20: api.ai.v1.CreateModelReply
	(*UpdateModelRequest)(nil),           // 21: api.ai.v1.UpdateModelRequest
	(*UpdateModelReply)(nil),             // 22: api.ai.v1.UpdateModelReply
	(*DeleteModelRequest)(nil),           // 23: api.ai.v1.DeleteModelRequest
	(*DeleteModelReply)(nil),             // 24: api.ai.v1.DeleteModelReply
	(*ListModelsRequest)(nil),            // 25: api.ai.v1.ListModelsRequest
	(*ListModelsReply)(nil),              // 26: api.ai.v1.ListModelsReply
	(*GetModelRequest)(nil),              // 27: api.ai.v1.GetModelRequest
	(*GetModelReply)(nil),                // 28: api.ai.v1.GetModelReply
	(*SwitchModelRequest)(nil),           // 29: api.ai.v1.SwitchModelRequest
	(*SwitchModelReply)(nil),             // 30: api.ai.v1.SwitchModelReply
	(*GetUserQuotaRequest)(nil),          // 31: api.ai.v1.GetUserQuotaRequest
	(*GetUserQuotaReply)(nil),            // 32: api.ai.v1.GetUserQuotaReply
	(*UpdateUserQuotaRequest)(nil),       // 33: api.ai.v1.UpdateUserQuotaRequest
	(*UpdateUserQuotaReply)(nil),         // 34: api.ai.v1.UpdateUserQuotaReply
	(*GetUsageStatsRequest)(nil),         // 35: api.ai.v1.GetUsageStatsRequest
	(*GetUsageStatsReply)(nil),           // 36: api.ai.v1.GetUsageStatsReply
	(*ResetUsageRequest)(nil),            // 37: api.ai.v1.ResetUsageRequest
	(*ResetUsageReply)(nil),              // 38: api.ai.v1.ResetUsageReply
	(*CheckRateLimitRequest)(nil),        // 39: api.ai.v1.CheckRateLimitRequest
	(*CheckRateLimitReply)(nil),          // 40: api.ai.v1.CheckRateLimitReply
	(*GetRateLimitConfigRequest)(nil),    // 41: api.ai.v1.GetRateLimitConfigRequest
	(*GetRateLimitConfigReply)(nil),      // 42: api.ai.v1.GetRateLimitConfigReply
	(*UpdateRateLimitConfigRequest)(nil), // 43: api.ai.v1.UpdateRateLimitConfigRequest
	(*UpdateRateLimitConfigReply)(nil),   // 44: api.ai.v1.UpdateRateLimitConfigReply
	(*HealthCheckRequest)(nil),           // 45: api.ai.v1.HealthCheckRequest
	(*HealthCheckReply)(nil),             // 46: api.ai.v1.HealthCheckReply
	(*GetModelMetricsRequest)(nil),       // 47: api.ai.v1.GetModelMetricsRequest
	(*GetModelMetricsReply)(nil),         // 48: api.ai.v1.GetModelMetricsReply
	nil,                                  // 49: api.ai.v1.Provider.DefaultHeadersEntry
	nil,                                  // 50: api.ai.v1.Provider.ConfigEntry
	nil,                                  // 51: api.ai.v1.ModelInfo.DefaultParamsEntry
	nil,                                  // 52: api.ai.v1.CreateProviderRequest.DefaultHeadersEntry
	nil,                                  // 53: api.ai.v1.CreateProviderRequest.ConfigEntry
	nil,                                  // 54: api.ai.v1.UpdateProviderRequest.DefaultHeadersEntry
	nil,                                  // 55: api.ai.v1.UpdateProviderRequest.ConfigEntry
	nil,                                  // 56: api.ai.v1.CreateModelRequest.DefaultParamsEntry
	nil,                                  // 57: api.ai.v1.UpdateModelRequest.DefaultParamsEntry
	(*timestamppb.Timestamp)(nil),        // 58: google.protobuf.Timestamp
}
var file_api_ai_v1_model_proto_depIdxs = []int32{
	49, // 0: api.ai.v1.Provider.default_headers:type_name -> api.ai.v1.Provider.DefaultHeadersEntry
	50, // 1: api.ai.v1.Provider.config:type_name -> api.ai.v1.Provider.ConfigEntry
	58, // 2: api.ai.v1.Provider.created_at:type_name -> google.protobuf.Timestamp
	58, // 3: api.ai.v1.Provider.updated_at:type_name -> google.protobuf.Timestamp
	2,  // 4: api.ai.v1.ModelInfo.capabilities:type_name -> api.ai.v1.ModelCapabilities
	3,  // 5: api.ai.v1.ModelInfo.limits:type_name -> api.ai.v1.ModelLimits
	4,  // 6: api.ai.v1.ModelInfo.pricing:type_name -> api.ai.v1.ModelPricing
	51, // 7: api.ai.v1.ModelInfo.default_params:type_name -> api.ai.v1.ModelInfo.DefaultParamsEntry
	58, // 8: api.ai.v1.ModelInfo.created_at:type_name -> google.protobuf.Timestamp
	58, // 9: api.ai.v1.ModelInfo.updated_at:type_name -> google.protobuf.Timestamp
	58, // 10: api.ai.v1.UserQuota.reset_daily_at:type_name -> google.protobuf.Timestamp
	58, // 11: api.ai.v1.UserQuota.reset_monthly_at:type_name -> google.protobuf.Timestamp
	58, // 12: api.ai.v1.RateLimitConfig.created_at:type_name -> google.protobuf.Timestamp
	58, // 13: api.ai.v1.RateLimitConfig.updated_at:type_name -> google.protobuf.Timestamp
	58, // 14: api.ai.v1.ModelHealth.last_check:type_name -> google.protobuf.Timestamp
	52, // 15: api.ai.v1.CreateProviderRequest.default_headers:type_name -> api.ai.v1.CreateProviderRequest.DefaultHeadersEntry
	53, // 16: api.ai.v1.CreateProviderRequest.config:type_name -> api.ai.v1.CreateProviderRequest.ConfigEntry
	0,  // 17: api.ai.v1.CreateProviderReply.provider:type_name -> api.ai.v1.Provider
	54, // 18: api.ai.v1.UpdateProviderRequest.default_headers:type_name -> api.ai.v1.UpdateProviderRequest.DefaultHeadersEntry
	55, // 19: api.ai.v1.UpdateProviderRequest.config:type_name -> api.ai.v1.UpdateProviderRequest.ConfigEntry
	0,  // 20: api.ai.v1.UpdateProviderReply.provider:type_name -> api.ai.v1.Provider
	0,  // 21: api.ai.v1.ListProvidersReply.providers:type_name -> api.ai.v1.Provider
	2,  // 22: api.ai.v1.CreateModelRequest.capabilities:type_name -> api.ai.v1.ModelCapabilities
	3,  // 23: api.ai.v1.CreateModelRequest.limits:type_name -> api.ai.v1.ModelLimits
	4,  // 24: api.ai.v1.CreateModelRequest.pricing:type_name -> api.ai.v1.ModelPricing
	56, // 25: api.ai.v1.CreateModelRequest.default_params:type_name -> api.ai.v1.CreateModelRequest.DefaultParamsEntry
	1,  // 26: api.ai.v1.CreateModelReply.model:type_name -> api.ai.v1.ModelInfo
	2,  // 27: api.ai.v1.UpdateModelRequest.capabilities:type_name -> api.ai.v1.ModelCapabilities
	3,  // 28: api.ai.v1.UpdateModelRequest.limits:type_name -> api.ai.v1.ModelLimits
	4,  // 29: api.ai.v1.UpdateModelRequest.pricing:type_name -> api.ai.v1.ModelPricing
	57, // 30: api.ai.v1.UpdateModelRequest.default_params:type_name -> api.ai.v1.UpdateModelRequest.DefaultParamsEntry
	1,  // 31: api.ai.v1.UpdateModelReply.model:type_name -> api.ai.v1.ModelInfo
	1,  // 32: api.ai.v1.ListModelsReply.models:type_name -> api.ai.v1.ModelInfo
	1,  // 33: api.ai.v1.GetModelReply.model:type_name -> api.ai.v1.ModelInfo
	5,  // 34: api.ai.v1.GetUserQuotaReply.quotas:type_name -> api.ai.v1.UserQuota
	5,  // 35: api.ai.v1.UpdateUserQuotaReply.quota:type_name -> api.ai.v1.UserQuota
	6,  // 36: api.ai.v1.GetUsageStatsReply.stats:type_name -> api.ai.v1.UsageStats
	7,  // 37: api.ai.v1.GetRateLimitConfigReply.configs:type_name -> api.ai.v1.RateLimitConfig
	7,  // 38: api.ai.v1.UpdateRateLimitConfigReply.config:type_name -> api.ai.v1.RateLimitConfig
	8,  // 39: api.ai.v1.HealthCheckReply.health_status:type_name -> api.ai.v1.ModelHealth
	9,  // 40: api.ai.v1.Model.CreateProvider:input_type -> api.ai.v1.CreateProviderRequest
	11, // 41: api.ai.v1.Model.UpdateProvider:input_type -> api.ai.v1.UpdateProviderRequest
	13, // 42: api.ai.v1.Model.DeleteProvider:input_type -> api.ai.v1.DeleteProviderRequest
	15, // 43: api.ai.v1.Model.ListProviders:input_type -> api.ai.v1.ListProvidersRequest
	17, // 44: api.ai.v1.Model.TestProvider:input_type -> api.ai.v1.TestProviderRequest
	19, // 45: api.ai.v1.Model.CreateModel:input_type -> api.ai.v1.CreateModelRequest
	21, // 46: api.ai.v1.Model.UpdateModel:input_type -> api.ai.v1.UpdateModelRequest
	23, // 47: api.ai.v1.Model.DeleteModel:input_type -> api.ai.v1.DeleteModelRequest
	25, // 48: api.ai.v1.Model.ListModels:input_type -> api.ai.v1.ListModelsRequest
	27, // 49: api.ai.v1.Model.GetModel:input_type -> api.ai.v1.GetModelRequest
	29, // 50: api.ai.v1.Model.SwitchModel:input_type -> api.ai.v1.SwitchModelRequest
	31, // 51: api.ai.v1.Model.GetUserQuota:input_type -> api.ai.v1.GetUserQuotaRequest
	33, // 52: api.ai.v1.Model.UpdateUserQuota:input_type -> api.ai.v1.UpdateUserQuotaRequest
	35, // 53: api.ai.v1.Model.GetUsageStats:input_type -> api.ai.v1.GetUsageStatsRequest
	37, // 54: api.ai.v1.Model.ResetUsage:input_type -> api.ai.v1.ResetUsageRequest
	39, // 55: api.ai.v1.Model.CheckRateLimit:input_type -> api.ai.v1.CheckRateLimitRequest
	41, // 56: api.ai.v1.Model.GetRateLimitConfig:input_type -> api.ai.v1.GetRateLimitConfigRequest
	43, // 57: api.ai.v1.Model.UpdateRateLimitConfig:input_type -> api.ai.v1.UpdateRateLimitConfigRequest
	45, // 58: api.ai.v1.Model.HealthCheck:input_type -> api.ai.v1.HealthCheckRequest
	47, // 59: api.ai.v1.Model.GetModelMetrics:input_type -> api.ai.v1.GetModelMetricsRequest
	10, // 60: api.ai.v1.Model.CreateProvider:output_type -> api.ai.v1.CreateProviderReply
	12, // 61: api.ai.v1.Model.UpdateProvider:output_type -> api.ai.v1.UpdateProviderReply
	14, // 62: api.ai.v1.Model.DeleteProvider:output_type -> api.ai.v1.DeleteProviderReply
	16, // 63: api.ai.v1.Model.ListProviders:output_type -> api.ai.v1.ListProvidersReply
	18, // 64: api.ai.v1.Model.TestProvider:output_type -> api.ai.v1.TestProviderReply
	20, // 65: api.ai.v1.Model.CreateModel:output_type -> api.ai.v1.CreateModelReply
	22, // 66: api.ai.v1.Model.UpdateModel:output_type -> api.ai.v1.UpdateModelReply
	24, // 67: api.ai.v1.Model.DeleteModel:output_type -> api.ai.v1.DeleteModelReply
	26, // 68: api.ai.v1.Model.ListModels:output_type -> api.ai.v1.ListModelsReply
	28, // 69: api.ai.v1.Model.GetModel:output_type -> api.ai.v1.GetModelReply
	30, // 70: api.ai.v1.Model.SwitchModel:output_type -> api.ai.v1.SwitchModelReply
	32, // 71: api.ai.v1.Model.GetUserQuota:output_type -> api.ai.v1.GetUserQuotaReply
	34, // 72: api.ai.v1.Model.UpdateUserQuota:output_type -> api.ai.v1.UpdateUserQuotaReply
	36, // 73: api.ai.v1.Model.GetUsageStats:output_type -> api.ai.v1.GetUsageStatsReply
	38, // 74: api.ai.v1.Model.ResetUsage:output_type -> api.ai.v1.ResetUsageReply
	40, // 75: api.ai.v1.Model.CheckRateLimit:output_type -> api.ai.v1.CheckRateLimitReply
	42, // 76: api.ai.v1.Model.GetRateLimitConfig:output_type -> api.ai.v1.GetRateLimitConfigReply
	44, // 77: api.ai.v1.Model.UpdateRateLimitConfig:output_type -> api.ai.v1.UpdateRateLimitConfigReply
	46, // 78: api.ai.v1.Model.HealthCheck:output_type -> api.ai.v1.HealthCheckReply
	48, // 79: api.ai.v1.Model.GetModelMetrics:output_type -> api.ai.v1.GetModelMetricsReply
	60, // [60:80] is the sub-list for method output_type
	40, // [40:60] is the sub-list for method input_type
	40, // [40:40] is the sub-list for extension type_name
	40, // [40:40] is the sub-list for extension extendee
	0,  // [0:40] is the sub-list for field type_name
}

func init() { file_api_ai_v1_model_proto_init() }
func file_api_ai_v1_model_proto_init() {
	if File_api_ai_v1_model_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_ai_v1_model_proto_rawDesc), len(file_api_ai_v1_model_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   58,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_api_ai_v1_model_proto_goTypes,
		DependencyIndexes: file_api_ai_v1_model_proto_depIdxs,
		MessageInfos:      file_api_ai_v1_model_proto_msgTypes,
	}.Build()
	File_api_ai_v1_model_proto = out.File
	file_api_ai_v1_model_proto_goTypes = nil
	file_api_ai_v1_model_proto_depIdxs = nil
}
