// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.8
// 	protoc        v6.32.0
// source: api/ai/v1/ai.proto

package v1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// 时间粒度枚举
type AnalyticsGranularity int32

const (
	AnalyticsGranularity_ANALYTICS_GRANULARITY_UNSPECIFIED AnalyticsGranularity = 0
	AnalyticsGranularity_ANALYTICS_GRANULARITY_HOUR        AnalyticsGranularity = 1 // 小时
	AnalyticsGranularity_ANALYTICS_GRANULARITY_DAY         AnalyticsGranularity = 2 // 天
	AnalyticsGranularity_ANALYTICS_GRANULARITY_WEEK        AnalyticsGranularity = 3 // 周
	AnalyticsGranularity_ANALYTICS_GRANULARITY_MONTH       AnalyticsGranularity = 4 // 月
)

// Enum value maps for AnalyticsGranularity.
var (
	AnalyticsGranularity_name = map[int32]string{
		0: "ANALYTICS_GRANULARITY_UNSPECIFIED",
		1: "ANALYTICS_GRANULARITY_HOUR",
		2: "ANALYTICS_GRANULARITY_DAY",
		3: "ANALYTICS_GRANULARITY_WEEK",
		4: "ANALYTICS_GRANULARITY_MONTH",
	}
	AnalyticsGranularity_value = map[string]int32{
		"ANALYTICS_GRANULARITY_UNSPECIFIED": 0,
		"ANALYTICS_GRANULARITY_HOUR":        1,
		"ANALYTICS_GRANULARITY_DAY":         2,
		"ANALYTICS_GRANULARITY_WEEK":        3,
		"ANALYTICS_GRANULARITY_MONTH":       4,
	}
)

func (x AnalyticsGranularity) Enum() *AnalyticsGranularity {
	p := new(AnalyticsGranularity)
	*p = x
	return p
}

func (x AnalyticsGranularity) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AnalyticsGranularity) Descriptor() protoreflect.EnumDescriptor {
	return file_api_ai_v1_ai_proto_enumTypes[0].Descriptor()
}

func (AnalyticsGranularity) Type() protoreflect.EnumType {
	return &file_api_ai_v1_ai_proto_enumTypes[0]
}

func (x AnalyticsGranularity) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AnalyticsGranularity.Descriptor instead.
func (AnalyticsGranularity) EnumDescriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{0}
}

// 分析指标枚举
type AnalyticsMetric int32

const (
	AnalyticsMetric_ANALYTICS_METRIC_UNSPECIFIED        AnalyticsMetric = 0
	AnalyticsMetric_ANALYTICS_METRIC_CONVERSATION_COUNT AnalyticsMetric = 1 // 对话数量
	AnalyticsMetric_ANALYTICS_METRIC_MESSAGE_COUNT      AnalyticsMetric = 2 // 消息数量
	AnalyticsMetric_ANALYTICS_METRIC_TOKEN_USAGE        AnalyticsMetric = 3 // Token使用量
	AnalyticsMetric_ANALYTICS_METRIC_RESPONSE_TIME      AnalyticsMetric = 4 // 响应时间
	AnalyticsMetric_ANALYTICS_METRIC_USER_ENGAGEMENT    AnalyticsMetric = 5 // 用户参与度
	AnalyticsMetric_ANALYTICS_METRIC_TOOL_USAGE         AnalyticsMetric = 6 // 工具使用情况
)

// Enum value maps for AnalyticsMetric.
var (
	AnalyticsMetric_name = map[int32]string{
		0: "ANALYTICS_METRIC_UNSPECIFIED",
		1: "ANALYTICS_METRIC_CONVERSATION_COUNT",
		2: "ANALYTICS_METRIC_MESSAGE_COUNT",
		3: "ANALYTICS_METRIC_TOKEN_USAGE",
		4: "ANALYTICS_METRIC_RESPONSE_TIME",
		5: "ANALYTICS_METRIC_USER_ENGAGEMENT",
		6: "ANALYTICS_METRIC_TOOL_USAGE",
	}
	AnalyticsMetric_value = map[string]int32{
		"ANALYTICS_METRIC_UNSPECIFIED":        0,
		"ANALYTICS_METRIC_CONVERSATION_COUNT": 1,
		"ANALYTICS_METRIC_MESSAGE_COUNT":      2,
		"ANALYTICS_METRIC_TOKEN_USAGE":        3,
		"ANALYTICS_METRIC_RESPONSE_TIME":      4,
		"ANALYTICS_METRIC_USER_ENGAGEMENT":    5,
		"ANALYTICS_METRIC_TOOL_USAGE":         6,
	}
)

func (x AnalyticsMetric) Enum() *AnalyticsMetric {
	p := new(AnalyticsMetric)
	*p = x
	return p
}

func (x AnalyticsMetric) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AnalyticsMetric) Descriptor() protoreflect.EnumDescriptor {
	return file_api_ai_v1_ai_proto_enumTypes[1].Descriptor()
}

func (AnalyticsMetric) Type() protoreflect.EnumType {
	return &file_api_ai_v1_ai_proto_enumTypes[1]
}

func (x AnalyticsMetric) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AnalyticsMetric.Descriptor instead.
func (AnalyticsMetric) EnumDescriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{1}
}

// 趋势指标枚举
type TrendMetric int32

const (
	TrendMetric_TREND_METRIC_UNSPECIFIED       TrendMetric = 0
	TrendMetric_TREND_METRIC_ACTIVE_USERS      TrendMetric = 1 // 活跃用户数
	TrendMetric_TREND_METRIC_NEW_CONVERSATIONS TrendMetric = 2 // 新对话数
	TrendMetric_TREND_METRIC_MESSAGE_VOLUME    TrendMetric = 3 // 消息量
	TrendMetric_TREND_METRIC_TOKEN_CONSUMPTION TrendMetric = 4 // Token消耗
	TrendMetric_TREND_METRIC_COST              TrendMetric = 5 // 成本
)

// Enum value maps for TrendMetric.
var (
	TrendMetric_name = map[int32]string{
		0: "TREND_METRIC_UNSPECIFIED",
		1: "TREND_METRIC_ACTIVE_USERS",
		2: "TREND_METRIC_NEW_CONVERSATIONS",
		3: "TREND_METRIC_MESSAGE_VOLUME",
		4: "TREND_METRIC_TOKEN_CONSUMPTION",
		5: "TREND_METRIC_COST",
	}
	TrendMetric_value = map[string]int32{
		"TREND_METRIC_UNSPECIFIED":       0,
		"TREND_METRIC_ACTIVE_USERS":      1,
		"TREND_METRIC_NEW_CONVERSATIONS": 2,
		"TREND_METRIC_MESSAGE_VOLUME":    3,
		"TREND_METRIC_TOKEN_CONSUMPTION": 4,
		"TREND_METRIC_COST":              5,
	}
)

func (x TrendMetric) Enum() *TrendMetric {
	p := new(TrendMetric)
	*p = x
	return p
}

func (x TrendMetric) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (TrendMetric) Descriptor() protoreflect.EnumDescriptor {
	return file_api_ai_v1_ai_proto_enumTypes[2].Descriptor()
}

func (TrendMetric) Type() protoreflect.EnumType {
	return &file_api_ai_v1_ai_proto_enumTypes[2]
}

func (x TrendMetric) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use TrendMetric.Descriptor instead.
func (TrendMetric) EnumDescriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{2}
}

// 话题分析方法枚举
type TopicAnalysisMethod int32

const (
	TopicAnalysisMethod_TOPIC_ANALYSIS_METHOD_UNSPECIFIED TopicAnalysisMethod = 0
	TopicAnalysisMethod_TOPIC_ANALYSIS_METHOD_KEYWORD     TopicAnalysisMethod = 1 // 关键词分析
	TopicAnalysisMethod_TOPIC_ANALYSIS_METHOD_LDA         TopicAnalysisMethod = 2 // LDA主题模型
	TopicAnalysisMethod_TOPIC_ANALYSIS_METHOD_CLUSTERING  TopicAnalysisMethod = 3 // 聚类分析
	TopicAnalysisMethod_TOPIC_ANALYSIS_METHOD_SEMANTIC    TopicAnalysisMethod = 4 // 语义分析
)

// Enum value maps for TopicAnalysisMethod.
var (
	TopicAnalysisMethod_name = map[int32]string{
		0: "TOPIC_ANALYSIS_METHOD_UNSPECIFIED",
		1: "TOPIC_ANALYSIS_METHOD_KEYWORD",
		2: "TOPIC_ANALYSIS_METHOD_LDA",
		3: "TOPIC_ANALYSIS_METHOD_CLUSTERING",
		4: "TOPIC_ANALYSIS_METHOD_SEMANTIC",
	}
	TopicAnalysisMethod_value = map[string]int32{
		"TOPIC_ANALYSIS_METHOD_UNSPECIFIED": 0,
		"TOPIC_ANALYSIS_METHOD_KEYWORD":     1,
		"TOPIC_ANALYSIS_METHOD_LDA":         2,
		"TOPIC_ANALYSIS_METHOD_CLUSTERING":  3,
		"TOPIC_ANALYSIS_METHOD_SEMANTIC":    4,
	}
)

func (x TopicAnalysisMethod) Enum() *TopicAnalysisMethod {
	p := new(TopicAnalysisMethod)
	*p = x
	return p
}

func (x TopicAnalysisMethod) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (TopicAnalysisMethod) Descriptor() protoreflect.EnumDescriptor {
	return file_api_ai_v1_ai_proto_enumTypes[3].Descriptor()
}

func (TopicAnalysisMethod) Type() protoreflect.EnumType {
	return &file_api_ai_v1_ai_proto_enumTypes[3]
}

func (x TopicAnalysisMethod) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use TopicAnalysisMethod.Descriptor instead.
func (TopicAnalysisMethod) EnumDescriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{3}
}

// 对话统计分析请求
type GetConversationAnalyticsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                                              // 用户ID，为空则分析全局数据
	StartTime     *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`                                                      // 开始时间
	EndTime       *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`                                                            // 结束时间
	Granularity   AnalyticsGranularity   `protobuf:"varint,4,opt,name=granularity,proto3,enum=api.ai.v1.AnalyticsGranularity" json:"granularity,omitempty"`                              // 时间粒度
	Metrics       []AnalyticsMetric      `protobuf:"varint,5,rep,packed,name=metrics,proto3,enum=api.ai.v1.AnalyticsMetric" json:"metrics,omitempty"`                                    // 需要的指标
	Filters       map[string]string      `protobuf:"bytes,6,rep,name=filters,proto3" json:"filters,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 过滤条件
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetConversationAnalyticsRequest) Reset() {
	*x = GetConversationAnalyticsRequest{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetConversationAnalyticsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetConversationAnalyticsRequest) ProtoMessage() {}

func (x *GetConversationAnalyticsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetConversationAnalyticsRequest.ProtoReflect.Descriptor instead.
func (*GetConversationAnalyticsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{0}
}

func (x *GetConversationAnalyticsRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *GetConversationAnalyticsRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetConversationAnalyticsRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetConversationAnalyticsRequest) GetGranularity() AnalyticsGranularity {
	if x != nil {
		return x.Granularity
	}
	return AnalyticsGranularity_ANALYTICS_GRANULARITY_UNSPECIFIED
}

func (x *GetConversationAnalyticsRequest) GetMetrics() []AnalyticsMetric {
	if x != nil {
		return x.Metrics
	}
	return nil
}

func (x *GetConversationAnalyticsRequest) GetFilters() map[string]string {
	if x != nil {
		return x.Filters
	}
	return nil
}

type GetConversationAnalyticsReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Analytics     *ConversationAnalytics `protobuf:"bytes,1,opt,name=analytics,proto3" json:"analytics,omitempty"` // 分析结果
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetConversationAnalyticsReply) Reset() {
	*x = GetConversationAnalyticsReply{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetConversationAnalyticsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetConversationAnalyticsReply) ProtoMessage() {}

func (x *GetConversationAnalyticsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetConversationAnalyticsReply.ProtoReflect.Descriptor instead.
func (*GetConversationAnalyticsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{1}
}

func (x *GetConversationAnalyticsReply) GetAnalytics() *ConversationAnalytics {
	if x != nil {
		return x.Analytics
	}
	return nil
}

// 用户使用统计请求
type GetUserUsageStatsRequest struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	UserId               int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                             // 用户ID
	StartTime            *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`                                     // 开始时间
	EndTime              *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`                                           // 结束时间
	IncludeCostBreakdown bool                   `protobuf:"varint,4,opt,name=include_cost_breakdown,json=includeCostBreakdown,proto3" json:"include_cost_breakdown,omitempty"` // 是否包含成本明细
	IncludeModelUsage    bool                   `protobuf:"varint,5,opt,name=include_model_usage,json=includeModelUsage,proto3" json:"include_model_usage,omitempty"`          // 是否包含模型使用情况
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *GetUserUsageStatsRequest) Reset() {
	*x = GetUserUsageStatsRequest{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetUserUsageStatsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetUserUsageStatsRequest) ProtoMessage() {}

func (x *GetUserUsageStatsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetUserUsageStatsRequest.ProtoReflect.Descriptor instead.
func (*GetUserUsageStatsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{2}
}

func (x *GetUserUsageStatsRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *GetUserUsageStatsRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetUserUsageStatsRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetUserUsageStatsRequest) GetIncludeCostBreakdown() bool {
	if x != nil {
		return x.IncludeCostBreakdown
	}
	return false
}

func (x *GetUserUsageStatsRequest) GetIncludeModelUsage() bool {
	if x != nil {
		return x.IncludeModelUsage
	}
	return false
}

type GetUserUsageStatsReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UsageStats    *UserUsageStats        `protobuf:"bytes,1,opt,name=usage_stats,json=usageStats,proto3" json:"usage_stats,omitempty"` // 使用统计
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetUserUsageStatsReply) Reset() {
	*x = GetUserUsageStatsReply{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetUserUsageStatsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetUserUsageStatsReply) ProtoMessage() {}

func (x *GetUserUsageStatsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetUserUsageStatsReply.ProtoReflect.Descriptor instead.
func (*GetUserUsageStatsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{3}
}

func (x *GetUserUsageStatsReply) GetUsageStats() *UserUsageStats {
	if x != nil {
		return x.UsageStats
	}
	return nil
}

// 模型性能统计请求
type GetModelPerformanceStatsRequest struct {
	state                   protoimpl.MessageState `protogen:"open.v1"`
	ModelNames              []string               `protobuf:"bytes,1,rep,name=model_names,json=modelNames,proto3" json:"model_names,omitempty"`                                           // 模型名称列表，为空则分析所有模型
	StartTime               *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`                                              // 开始时间
	EndTime                 *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`                                                    // 结束时间
	IncludeUserSatisfaction bool                   `protobuf:"varint,4,opt,name=include_user_satisfaction,json=includeUserSatisfaction,proto3" json:"include_user_satisfaction,omitempty"` // 是否包含用户满意度
	IncludeErrorAnalysis    bool                   `protobuf:"varint,5,opt,name=include_error_analysis,json=includeErrorAnalysis,proto3" json:"include_error_analysis,omitempty"`          // 是否包含错误分析
	unknownFields           protoimpl.UnknownFields
	sizeCache               protoimpl.SizeCache
}

func (x *GetModelPerformanceStatsRequest) Reset() {
	*x = GetModelPerformanceStatsRequest{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelPerformanceStatsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelPerformanceStatsRequest) ProtoMessage() {}

func (x *GetModelPerformanceStatsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelPerformanceStatsRequest.ProtoReflect.Descriptor instead.
func (*GetModelPerformanceStatsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{4}
}

func (x *GetModelPerformanceStatsRequest) GetModelNames() []string {
	if x != nil {
		return x.ModelNames
	}
	return nil
}

func (x *GetModelPerformanceStatsRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetModelPerformanceStatsRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetModelPerformanceStatsRequest) GetIncludeUserSatisfaction() bool {
	if x != nil {
		return x.IncludeUserSatisfaction
	}
	return false
}

func (x *GetModelPerformanceStatsRequest) GetIncludeErrorAnalysis() bool {
	if x != nil {
		return x.IncludeErrorAnalysis
	}
	return false
}

type GetModelPerformanceStatsReply struct {
	state         protoimpl.MessageState   `protogen:"open.v1"`
	ModelStats    []*ModelPerformanceStats `protobuf:"bytes,1,rep,name=model_stats,json=modelStats,proto3" json:"model_stats,omitempty"` // 模型统计列表
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelPerformanceStatsReply) Reset() {
	*x = GetModelPerformanceStatsReply{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelPerformanceStatsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelPerformanceStatsReply) ProtoMessage() {}

func (x *GetModelPerformanceStatsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelPerformanceStatsReply.ProtoReflect.Descriptor instead.
func (*GetModelPerformanceStatsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{5}
}

func (x *GetModelPerformanceStatsReply) GetModelStats() []*ModelPerformanceStats {
	if x != nil {
		return x.ModelStats
	}
	return nil
}

// 对话趋势分析请求
type GetConversationTrendsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	UserId        int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                                     // 用户ID，为空则分析全局趋势
	StartTime     *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`                                             // 开始时间
	EndTime       *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`                                                   // 结束时间
	Granularity   AnalyticsGranularity   `protobuf:"varint,4,opt,name=granularity,proto3,enum=api.ai.v1.AnalyticsGranularity" json:"granularity,omitempty"`                     // 时间粒度
	TrendMetrics  []TrendMetric          `protobuf:"varint,5,rep,packed,name=trend_metrics,json=trendMetrics,proto3,enum=api.ai.v1.TrendMetric" json:"trend_metrics,omitempty"` // 趋势指标
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetConversationTrendsRequest) Reset() {
	*x = GetConversationTrendsRequest{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetConversationTrendsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetConversationTrendsRequest) ProtoMessage() {}

func (x *GetConversationTrendsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetConversationTrendsRequest.ProtoReflect.Descriptor instead.
func (*GetConversationTrendsRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{6}
}

func (x *GetConversationTrendsRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *GetConversationTrendsRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetConversationTrendsRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetConversationTrendsRequest) GetGranularity() AnalyticsGranularity {
	if x != nil {
		return x.Granularity
	}
	return AnalyticsGranularity_ANALYTICS_GRANULARITY_UNSPECIFIED
}

func (x *GetConversationTrendsRequest) GetTrendMetrics() []TrendMetric {
	if x != nil {
		return x.TrendMetrics
	}
	return nil
}

type GetConversationTrendsReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Trends        []*TrendData           `protobuf:"bytes,1,rep,name=trends,proto3" json:"trends,omitempty"` // 趋势数据
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetConversationTrendsReply) Reset() {
	*x = GetConversationTrendsReply{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetConversationTrendsReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetConversationTrendsReply) ProtoMessage() {}

func (x *GetConversationTrendsReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetConversationTrendsReply.ProtoReflect.Descriptor instead.
func (*GetConversationTrendsReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{7}
}

func (x *GetConversationTrendsReply) GetTrends() []*TrendData {
	if x != nil {
		return x.Trends
	}
	return nil
}

// 话题分析请求
type GetTopicAnalysisRequest struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	UserId         int64                  `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                                              // 用户ID，为空则分析全局话题
	StartTime      *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`                                                      // 开始时间
	EndTime        *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`                                                            // 结束时间
	TopTopicsCount int32                  `protobuf:"varint,4,opt,name=top_topics_count,json=topTopicsCount,proto3" json:"top_topics_count,omitempty"`                                    // 返回热门话题数量
	Method         TopicAnalysisMethod    `protobuf:"varint,5,opt,name=method,proto3,enum=api.ai.v1.TopicAnalysisMethod" json:"method,omitempty"`                                         // 分析方法
	Filters        map[string]string      `protobuf:"bytes,6,rep,name=filters,proto3" json:"filters,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 过滤条件
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *GetTopicAnalysisRequest) Reset() {
	*x = GetTopicAnalysisRequest{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetTopicAnalysisRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetTopicAnalysisRequest) ProtoMessage() {}

func (x *GetTopicAnalysisRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetTopicAnalysisRequest.ProtoReflect.Descriptor instead.
func (*GetTopicAnalysisRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{8}
}

func (x *GetTopicAnalysisRequest) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *GetTopicAnalysisRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetTopicAnalysisRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetTopicAnalysisRequest) GetTopTopicsCount() int32 {
	if x != nil {
		return x.TopTopicsCount
	}
	return 0
}

func (x *GetTopicAnalysisRequest) GetMethod() TopicAnalysisMethod {
	if x != nil {
		return x.Method
	}
	return TopicAnalysisMethod_TOPIC_ANALYSIS_METHOD_UNSPECIFIED
}

func (x *GetTopicAnalysisRequest) GetFilters() map[string]string {
	if x != nil {
		return x.Filters
	}
	return nil
}

type GetTopicAnalysisReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Topics        []*TopicInsight        `protobuf:"bytes,1,rep,name=topics,proto3" json:"topics,omitempty"`             // 话题洞察
	Distribution  *TopicDistribution     `protobuf:"bytes,2,opt,name=distribution,proto3" json:"distribution,omitempty"` // 话题分布
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetTopicAnalysisReply) Reset() {
	*x = GetTopicAnalysisReply{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetTopicAnalysisReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetTopicAnalysisReply) ProtoMessage() {}

func (x *GetTopicAnalysisReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetTopicAnalysisReply.ProtoReflect.Descriptor instead.
func (*GetTopicAnalysisReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{9}
}

func (x *GetTopicAnalysisReply) GetTopics() []*TopicInsight {
	if x != nil {
		return x.Topics
	}
	return nil
}

func (x *GetTopicAnalysisReply) GetDistribution() *TopicDistribution {
	if x != nil {
		return x.Distribution
	}
	return nil
}

// 系统总览请求
type GetSystemOverviewRequest struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	StartTime            *timestamppb.Timestamp `protobuf:"bytes,1,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`                                     // 开始时间
	EndTime              *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`                                           // 结束时间
	IncludeHealthMetrics bool                   `protobuf:"varint,3,opt,name=include_health_metrics,json=includeHealthMetrics,proto3" json:"include_health_metrics,omitempty"` // 是否包含健康指标
	IncludeResourceUsage bool                   `protobuf:"varint,4,opt,name=include_resource_usage,json=includeResourceUsage,proto3" json:"include_resource_usage,omitempty"` // 是否包含资源使用情况
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *GetSystemOverviewRequest) Reset() {
	*x = GetSystemOverviewRequest{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetSystemOverviewRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetSystemOverviewRequest) ProtoMessage() {}

func (x *GetSystemOverviewRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetSystemOverviewRequest.ProtoReflect.Descriptor instead.
func (*GetSystemOverviewRequest) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{10}
}

func (x *GetSystemOverviewRequest) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *GetSystemOverviewRequest) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *GetSystemOverviewRequest) GetIncludeHealthMetrics() bool {
	if x != nil {
		return x.IncludeHealthMetrics
	}
	return false
}

func (x *GetSystemOverviewRequest) GetIncludeResourceUsage() bool {
	if x != nil {
		return x.IncludeResourceUsage
	}
	return false
}

type GetSystemOverviewReply struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Overview      *SystemOverviewStats   `protobuf:"bytes,1,opt,name=overview,proto3" json:"overview,omitempty"` // 系统总览
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetSystemOverviewReply) Reset() {
	*x = GetSystemOverviewReply{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetSystemOverviewReply) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetSystemOverviewReply) ProtoMessage() {}

func (x *GetSystemOverviewReply) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetSystemOverviewReply.ProtoReflect.Descriptor instead.
func (*GetSystemOverviewReply) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{11}
}

func (x *GetSystemOverviewReply) GetOverview() *SystemOverviewStats {
	if x != nil {
		return x.Overview
	}
	return nil
}

// 对话分析数据
type ConversationAnalytics struct {
	state                     protoimpl.MessageState `protogen:"open.v1"`
	TotalConversations        int64                  `protobuf:"varint,1,opt,name=total_conversations,json=totalConversations,proto3" json:"total_conversations,omitempty"`                                                                                         // 总对话数
	ActiveUsers               int64                  `protobuf:"varint,2,opt,name=active_users,json=activeUsers,proto3" json:"active_users,omitempty"`                                                                                                              // 活跃用户数
	AverageConversationLength float64                `protobuf:"fixed64,3,opt,name=average_conversation_length,json=averageConversationLength,proto3" json:"average_conversation_length,omitempty"`                                                                 // 平均对话长度
	AverageResponseTime       float64                `protobuf:"fixed64,4,opt,name=average_response_time,json=averageResponseTime,proto3" json:"average_response_time,omitempty"`                                                                                   // 平均响应时间
	ModelUsageDistribution    map[string]int64       `protobuf:"bytes,5,rep,name=model_usage_distribution,json=modelUsageDistribution,proto3" json:"model_usage_distribution,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"varint,2,opt,name=value"` // 模型使用分布
	TimeDistribution          map[string]int64       `protobuf:"bytes,6,rep,name=time_distribution,json=timeDistribution,proto3" json:"time_distribution,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"varint,2,opt,name=value"`                     // 时间分布
	TimeSeriesData            []*TimeSeriesPoint     `protobuf:"bytes,7,rep,name=time_series_data,json=timeSeriesData,proto3" json:"time_series_data,omitempty"`                                                                                                    // 时序数据
	Engagement                *UserEngagementMetrics `protobuf:"bytes,8,opt,name=engagement,proto3" json:"engagement,omitempty"`                                                                                                                                    // 用户参与度指标
	unknownFields             protoimpl.UnknownFields
	sizeCache                 protoimpl.SizeCache
}

func (x *ConversationAnalytics) Reset() {
	*x = ConversationAnalytics{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConversationAnalytics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConversationAnalytics) ProtoMessage() {}

func (x *ConversationAnalytics) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConversationAnalytics.ProtoReflect.Descriptor instead.
func (*ConversationAnalytics) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{12}
}

func (x *ConversationAnalytics) GetTotalConversations() int64 {
	if x != nil {
		return x.TotalConversations
	}
	return 0
}

func (x *ConversationAnalytics) GetActiveUsers() int64 {
	if x != nil {
		return x.ActiveUsers
	}
	return 0
}

func (x *ConversationAnalytics) GetAverageConversationLength() float64 {
	if x != nil {
		return x.AverageConversationLength
	}
	return 0
}

func (x *ConversationAnalytics) GetAverageResponseTime() float64 {
	if x != nil {
		return x.AverageResponseTime
	}
	return 0
}

func (x *ConversationAnalytics) GetModelUsageDistribution() map[string]int64 {
	if x != nil {
		return x.ModelUsageDistribution
	}
	return nil
}

func (x *ConversationAnalytics) GetTimeDistribution() map[string]int64 {
	if x != nil {
		return x.TimeDistribution
	}
	return nil
}

func (x *ConversationAnalytics) GetTimeSeriesData() []*TimeSeriesPoint {
	if x != nil {
		return x.TimeSeriesData
	}
	return nil
}

func (x *ConversationAnalytics) GetEngagement() *UserEngagementMetrics {
	if x != nil {
		return x.Engagement
	}
	return nil
}

// 用户使用统计
type UserUsageStats struct {
	state                  protoimpl.MessageState      `protogen:"open.v1"`
	UserId                 int64                       `protobuf:"varint,1,opt,name=user_id,json=userId,proto3" json:"user_id,omitempty"`                                                                                                 // 用户ID
	TotalConversations     int64                       `protobuf:"varint,2,opt,name=total_conversations,json=totalConversations,proto3" json:"total_conversations,omitempty"`                                                             // 总对话数
	TotalMessages          int64                       `protobuf:"varint,3,opt,name=total_messages,json=totalMessages,proto3" json:"total_messages,omitempty"`                                                                            // 总消息数
	TotalInputTokens       int64                       `protobuf:"varint,4,opt,name=total_input_tokens,json=totalInputTokens,proto3" json:"total_input_tokens,omitempty"`                                                                 // 总输入Token
	TotalOutputTokens      int64                       `protobuf:"varint,5,opt,name=total_output_tokens,json=totalOutputTokens,proto3" json:"total_output_tokens,omitempty"`                                                              // 总输出Token
	TotalCost              float64                     `protobuf:"fixed64,6,opt,name=total_cost,json=totalCost,proto3" json:"total_cost,omitempty"`                                                                                       // 总成本
	AverageSessionDuration float64                     `protobuf:"fixed64,7,opt,name=average_session_duration,json=averageSessionDuration,proto3" json:"average_session_duration,omitempty"`                                              // 平均会话时长
	ModelUsage             map[string]*ModelUsageStats `protobuf:"bytes,8,rep,name=model_usage,json=modelUsage,proto3" json:"model_usage,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`            // 各模型使用情况
	CostBreakdown          map[string]float64          `protobuf:"bytes,9,rep,name=cost_breakdown,json=costBreakdown,proto3" json:"cost_breakdown,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"` // 成本明细
	UsageTimeline          []*UsageTimePoint           `protobuf:"bytes,10,rep,name=usage_timeline,json=usageTimeline,proto3" json:"usage_timeline,omitempty"`                                                                            // 使用时间线
	BehaviorProfile        *UserBehaviorProfile        `protobuf:"bytes,11,opt,name=behavior_profile,json=behaviorProfile,proto3" json:"behavior_profile,omitempty"`                                                                      // 用户行为画像
	unknownFields          protoimpl.UnknownFields
	sizeCache              protoimpl.SizeCache
}

func (x *UserUsageStats) Reset() {
	*x = UserUsageStats{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UserUsageStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UserUsageStats) ProtoMessage() {}

func (x *UserUsageStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UserUsageStats.ProtoReflect.Descriptor instead.
func (*UserUsageStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{13}
}

func (x *UserUsageStats) GetUserId() int64 {
	if x != nil {
		return x.UserId
	}
	return 0
}

func (x *UserUsageStats) GetTotalConversations() int64 {
	if x != nil {
		return x.TotalConversations
	}
	return 0
}

func (x *UserUsageStats) GetTotalMessages() int64 {
	if x != nil {
		return x.TotalMessages
	}
	return 0
}

func (x *UserUsageStats) GetTotalInputTokens() int64 {
	if x != nil {
		return x.TotalInputTokens
	}
	return 0
}

func (x *UserUsageStats) GetTotalOutputTokens() int64 {
	if x != nil {
		return x.TotalOutputTokens
	}
	return 0
}

func (x *UserUsageStats) GetTotalCost() float64 {
	if x != nil {
		return x.TotalCost
	}
	return 0
}

func (x *UserUsageStats) GetAverageSessionDuration() float64 {
	if x != nil {
		return x.AverageSessionDuration
	}
	return 0
}

func (x *UserUsageStats) GetModelUsage() map[string]*ModelUsageStats {
	if x != nil {
		return x.ModelUsage
	}
	return nil
}

func (x *UserUsageStats) GetCostBreakdown() map[string]float64 {
	if x != nil {
		return x.CostBreakdown
	}
	return nil
}

func (x *UserUsageStats) GetUsageTimeline() []*UsageTimePoint {
	if x != nil {
		return x.UsageTimeline
	}
	return nil
}

func (x *UserUsageStats) GetBehaviorProfile() *UserBehaviorProfile {
	if x != nil {
		return x.BehaviorProfile
	}
	return nil
}

// 模型性能统计
type ModelPerformanceStats struct {
	state                 protoimpl.MessageState  `protogen:"open.v1"`
	ModelName             string                  `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`                                                                                                    // 模型名称
	TotalRequests         int64                   `protobuf:"varint,2,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"`                                                                                       // 总请求数
	SuccessRate           float64                 `protobuf:"fixed64,3,opt,name=success_rate,json=successRate,proto3" json:"success_rate,omitempty"`                                                                                            // 成功率
	AverageResponseTime   float64                 `protobuf:"fixed64,4,opt,name=average_response_time,json=averageResponseTime,proto3" json:"average_response_time,omitempty"`                                                                  // 平均响应时间
	AverageInputTokens    float64                 `protobuf:"fixed64,5,opt,name=average_input_tokens,json=averageInputTokens,proto3" json:"average_input_tokens,omitempty"`                                                                     // 平均输入Token数
	AverageOutputTokens   float64                 `protobuf:"fixed64,6,opt,name=average_output_tokens,json=averageOutputTokens,proto3" json:"average_output_tokens,omitempty"`                                                                  // 平均输出Token数
	CostPerRequest        float64                 `protobuf:"fixed64,7,opt,name=cost_per_request,json=costPerRequest,proto3" json:"cost_per_request,omitempty"`                                                                                 // 每请求成本
	UserSatisfactionScore float64                 `protobuf:"fixed64,8,opt,name=user_satisfaction_score,json=userSatisfactionScore,proto3" json:"user_satisfaction_score,omitempty"`                                                            // 用户满意度评分
	ErrorDistribution     map[string]int64        `protobuf:"bytes,9,rep,name=error_distribution,json=errorDistribution,proto3" json:"error_distribution,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"varint,2,opt,name=value"` // 错误分布
	PerformanceTimeline   []*PerformanceTimePoint `protobuf:"bytes,10,rep,name=performance_timeline,json=performanceTimeline,proto3" json:"performance_timeline,omitempty"`                                                                     // 性能时间线
	Capabilities          *ModelCapabilityMetrics `protobuf:"bytes,11,opt,name=capabilities,proto3" json:"capabilities,omitempty"`                                                                                                              // 能力指标
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *ModelPerformanceStats) Reset() {
	*x = ModelPerformanceStats{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelPerformanceStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelPerformanceStats) ProtoMessage() {}

func (x *ModelPerformanceStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelPerformanceStats.ProtoReflect.Descriptor instead.
func (*ModelPerformanceStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{14}
}

func (x *ModelPerformanceStats) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *ModelPerformanceStats) GetTotalRequests() int64 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *ModelPerformanceStats) GetSuccessRate() float64 {
	if x != nil {
		return x.SuccessRate
	}
	return 0
}

func (x *ModelPerformanceStats) GetAverageResponseTime() float64 {
	if x != nil {
		return x.AverageResponseTime
	}
	return 0
}

func (x *ModelPerformanceStats) GetAverageInputTokens() float64 {
	if x != nil {
		return x.AverageInputTokens
	}
	return 0
}

func (x *ModelPerformanceStats) GetAverageOutputTokens() float64 {
	if x != nil {
		return x.AverageOutputTokens
	}
	return 0
}

func (x *ModelPerformanceStats) GetCostPerRequest() float64 {
	if x != nil {
		return x.CostPerRequest
	}
	return 0
}

func (x *ModelPerformanceStats) GetUserSatisfactionScore() float64 {
	if x != nil {
		return x.UserSatisfactionScore
	}
	return 0
}

func (x *ModelPerformanceStats) GetErrorDistribution() map[string]int64 {
	if x != nil {
		return x.ErrorDistribution
	}
	return nil
}

func (x *ModelPerformanceStats) GetPerformanceTimeline() []*PerformanceTimePoint {
	if x != nil {
		return x.PerformanceTimeline
	}
	return nil
}

func (x *ModelPerformanceStats) GetCapabilities() *ModelCapabilityMetrics {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

// 趋势数据
type TrendData struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	Metric         TrendMetric            `protobuf:"varint,1,opt,name=metric,proto3,enum=api.ai.v1.TrendMetric" json:"metric,omitempty"`           // 指标类型
	DataPoints     []*TimeSeriesPoint     `protobuf:"bytes,2,rep,name=data_points,json=dataPoints,proto3" json:"data_points,omitempty"`             // 数据点
	GrowthRate     float64                `protobuf:"fixed64,3,opt,name=growth_rate,json=growthRate,proto3" json:"growth_rate,omitempty"`           // 增长率
	TrendDirection string                 `protobuf:"bytes,4,opt,name=trend_direction,json=trendDirection,proto3" json:"trend_direction,omitempty"` // 趋势方向: up/down/stable
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *TrendData) Reset() {
	*x = TrendData{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TrendData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TrendData) ProtoMessage() {}

func (x *TrendData) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TrendData.ProtoReflect.Descriptor instead.
func (*TrendData) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{15}
}

func (x *TrendData) GetMetric() TrendMetric {
	if x != nil {
		return x.Metric
	}
	return TrendMetric_TREND_METRIC_UNSPECIFIED
}

func (x *TrendData) GetDataPoints() []*TimeSeriesPoint {
	if x != nil {
		return x.DataPoints
	}
	return nil
}

func (x *TrendData) GetGrowthRate() float64 {
	if x != nil {
		return x.GrowthRate
	}
	return 0
}

func (x *TrendData) GetTrendDirection() string {
	if x != nil {
		return x.TrendDirection
	}
	return ""
}

// 话题洞察
type TopicInsight struct {
	state                  protoimpl.MessageState `protogen:"open.v1"`
	TopicName              string                 `protobuf:"bytes,1,opt,name=topic_name,json=topicName,proto3" json:"topic_name,omitempty"`                                        // 话题名称
	Keywords               []string               `protobuf:"bytes,2,rep,name=keywords,proto3" json:"keywords,omitempty"`                                                           // 关键词
	MessageCount           int64                  `protobuf:"varint,3,opt,name=message_count,json=messageCount,proto3" json:"message_count,omitempty"`                              // 消息数量
	RelevanceScore         float64                `protobuf:"fixed64,4,opt,name=relevance_score,json=relevanceScore,proto3" json:"relevance_score,omitempty"`                       // 相关度分数
	SentimentScore         float64                `protobuf:"fixed64,5,opt,name=sentiment_score,json=sentimentScore,proto3" json:"sentiment_score,omitempty"`                       // 情感分数
	RepresentativeMessages []string               `protobuf:"bytes,6,rep,name=representative_messages,json=representativeMessages,proto3" json:"representative_messages,omitempty"` // 代表性消息
	FirstSeen              *timestamppb.Timestamp `protobuf:"bytes,7,opt,name=first_seen,json=firstSeen,proto3" json:"first_seen,omitempty"`                                        // 首次出现时间
	LastSeen               *timestamppb.Timestamp `protobuf:"bytes,8,opt,name=last_seen,json=lastSeen,proto3" json:"last_seen,omitempty"`                                           // 最后出现时间
	unknownFields          protoimpl.UnknownFields
	sizeCache              protoimpl.SizeCache
}

func (x *TopicInsight) Reset() {
	*x = TopicInsight{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TopicInsight) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TopicInsight) ProtoMessage() {}

func (x *TopicInsight) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TopicInsight.ProtoReflect.Descriptor instead.
func (*TopicInsight) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{16}
}

func (x *TopicInsight) GetTopicName() string {
	if x != nil {
		return x.TopicName
	}
	return ""
}

func (x *TopicInsight) GetKeywords() []string {
	if x != nil {
		return x.Keywords
	}
	return nil
}

func (x *TopicInsight) GetMessageCount() int64 {
	if x != nil {
		return x.MessageCount
	}
	return 0
}

func (x *TopicInsight) GetRelevanceScore() float64 {
	if x != nil {
		return x.RelevanceScore
	}
	return 0
}

func (x *TopicInsight) GetSentimentScore() float64 {
	if x != nil {
		return x.SentimentScore
	}
	return 0
}

func (x *TopicInsight) GetRepresentativeMessages() []string {
	if x != nil {
		return x.RepresentativeMessages
	}
	return nil
}

func (x *TopicInsight) GetFirstSeen() *timestamppb.Timestamp {
	if x != nil {
		return x.FirstSeen
	}
	return nil
}

func (x *TopicInsight) GetLastSeen() *timestamppb.Timestamp {
	if x != nil {
		return x.LastSeen
	}
	return nil
}

// 话题分布
type TopicDistribution struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	TopicPercentages    map[string]float64     `protobuf:"bytes,1,rep,name=topic_percentages,json=topicPercentages,proto3" json:"topic_percentages,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"` // 话题百分比分布
	TopicDiversityIndex float64                `protobuf:"fixed64,2,opt,name=topic_diversity_index,json=topicDiversityIndex,proto3" json:"topic_diversity_index,omitempty"`                                                                // 话题多样性指数
	TotalTopicsDetected int32                  `protobuf:"varint,3,opt,name=total_topics_detected,json=totalTopicsDetected,proto3" json:"total_topics_detected,omitempty"`                                                                 // 检测到的总话题数
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *TopicDistribution) Reset() {
	*x = TopicDistribution{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TopicDistribution) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TopicDistribution) ProtoMessage() {}

func (x *TopicDistribution) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TopicDistribution.ProtoReflect.Descriptor instead.
func (*TopicDistribution) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{17}
}

func (x *TopicDistribution) GetTopicPercentages() map[string]float64 {
	if x != nil {
		return x.TopicPercentages
	}
	return nil
}

func (x *TopicDistribution) GetTopicDiversityIndex() float64 {
	if x != nil {
		return x.TopicDiversityIndex
	}
	return 0
}

func (x *TopicDistribution) GetTotalTopicsDetected() int32 {
	if x != nil {
		return x.TotalTopicsDetected
	}
	return 0
}

// 系统总览统计
type SystemOverviewStats struct {
	state                protoimpl.MessageState   `protogen:"open.v1"`
	TotalUsers           int64                    `protobuf:"varint,1,opt,name=total_users,json=totalUsers,proto3" json:"total_users,omitempty"`                                                                                // 总用户数
	ActiveUsersToday     int64                    `protobuf:"varint,2,opt,name=active_users_today,json=activeUsersToday,proto3" json:"active_users_today,omitempty"`                                                            // 今日活跃用户
	TotalConversations   int64                    `protobuf:"varint,3,opt,name=total_conversations,json=totalConversations,proto3" json:"total_conversations,omitempty"`                                                        // 总对话数
	TotalMessages        int64                    `protobuf:"varint,4,opt,name=total_messages,json=totalMessages,proto3" json:"total_messages,omitempty"`                                                                       // 总消息数
	TotalTokensProcessed int64                    `protobuf:"varint,5,opt,name=total_tokens_processed,json=totalTokensProcessed,proto3" json:"total_tokens_processed,omitempty"`                                                // 总处理Token数
	TotalCost            float64                  `protobuf:"fixed64,6,opt,name=total_cost,json=totalCost,proto3" json:"total_cost,omitempty"`                                                                                  // 总成本
	Health               *SystemHealthMetrics     `protobuf:"bytes,7,opt,name=health,proto3" json:"health,omitempty"`                                                                                                           // 系统健康指标
	ResourceUsage        *ResourceUsageStats      `protobuf:"bytes,8,opt,name=resource_usage,json=resourceUsage,proto3" json:"resource_usage,omitempty"`                                                                        // 资源使用统计
	ServiceStats         map[string]*ServiceStats `protobuf:"bytes,9,rep,name=service_stats,json=serviceStats,proto3" json:"service_stats,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // 各服务统计
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *SystemOverviewStats) Reset() {
	*x = SystemOverviewStats{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SystemOverviewStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SystemOverviewStats) ProtoMessage() {}

func (x *SystemOverviewStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SystemOverviewStats.ProtoReflect.Descriptor instead.
func (*SystemOverviewStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{18}
}

func (x *SystemOverviewStats) GetTotalUsers() int64 {
	if x != nil {
		return x.TotalUsers
	}
	return 0
}

func (x *SystemOverviewStats) GetActiveUsersToday() int64 {
	if x != nil {
		return x.ActiveUsersToday
	}
	return 0
}

func (x *SystemOverviewStats) GetTotalConversations() int64 {
	if x != nil {
		return x.TotalConversations
	}
	return 0
}

func (x *SystemOverviewStats) GetTotalMessages() int64 {
	if x != nil {
		return x.TotalMessages
	}
	return 0
}

func (x *SystemOverviewStats) GetTotalTokensProcessed() int64 {
	if x != nil {
		return x.TotalTokensProcessed
	}
	return 0
}

func (x *SystemOverviewStats) GetTotalCost() float64 {
	if x != nil {
		return x.TotalCost
	}
	return 0
}

func (x *SystemOverviewStats) GetHealth() *SystemHealthMetrics {
	if x != nil {
		return x.Health
	}
	return nil
}

func (x *SystemOverviewStats) GetResourceUsage() *ResourceUsageStats {
	if x != nil {
		return x.ResourceUsage
	}
	return nil
}

func (x *SystemOverviewStats) GetServiceStats() map[string]*ServiceStats {
	if x != nil {
		return x.ServiceStats
	}
	return nil
}

// 时序数据点
type TimeSeriesPoint struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Timestamp     *timestamppb.Timestamp `protobuf:"bytes,1,opt,name=timestamp,proto3" json:"timestamp,omitempty"`                                                                               // 时间戳
	Value         float64                `protobuf:"fixed64,2,opt,name=value,proto3" json:"value,omitempty"`                                                                                     // 数值
	Label         string                 `protobuf:"bytes,3,opt,name=label,proto3" json:"label,omitempty"`                                                                                       // 标签
	Dimensions    map[string]float64     `protobuf:"bytes,4,rep,name=dimensions,proto3" json:"dimensions,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"` // 多维数据
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TimeSeriesPoint) Reset() {
	*x = TimeSeriesPoint{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TimeSeriesPoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TimeSeriesPoint) ProtoMessage() {}

func (x *TimeSeriesPoint) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TimeSeriesPoint.ProtoReflect.Descriptor instead.
func (*TimeSeriesPoint) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{19}
}

func (x *TimeSeriesPoint) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

func (x *TimeSeriesPoint) GetValue() float64 {
	if x != nil {
		return x.Value
	}
	return 0
}

func (x *TimeSeriesPoint) GetLabel() string {
	if x != nil {
		return x.Label
	}
	return ""
}

func (x *TimeSeriesPoint) GetDimensions() map[string]float64 {
	if x != nil {
		return x.Dimensions
	}
	return nil
}

// 用户参与度指标
type UserEngagementMetrics struct {
	state                          protoimpl.MessageState `protogen:"open.v1"`
	AverageMessagesPerConversation float64                `protobuf:"fixed64,1,opt,name=average_messages_per_conversation,json=averageMessagesPerConversation,proto3" json:"average_messages_per_conversation,omitempty"` // 每对话平均消息数
	ConversationCompletionRate     float64                `protobuf:"fixed64,2,opt,name=conversation_completion_rate,json=conversationCompletionRate,proto3" json:"conversation_completion_rate,omitempty"`               // 对话完成率
	UserRetentionRate              float64                `protobuf:"fixed64,3,opt,name=user_retention_rate,json=userRetentionRate,proto3" json:"user_retention_rate,omitempty"`                                          // 用户留存率
	FeatureAdoptionRate            float64                `protobuf:"fixed64,4,opt,name=feature_adoption_rate,json=featureAdoptionRate,proto3" json:"feature_adoption_rate,omitempty"`                                    // 功能采用率
	unknownFields                  protoimpl.UnknownFields
	sizeCache                      protoimpl.SizeCache
}

func (x *UserEngagementMetrics) Reset() {
	*x = UserEngagementMetrics{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UserEngagementMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UserEngagementMetrics) ProtoMessage() {}

func (x *UserEngagementMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UserEngagementMetrics.ProtoReflect.Descriptor instead.
func (*UserEngagementMetrics) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{20}
}

func (x *UserEngagementMetrics) GetAverageMessagesPerConversation() float64 {
	if x != nil {
		return x.AverageMessagesPerConversation
	}
	return 0
}

func (x *UserEngagementMetrics) GetConversationCompletionRate() float64 {
	if x != nil {
		return x.ConversationCompletionRate
	}
	return 0
}

func (x *UserEngagementMetrics) GetUserRetentionRate() float64 {
	if x != nil {
		return x.UserRetentionRate
	}
	return 0
}

func (x *UserEngagementMetrics) GetFeatureAdoptionRate() float64 {
	if x != nil {
		return x.FeatureAdoptionRate
	}
	return 0
}

// 模型使用统计
type ModelUsageStats struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	ModelName           string                 `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`                                   // 模型名称
	RequestCount        int64                  `protobuf:"varint,2,opt,name=request_count,json=requestCount,proto3" json:"request_count,omitempty"`                         // 请求数
	InputTokens         int64                  `protobuf:"varint,3,opt,name=input_tokens,json=inputTokens,proto3" json:"input_tokens,omitempty"`                            // 输入Token数
	OutputTokens        int64                  `protobuf:"varint,4,opt,name=output_tokens,json=outputTokens,proto3" json:"output_tokens,omitempty"`                         // 输出Token数
	Cost                float64                `protobuf:"fixed64,5,opt,name=cost,proto3" json:"cost,omitempty"`                                                            // 成本
	AverageResponseTime float64                `protobuf:"fixed64,6,opt,name=average_response_time,json=averageResponseTime,proto3" json:"average_response_time,omitempty"` // 平均响应时间
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *ModelUsageStats) Reset() {
	*x = ModelUsageStats{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelUsageStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelUsageStats) ProtoMessage() {}

func (x *ModelUsageStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelUsageStats.ProtoReflect.Descriptor instead.
func (*ModelUsageStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{21}
}

func (x *ModelUsageStats) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *ModelUsageStats) GetRequestCount() int64 {
	if x != nil {
		return x.RequestCount
	}
	return 0
}

func (x *ModelUsageStats) GetInputTokens() int64 {
	if x != nil {
		return x.InputTokens
	}
	return 0
}

func (x *ModelUsageStats) GetOutputTokens() int64 {
	if x != nil {
		return x.OutputTokens
	}
	return 0
}

func (x *ModelUsageStats) GetCost() float64 {
	if x != nil {
		return x.Cost
	}
	return 0
}

func (x *ModelUsageStats) GetAverageResponseTime() float64 {
	if x != nil {
		return x.AverageResponseTime
	}
	return 0
}

// 使用时间点
type UsageTimePoint struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Timestamp     *timestamppb.Timestamp `protobuf:"bytes,1,opt,name=timestamp,proto3" json:"timestamp,omitempty"`                            // 时间戳
	MessageCount  int32                  `protobuf:"varint,2,opt,name=message_count,json=messageCount,proto3" json:"message_count,omitempty"` // 消息数
	TokenCount    int32                  `protobuf:"varint,3,opt,name=token_count,json=tokenCount,proto3" json:"token_count,omitempty"`       // Token数
	Cost          float64                `protobuf:"fixed64,4,opt,name=cost,proto3" json:"cost,omitempty"`                                    // 成本
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UsageTimePoint) Reset() {
	*x = UsageTimePoint{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UsageTimePoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UsageTimePoint) ProtoMessage() {}

func (x *UsageTimePoint) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UsageTimePoint.ProtoReflect.Descriptor instead.
func (*UsageTimePoint) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{22}
}

func (x *UsageTimePoint) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

func (x *UsageTimePoint) GetMessageCount() int32 {
	if x != nil {
		return x.MessageCount
	}
	return 0
}

func (x *UsageTimePoint) GetTokenCount() int32 {
	if x != nil {
		return x.TokenCount
	}
	return 0
}

func (x *UsageTimePoint) GetCost() float64 {
	if x != nil {
		return x.Cost
	}
	return 0
}

// 用户行为画像
type UserBehaviorProfile struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	PreferredModels      []string               `protobuf:"bytes,1,rep,name=preferred_models,json=preferredModels,proto3" json:"preferred_models,omitempty"`                                                                    // 偏好模型
	FrequentTopics       []string               `protobuf:"bytes,2,rep,name=frequent_topics,json=frequentTopics,proto3" json:"frequent_topics,omitempty"`                                                                       // 常用话题
	MostActiveTime       string                 `protobuf:"bytes,3,opt,name=most_active_time,json=mostActiveTime,proto3" json:"most_active_time,omitempty"`                                                                     // 最活跃时间段
	ComplexityPreference float64                `protobuf:"fixed64,4,opt,name=complexity_preference,json=complexityPreference,proto3" json:"complexity_preference,omitempty"`                                                   // 复杂度偏好
	FeatureUsage         map[string]float64     `protobuf:"bytes,5,rep,name=feature_usage,json=featureUsage,proto3" json:"feature_usage,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"` // 功能使用情况
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *UserBehaviorProfile) Reset() {
	*x = UserBehaviorProfile{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UserBehaviorProfile) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UserBehaviorProfile) ProtoMessage() {}

func (x *UserBehaviorProfile) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UserBehaviorProfile.ProtoReflect.Descriptor instead.
func (*UserBehaviorProfile) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{23}
}

func (x *UserBehaviorProfile) GetPreferredModels() []string {
	if x != nil {
		return x.PreferredModels
	}
	return nil
}

func (x *UserBehaviorProfile) GetFrequentTopics() []string {
	if x != nil {
		return x.FrequentTopics
	}
	return nil
}

func (x *UserBehaviorProfile) GetMostActiveTime() string {
	if x != nil {
		return x.MostActiveTime
	}
	return ""
}

func (x *UserBehaviorProfile) GetComplexityPreference() float64 {
	if x != nil {
		return x.ComplexityPreference
	}
	return 0
}

func (x *UserBehaviorProfile) GetFeatureUsage() map[string]float64 {
	if x != nil {
		return x.FeatureUsage
	}
	return nil
}

// 性能时间点
type PerformanceTimePoint struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Timestamp     *timestamppb.Timestamp `protobuf:"bytes,1,opt,name=timestamp,proto3" json:"timestamp,omitempty"`                             // 时间戳
	ResponseTime  float64                `protobuf:"fixed64,2,opt,name=response_time,json=responseTime,proto3" json:"response_time,omitempty"` // 响应时间
	SuccessRate   float64                `protobuf:"fixed64,3,opt,name=success_rate,json=successRate,proto3" json:"success_rate,omitempty"`    // 成功率
	Throughput    float64                `protobuf:"fixed64,4,opt,name=throughput,proto3" json:"throughput,omitempty"`                         // 吞吐量
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PerformanceTimePoint) Reset() {
	*x = PerformanceTimePoint{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PerformanceTimePoint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PerformanceTimePoint) ProtoMessage() {}

func (x *PerformanceTimePoint) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PerformanceTimePoint.ProtoReflect.Descriptor instead.
func (*PerformanceTimePoint) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{24}
}

func (x *PerformanceTimePoint) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

func (x *PerformanceTimePoint) GetResponseTime() float64 {
	if x != nil {
		return x.ResponseTime
	}
	return 0
}

func (x *PerformanceTimePoint) GetSuccessRate() float64 {
	if x != nil {
		return x.SuccessRate
	}
	return 0
}

func (x *PerformanceTimePoint) GetThroughput() float64 {
	if x != nil {
		return x.Throughput
	}
	return 0
}

// 模型能力指标
type ModelCapabilityMetrics struct {
	state              protoimpl.MessageState `protogen:"open.v1"`
	ReasoningScore     float64                `protobuf:"fixed64,1,opt,name=reasoning_score,json=reasoningScore,proto3" json:"reasoning_score,omitempty"`                                                                                         // 推理能力分数
	CreativityScore    float64                `protobuf:"fixed64,2,opt,name=creativity_score,json=creativityScore,proto3" json:"creativity_score,omitempty"`                                                                                      // 创造力分数
	AccuracyScore      float64                `protobuf:"fixed64,3,opt,name=accuracy_score,json=accuracyScore,proto3" json:"accuracy_score,omitempty"`                                                                                            // 准确性分数
	SafetyScore        float64                `protobuf:"fixed64,4,opt,name=safety_score,json=safetyScore,proto3" json:"safety_score,omitempty"`                                                                                                  // 安全性分数
	TaskSpecificScores map[string]float64     `protobuf:"bytes,5,rep,name=task_specific_scores,json=taskSpecificScores,proto3" json:"task_specific_scores,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"` // 任务特定分数
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *ModelCapabilityMetrics) Reset() {
	*x = ModelCapabilityMetrics{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelCapabilityMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelCapabilityMetrics) ProtoMessage() {}

func (x *ModelCapabilityMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelCapabilityMetrics.ProtoReflect.Descriptor instead.
func (*ModelCapabilityMetrics) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{25}
}

func (x *ModelCapabilityMetrics) GetReasoningScore() float64 {
	if x != nil {
		return x.ReasoningScore
	}
	return 0
}

func (x *ModelCapabilityMetrics) GetCreativityScore() float64 {
	if x != nil {
		return x.CreativityScore
	}
	return 0
}

func (x *ModelCapabilityMetrics) GetAccuracyScore() float64 {
	if x != nil {
		return x.AccuracyScore
	}
	return 0
}

func (x *ModelCapabilityMetrics) GetSafetyScore() float64 {
	if x != nil {
		return x.SafetyScore
	}
	return 0
}

func (x *ModelCapabilityMetrics) GetTaskSpecificScores() map[string]float64 {
	if x != nil {
		return x.TaskSpecificScores
	}
	return nil
}

// 系统健康指标
type SystemHealthMetrics struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	OverallHealthScore  float64                `protobuf:"fixed64,1,opt,name=overall_health_score,json=overallHealthScore,proto3" json:"overall_health_score,omitempty"`    // 总体健康分数
	ServiceAvailability float64                `protobuf:"fixed64,2,opt,name=service_availability,json=serviceAvailability,proto3" json:"service_availability,omitempty"`   // 服务可用性
	AverageResponseTime float64                `protobuf:"fixed64,3,opt,name=average_response_time,json=averageResponseTime,proto3" json:"average_response_time,omitempty"` // 平均响应时间
	ErrorRate           float64                `protobuf:"fixed64,4,opt,name=error_rate,json=errorRate,proto3" json:"error_rate,omitempty"`                                 // 错误率
	ActiveConnections   int64                  `protobuf:"varint,5,opt,name=active_connections,json=activeConnections,proto3" json:"active_connections,omitempty"`          // 活跃连接数
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *SystemHealthMetrics) Reset() {
	*x = SystemHealthMetrics{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SystemHealthMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SystemHealthMetrics) ProtoMessage() {}

func (x *SystemHealthMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SystemHealthMetrics.ProtoReflect.Descriptor instead.
func (*SystemHealthMetrics) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{26}
}

func (x *SystemHealthMetrics) GetOverallHealthScore() float64 {
	if x != nil {
		return x.OverallHealthScore
	}
	return 0
}

func (x *SystemHealthMetrics) GetServiceAvailability() float64 {
	if x != nil {
		return x.ServiceAvailability
	}
	return 0
}

func (x *SystemHealthMetrics) GetAverageResponseTime() float64 {
	if x != nil {
		return x.AverageResponseTime
	}
	return 0
}

func (x *SystemHealthMetrics) GetErrorRate() float64 {
	if x != nil {
		return x.ErrorRate
	}
	return 0
}

func (x *SystemHealthMetrics) GetActiveConnections() int64 {
	if x != nil {
		return x.ActiveConnections
	}
	return 0
}

// 资源使用统计
type ResourceUsageStats struct {
	state                 protoimpl.MessageState `protogen:"open.v1"`
	CpuUsagePercentage    float64                `protobuf:"fixed64,1,opt,name=cpu_usage_percentage,json=cpuUsagePercentage,proto3" json:"cpu_usage_percentage,omitempty"`          // CPU使用率
	MemoryUsagePercentage float64                `protobuf:"fixed64,2,opt,name=memory_usage_percentage,json=memoryUsagePercentage,proto3" json:"memory_usage_percentage,omitempty"` // 内存使用率
	StorageUsageGb        float64                `protobuf:"fixed64,3,opt,name=storage_usage_gb,json=storageUsageGb,proto3" json:"storage_usage_gb,omitempty"`                      // 存储使用量(GB)
	NetworkBandwidthMbps  float64                `protobuf:"fixed64,4,opt,name=network_bandwidth_mbps,json=networkBandwidthMbps,proto3" json:"network_bandwidth_mbps,omitempty"`    // 网络带宽(Mbps)
	DatabaseConnections   int64                  `protobuf:"varint,5,opt,name=database_connections,json=databaseConnections,proto3" json:"database_connections,omitempty"`          // 数据库连接数
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *ResourceUsageStats) Reset() {
	*x = ResourceUsageStats{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResourceUsageStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResourceUsageStats) ProtoMessage() {}

func (x *ResourceUsageStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResourceUsageStats.ProtoReflect.Descriptor instead.
func (*ResourceUsageStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{27}
}

func (x *ResourceUsageStats) GetCpuUsagePercentage() float64 {
	if x != nil {
		return x.CpuUsagePercentage
	}
	return 0
}

func (x *ResourceUsageStats) GetMemoryUsagePercentage() float64 {
	if x != nil {
		return x.MemoryUsagePercentage
	}
	return 0
}

func (x *ResourceUsageStats) GetStorageUsageGb() float64 {
	if x != nil {
		return x.StorageUsageGb
	}
	return 0
}

func (x *ResourceUsageStats) GetNetworkBandwidthMbps() float64 {
	if x != nil {
		return x.NetworkBandwidthMbps
	}
	return 0
}

func (x *ResourceUsageStats) GetDatabaseConnections() int64 {
	if x != nil {
		return x.DatabaseConnections
	}
	return 0
}

// 服务统计
type ServiceStats struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	ServiceName         string                 `protobuf:"bytes,1,opt,name=service_name,json=serviceName,proto3" json:"service_name,omitempty"`                             // 服务名称
	UptimePercentage    float64                `protobuf:"fixed64,2,opt,name=uptime_percentage,json=uptimePercentage,proto3" json:"uptime_percentage,omitempty"`            // 运行时间百分比
	RequestCount        int64                  `protobuf:"varint,3,opt,name=request_count,json=requestCount,proto3" json:"request_count,omitempty"`                         // 请求数
	AverageResponseTime float64                `protobuf:"fixed64,4,opt,name=average_response_time,json=averageResponseTime,proto3" json:"average_response_time,omitempty"` // 平均响应时间
	ErrorRate           float64                `protobuf:"fixed64,5,opt,name=error_rate,json=errorRate,proto3" json:"error_rate,omitempty"`                                 // 错误率
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *ServiceStats) Reset() {
	*x = ServiceStats{}
	mi := &file_api_ai_v1_ai_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ServiceStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ServiceStats) ProtoMessage() {}

func (x *ServiceStats) ProtoReflect() protoreflect.Message {
	mi := &file_api_ai_v1_ai_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ServiceStats.ProtoReflect.Descriptor instead.
func (*ServiceStats) Descriptor() ([]byte, []int) {
	return file_api_ai_v1_ai_proto_rawDescGZIP(), []int{28}
}

func (x *ServiceStats) GetServiceName() string {
	if x != nil {
		return x.ServiceName
	}
	return ""
}

func (x *ServiceStats) GetUptimePercentage() float64 {
	if x != nil {
		return x.UptimePercentage
	}
	return 0
}

func (x *ServiceStats) GetRequestCount() int64 {
	if x != nil {
		return x.RequestCount
	}
	return 0
}

func (x *ServiceStats) GetAverageResponseTime() float64 {
	if x != nil {
		return x.AverageResponseTime
	}
	return 0
}

func (x *ServiceStats) GetErrorRate() float64 {
	if x != nil {
		return x.ErrorRate
	}
	return 0
}

var File_api_ai_v1_ai_proto protoreflect.FileDescriptor

const file_api_ai_v1_ai_proto_rawDesc = "" +
	"\n" +
	"\x12api/ai/v1/ai.proto\x12\tapi.ai.v1\x1a\x1fgoogle/protobuf/timestamp.proto\"\xb4\x03\n" +
	"\x1fGetConversationAnalyticsRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x129\n" +
	"\n" +
	"start_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x12A\n" +
	"\vgranularity\x18\x04 \x01(\x0e2\x1f.api.ai.v1.AnalyticsGranularityR\vgranularity\x124\n" +
	"\ametrics\x18\x05 \x03(\x0e2\x1a.api.ai.v1.AnalyticsMetricR\ametrics\x12Q\n" +
	"\afilters\x18\x06 \x03(\v27.api.ai.v1.GetConversationAnalyticsRequest.FiltersEntryR\afilters\x1a:\n" +
	"\fFiltersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"_\n" +
	"\x1dGetConversationAnalyticsReply\x12>\n" +
	"\tanalytics\x18\x01 \x01(\v2 .api.ai.v1.ConversationAnalyticsR\tanalytics\"\x8b\x02\n" +
	"\x18GetUserUsageStatsRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x129\n" +
	"\n" +
	"start_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x124\n" +
	"\x16include_cost_breakdown\x18\x04 \x01(\bR\x14includeCostBreakdown\x12.\n" +
	"\x13include_model_usage\x18\x05 \x01(\bR\x11includeModelUsage\"T\n" +
	"\x16GetUserUsageStatsReply\x12:\n" +
	"\vusage_stats\x18\x01 \x01(\v2\x19.api.ai.v1.UserUsageStatsR\n" +
	"usageStats\"\xa6\x02\n" +
	"\x1fGetModelPerformanceStatsRequest\x12\x1f\n" +
	"\vmodel_names\x18\x01 \x03(\tR\n" +
	"modelNames\x129\n" +
	"\n" +
	"start_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x12:\n" +
	"\x19include_user_satisfaction\x18\x04 \x01(\bR\x17includeUserSatisfaction\x124\n" +
	"\x16include_error_analysis\x18\x05 \x01(\bR\x14includeErrorAnalysis\"b\n" +
	"\x1dGetModelPerformanceStatsReply\x12A\n" +
	"\vmodel_stats\x18\x01 \x03(\v2 .api.ai.v1.ModelPerformanceStatsR\n" +
	"modelStats\"\xa9\x02\n" +
	"\x1cGetConversationTrendsRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x129\n" +
	"\n" +
	"start_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x12A\n" +
	"\vgranularity\x18\x04 \x01(\x0e2\x1f.api.ai.v1.AnalyticsGranularityR\vgranularity\x12;\n" +
	"\rtrend_metrics\x18\x05 \x03(\x0e2\x16.api.ai.v1.TrendMetricR\ftrendMetrics\"J\n" +
	"\x1aGetConversationTrendsReply\x12,\n" +
	"\x06trends\x18\x01 \x03(\v2\x14.api.ai.v1.TrendDataR\x06trends\"\x8d\x03\n" +
	"\x17GetTopicAnalysisRequest\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x129\n" +
	"\n" +
	"start_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x12(\n" +
	"\x10top_topics_count\x18\x04 \x01(\x05R\x0etopTopicsCount\x126\n" +
	"\x06method\x18\x05 \x01(\x0e2\x1e.api.ai.v1.TopicAnalysisMethodR\x06method\x12I\n" +
	"\afilters\x18\x06 \x03(\v2/.api.ai.v1.GetTopicAnalysisRequest.FiltersEntryR\afilters\x1a:\n" +
	"\fFiltersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x8a\x01\n" +
	"\x15GetTopicAnalysisReply\x12/\n" +
	"\x06topics\x18\x01 \x03(\v2\x17.api.ai.v1.TopicInsightR\x06topics\x12@\n" +
	"\fdistribution\x18\x02 \x01(\v2\x1c.api.ai.v1.TopicDistributionR\fdistribution\"\xf8\x01\n" +
	"\x18GetSystemOverviewRequest\x129\n" +
	"\n" +
	"start_time\x18\x01 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x02 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x124\n" +
	"\x16include_health_metrics\x18\x03 \x01(\bR\x14includeHealthMetrics\x124\n" +
	"\x16include_resource_usage\x18\x04 \x01(\bR\x14includeResourceUsage\"T\n" +
	"\x16GetSystemOverviewReply\x12:\n" +
	"\boverview\x18\x01 \x01(\v2\x1e.api.ai.v1.SystemOverviewStatsR\boverview\"\xd4\x05\n" +
	"\x15ConversationAnalytics\x12/\n" +
	"\x13total_conversations\x18\x01 \x01(\x03R\x12totalConversations\x12!\n" +
	"\factive_users\x18\x02 \x01(\x03R\vactiveUsers\x12>\n" +
	"\x1baverage_conversation_length\x18\x03 \x01(\x01R\x19averageConversationLength\x122\n" +
	"\x15average_response_time\x18\x04 \x01(\x01R\x13averageResponseTime\x12v\n" +
	"\x18model_usage_distribution\x18\x05 \x03(\v2<.api.ai.v1.ConversationAnalytics.ModelUsageDistributionEntryR\x16modelUsageDistribution\x12c\n" +
	"\x11time_distribution\x18\x06 \x03(\v26.api.ai.v1.ConversationAnalytics.TimeDistributionEntryR\x10timeDistribution\x12D\n" +
	"\x10time_series_data\x18\a \x03(\v2\x1a.api.ai.v1.TimeSeriesPointR\x0etimeSeriesData\x12@\n" +
	"\n" +
	"engagement\x18\b \x01(\v2 .api.ai.v1.UserEngagementMetricsR\n" +
	"engagement\x1aI\n" +
	"\x1bModelUsageDistributionEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x03R\x05value:\x028\x01\x1aC\n" +
	"\x15TimeDistributionEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x03R\x05value:\x028\x01\"\x83\x06\n" +
	"\x0eUserUsageStats\x12\x17\n" +
	"\auser_id\x18\x01 \x01(\x03R\x06userId\x12/\n" +
	"\x13total_conversations\x18\x02 \x01(\x03R\x12totalConversations\x12%\n" +
	"\x0etotal_messages\x18\x03 \x01(\x03R\rtotalMessages\x12,\n" +
	"\x12total_input_tokens\x18\x04 \x01(\x03R\x10totalInputTokens\x12.\n" +
	"\x13total_output_tokens\x18\x05 \x01(\x03R\x11totalOutputTokens\x12\x1d\n" +
	"\n" +
	"total_cost\x18\x06 \x01(\x01R\ttotalCost\x128\n" +
	"\x18average_session_duration\x18\a \x01(\x01R\x16averageSessionDuration\x12J\n" +
	"\vmodel_usage\x18\b \x03(\v2).api.ai.v1.UserUsageStats.ModelUsageEntryR\n" +
	"modelUsage\x12S\n" +
	"\x0ecost_breakdown\x18\t \x03(\v2,.api.ai.v1.UserUsageStats.CostBreakdownEntryR\rcostBreakdown\x12@\n" +
	"\x0eusage_timeline\x18\n" +
	" \x03(\v2\x19.api.ai.v1.UsageTimePointR\rusageTimeline\x12I\n" +
	"\x10behavior_profile\x18\v \x01(\v2\x1e.api.ai.v1.UserBehaviorProfileR\x0fbehaviorProfile\x1aY\n" +
	"\x0fModelUsageEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x120\n" +
	"\x05value\x18\x02 \x01(\v2\x1a.api.ai.v1.ModelUsageStatsR\x05value:\x028\x01\x1a@\n" +
	"\x12CostBreakdownEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01\"\xc5\x05\n" +
	"\x15ModelPerformanceStats\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\x12%\n" +
	"\x0etotal_requests\x18\x02 \x01(\x03R\rtotalRequests\x12!\n" +
	"\fsuccess_rate\x18\x03 \x01(\x01R\vsuccessRate\x122\n" +
	"\x15average_response_time\x18\x04 \x01(\x01R\x13averageResponseTime\x120\n" +
	"\x14average_input_tokens\x18\x05 \x01(\x01R\x12averageInputTokens\x122\n" +
	"\x15average_output_tokens\x18\x06 \x01(\x01R\x13averageOutputTokens\x12(\n" +
	"\x10cost_per_request\x18\a \x01(\x01R\x0ecostPerRequest\x126\n" +
	"\x17user_satisfaction_score\x18\b \x01(\x01R\x15userSatisfactionScore\x12f\n" +
	"\x12error_distribution\x18\t \x03(\v27.api.ai.v1.ModelPerformanceStats.ErrorDistributionEntryR\x11errorDistribution\x12R\n" +
	"\x14performance_timeline\x18\n" +
	" \x03(\v2\x1f.api.ai.v1.PerformanceTimePointR\x13performanceTimeline\x12E\n" +
	"\fcapabilities\x18\v \x01(\v2!.api.ai.v1.ModelCapabilityMetricsR\fcapabilities\x1aD\n" +
	"\x16ErrorDistributionEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x03R\x05value:\x028\x01\"\xc2\x01\n" +
	"\tTrendData\x12.\n" +
	"\x06metric\x18\x01 \x01(\x0e2\x16.api.ai.v1.TrendMetricR\x06metric\x12;\n" +
	"\vdata_points\x18\x02 \x03(\v2\x1a.api.ai.v1.TimeSeriesPointR\n" +
	"dataPoints\x12\x1f\n" +
	"\vgrowth_rate\x18\x03 \x01(\x01R\n" +
	"growthRate\x12'\n" +
	"\x0ftrend_direction\x18\x04 \x01(\tR\x0etrendDirection\"\xed\x02\n" +
	"\fTopicInsight\x12\x1d\n" +
	"\n" +
	"topic_name\x18\x01 \x01(\tR\ttopicName\x12\x1a\n" +
	"\bkeywords\x18\x02 \x03(\tR\bkeywords\x12#\n" +
	"\rmessage_count\x18\x03 \x01(\x03R\fmessageCount\x12'\n" +
	"\x0frelevance_score\x18\x04 \x01(\x01R\x0erelevanceScore\x12'\n" +
	"\x0fsentiment_score\x18\x05 \x01(\x01R\x0esentimentScore\x127\n" +
	"\x17representative_messages\x18\x06 \x03(\tR\x16representativeMessages\x129\n" +
	"\n" +
	"first_seen\x18\a \x01(\v2\x1a.google.protobuf.TimestampR\tfirstSeen\x127\n" +
	"\tlast_seen\x18\b \x01(\v2\x1a.google.protobuf.TimestampR\blastSeen\"\xa1\x02\n" +
	"\x11TopicDistribution\x12_\n" +
	"\x11topic_percentages\x18\x01 \x03(\v22.api.ai.v1.TopicDistribution.TopicPercentagesEntryR\x10topicPercentages\x122\n" +
	"\x15topic_diversity_index\x18\x02 \x01(\x01R\x13topicDiversityIndex\x122\n" +
	"\x15total_topics_detected\x18\x03 \x01(\x05R\x13totalTopicsDetected\x1aC\n" +
	"\x15TopicPercentagesEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01\"\xc0\x04\n" +
	"\x13SystemOverviewStats\x12\x1f\n" +
	"\vtotal_users\x18\x01 \x01(\x03R\n" +
	"totalUsers\x12,\n" +
	"\x12active_users_today\x18\x02 \x01(\x03R\x10activeUsersToday\x12/\n" +
	"\x13total_conversations\x18\x03 \x01(\x03R\x12totalConversations\x12%\n" +
	"\x0etotal_messages\x18\x04 \x01(\x03R\rtotalMessages\x124\n" +
	"\x16total_tokens_processed\x18\x05 \x01(\x03R\x14totalTokensProcessed\x12\x1d\n" +
	"\n" +
	"total_cost\x18\x06 \x01(\x01R\ttotalCost\x126\n" +
	"\x06health\x18\a \x01(\v2\x1e.api.ai.v1.SystemHealthMetricsR\x06health\x12D\n" +
	"\x0eresource_usage\x18\b \x01(\v2\x1d.api.ai.v1.ResourceUsageStatsR\rresourceUsage\x12U\n" +
	"\rservice_stats\x18\t \x03(\v20.api.ai.v1.SystemOverviewStats.ServiceStatsEntryR\fserviceStats\x1aX\n" +
	"\x11ServiceStatsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12-\n" +
	"\x05value\x18\x02 \x01(\v2\x17.api.ai.v1.ServiceStatsR\x05value:\x028\x01\"\x82\x02\n" +
	"\x0fTimeSeriesPoint\x128\n" +
	"\ttimestamp\x18\x01 \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value\x12\x14\n" +
	"\x05label\x18\x03 \x01(\tR\x05label\x12J\n" +
	"\n" +
	"dimensions\x18\x04 \x03(\v2*.api.ai.v1.TimeSeriesPoint.DimensionsEntryR\n" +
	"dimensions\x1a=\n" +
	"\x0fDimensionsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01\"\x88\x02\n" +
	"\x15UserEngagementMetrics\x12I\n" +
	"!average_messages_per_conversation\x18\x01 \x01(\x01R\x1eaverageMessagesPerConversation\x12@\n" +
	"\x1cconversation_completion_rate\x18\x02 \x01(\x01R\x1aconversationCompletionRate\x12.\n" +
	"\x13user_retention_rate\x18\x03 \x01(\x01R\x11userRetentionRate\x122\n" +
	"\x15feature_adoption_rate\x18\x04 \x01(\x01R\x13featureAdoptionRate\"\xe5\x01\n" +
	"\x0fModelUsageStats\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\x12#\n" +
	"\rrequest_count\x18\x02 \x01(\x03R\frequestCount\x12!\n" +
	"\finput_tokens\x18\x03 \x01(\x03R\vinputTokens\x12#\n" +
	"\routput_tokens\x18\x04 \x01(\x03R\foutputTokens\x12\x12\n" +
	"\x04cost\x18\x05 \x01(\x01R\x04cost\x122\n" +
	"\x15average_response_time\x18\x06 \x01(\x01R\x13averageResponseTime\"\xa4\x01\n" +
	"\x0eUsageTimePoint\x128\n" +
	"\ttimestamp\x18\x01 \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\x12#\n" +
	"\rmessage_count\x18\x02 \x01(\x05R\fmessageCount\x12\x1f\n" +
	"\vtoken_count\x18\x03 \x01(\x05R\n" +
	"tokenCount\x12\x12\n" +
	"\x04cost\x18\x04 \x01(\x01R\x04cost\"\xe0\x02\n" +
	"\x13UserBehaviorProfile\x12)\n" +
	"\x10preferred_models\x18\x01 \x03(\tR\x0fpreferredModels\x12'\n" +
	"\x0ffrequent_topics\x18\x02 \x03(\tR\x0efrequentTopics\x12(\n" +
	"\x10most_active_time\x18\x03 \x01(\tR\x0emostActiveTime\x123\n" +
	"\x15complexity_preference\x18\x04 \x01(\x01R\x14complexityPreference\x12U\n" +
	"\rfeature_usage\x18\x05 \x03(\v20.api.ai.v1.UserBehaviorProfile.FeatureUsageEntryR\ffeatureUsage\x1a?\n" +
	"\x11FeatureUsageEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01\"\xb8\x01\n" +
	"\x14PerformanceTimePoint\x128\n" +
	"\ttimestamp\x18\x01 \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\x12#\n" +
	"\rresponse_time\x18\x02 \x01(\x01R\fresponseTime\x12!\n" +
	"\fsuccess_rate\x18\x03 \x01(\x01R\vsuccessRate\x12\x1e\n" +
	"\n" +
	"throughput\x18\x04 \x01(\x01R\n" +
	"throughput\"\xea\x02\n" +
	"\x16ModelCapabilityMetrics\x12'\n" +
	"\x0freasoning_score\x18\x01 \x01(\x01R\x0ereasoningScore\x12)\n" +
	"\x10creativity_score\x18\x02 \x01(\x01R\x0fcreativityScore\x12%\n" +
	"\x0eaccuracy_score\x18\x03 \x01(\x01R\raccuracyScore\x12!\n" +
	"\fsafety_score\x18\x04 \x01(\x01R\vsafetyScore\x12k\n" +
	"\x14task_specific_scores\x18\x05 \x03(\v29.api.ai.v1.ModelCapabilityMetrics.TaskSpecificScoresEntryR\x12taskSpecificScores\x1aE\n" +
	"\x17TaskSpecificScoresEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01\"\xfc\x01\n" +
	"\x13SystemHealthMetrics\x120\n" +
	"\x14overall_health_score\x18\x01 \x01(\x01R\x12overallHealthScore\x121\n" +
	"\x14service_availability\x18\x02 \x01(\x01R\x13serviceAvailability\x122\n" +
	"\x15average_response_time\x18\x03 \x01(\x01R\x13averageResponseTime\x12\x1d\n" +
	"\n" +
	"error_rate\x18\x04 \x01(\x01R\terrorRate\x12-\n" +
	"\x12active_connections\x18\x05 \x01(\x03R\x11activeConnections\"\x91\x02\n" +
	"\x12ResourceUsageStats\x120\n" +
	"\x14cpu_usage_percentage\x18\x01 \x01(\x01R\x12cpuUsagePercentage\x126\n" +
	"\x17memory_usage_percentage\x18\x02 \x01(\x01R\x15memoryUsagePercentage\x12(\n" +
	"\x10storage_usage_gb\x18\x03 \x01(\x01R\x0estorageUsageGb\x124\n" +
	"\x16network_bandwidth_mbps\x18\x04 \x01(\x01R\x14networkBandwidthMbps\x121\n" +
	"\x14database_connections\x18\x05 \x01(\x03R\x13databaseConnections\"\xd6\x01\n" +
	"\fServiceStats\x12!\n" +
	"\fservice_name\x18\x01 \x01(\tR\vserviceName\x12+\n" +
	"\x11uptime_percentage\x18\x02 \x01(\x01R\x10uptimePercentage\x12#\n" +
	"\rrequest_count\x18\x03 \x01(\x03R\frequestCount\x122\n" +
	"\x15average_response_time\x18\x04 \x01(\x01R\x13averageResponseTime\x12\x1d\n" +
	"\n" +
	"error_rate\x18\x05 \x01(\x01R\terrorRate*\xbd\x01\n" +
	"\x14AnalyticsGranularity\x12%\n" +
	"!ANALYTICS_GRANULARITY_UNSPECIFIED\x10\x00\x12\x1e\n" +
	"\x1aANALYTICS_GRANULARITY_HOUR\x10\x01\x12\x1d\n" +
	"\x19ANALYTICS_GRANULARITY_DAY\x10\x02\x12\x1e\n" +
	"\x1aANALYTICS_GRANULARITY_WEEK\x10\x03\x12\x1f\n" +
	"\x1bANALYTICS_GRANULARITY_MONTH\x10\x04*\x8d\x02\n" +
	"\x0fAnalyticsMetric\x12 \n" +
	"\x1cANALYTICS_METRIC_UNSPECIFIED\x10\x00\x12'\n" +
	"#ANALYTICS_METRIC_CONVERSATION_COUNT\x10\x01\x12\"\n" +
	"\x1eANALYTICS_METRIC_MESSAGE_COUNT\x10\x02\x12 \n" +
	"\x1cANALYTICS_METRIC_TOKEN_USAGE\x10\x03\x12\"\n" +
	"\x1eANALYTICS_METRIC_RESPONSE_TIME\x10\x04\x12$\n" +
	" ANALYTICS_METRIC_USER_ENGAGEMENT\x10\x05\x12\x1f\n" +
	"\x1bANALYTICS_METRIC_TOOL_USAGE\x10\x06*\xca\x01\n" +
	"\vTrendMetric\x12\x1c\n" +
	"\x18TREND_METRIC_UNSPECIFIED\x10\x00\x12\x1d\n" +
	"\x19TREND_METRIC_ACTIVE_USERS\x10\x01\x12\"\n" +
	"\x1eTREND_METRIC_NEW_CONVERSATIONS\x10\x02\x12\x1f\n" +
	"\x1bTREND_METRIC_MESSAGE_VOLUME\x10\x03\x12\"\n" +
	"\x1eTREND_METRIC_TOKEN_CONSUMPTION\x10\x04\x12\x15\n" +
	"\x11TREND_METRIC_COST\x10\x05*\xc8\x01\n" +
	"\x13TopicAnalysisMethod\x12%\n" +
	"!TOPIC_ANALYSIS_METHOD_UNSPECIFIED\x10\x00\x12!\n" +
	"\x1dTOPIC_ANALYSIS_METHOD_KEYWORD\x10\x01\x12\x1d\n" +
	"\x19TOPIC_ANALYSIS_METHOD_LDA\x10\x02\x12$\n" +
	" TOPIC_ANALYSIS_METHOD_CLUSTERING\x10\x03\x12\"\n" +
	"\x1eTOPIC_ANALYSIS_METHOD_SEMANTIC\x10\x042\xe5\x04\n" +
	"\x02Ai\x12p\n" +
	"\x18GetConversationAnalytics\x12*.api.ai.v1.GetConversationAnalyticsRequest\x1a(.api.ai.v1.GetConversationAnalyticsReply\x12[\n" +
	"\x11GetUserUsageStats\x12#.api.ai.v1.GetUserUsageStatsRequest\x1a!.api.ai.v1.GetUserUsageStatsReply\x12p\n" +
	"\x18GetModelPerformanceStats\x12*.api.ai.v1.GetModelPerformanceStatsRequest\x1a(.api.ai.v1.GetModelPerformanceStatsReply\x12g\n" +
	"\x15GetConversationTrends\x12'.api.ai.v1.GetConversationTrendsRequest\x1a%.api.ai.v1.GetConversationTrendsReply\x12X\n" +
	"\x10GetTopicAnalysis\x12\".api.ai.v1.GetTopicAnalysisRequest\x1a .api.ai.v1.GetTopicAnalysisReply\x12[\n" +
	"\x11GetSystemOverview\x12#.api.ai.v1.GetSystemOverviewRequest\x1a!.api.ai.v1.GetSystemOverviewReplyBE\n" +
	"\x1ecom.oldwei.universal.api.ai.v1B\tAiProtoV1P\x01Z\x16universal/api/ai/v1;v1b\x06proto3"

var (
	file_api_ai_v1_ai_proto_rawDescOnce sync.Once
	file_api_ai_v1_ai_proto_rawDescData []byte
)

func file_api_ai_v1_ai_proto_rawDescGZIP() []byte {
	file_api_ai_v1_ai_proto_rawDescOnce.Do(func() {
		file_api_ai_v1_ai_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_ai_v1_ai_proto_rawDesc), len(file_api_ai_v1_ai_proto_rawDesc)))
	})
	return file_api_ai_v1_ai_proto_rawDescData
}

var file_api_ai_v1_ai_proto_enumTypes = make([]protoimpl.EnumInfo, 4)
var file_api_ai_v1_ai_proto_msgTypes = make([]protoimpl.MessageInfo, 41)
var file_api_ai_v1_ai_proto_goTypes = []any{
	(AnalyticsGranularity)(0),               // 0: api.ai.v1.AnalyticsGranularity
	(AnalyticsMetric)(0),                    // 1: api.ai.v1.AnalyticsMetric
	(TrendMetric)(0),                        // 2: api.ai.v1.TrendMetric
	(TopicAnalysisMethod)(0),                // 3: api.ai.v1.TopicAnalysisMethod
	(*GetConversationAnalyticsRequest)(nil), // 4: api.ai.v1.GetConversationAnalyticsRequest
	(*GetConversationAnalyticsReply)(nil),   // 5: api.ai.v1.GetConversationAnalyticsReply
	(*GetUserUsageStatsRequest)(nil),        // 6: api.ai.v1.GetUserUsageStatsRequest
	(*GetUserUsageStatsReply)(nil),          // 7: api.ai.v1.GetUserUsageStatsReply
	(*GetModelPerformanceStatsRequest)(nil), // 8: api.ai.v1.GetModelPerformanceStatsRequest
	(*GetModelPerformanceStatsReply)(nil),   // 9: api.ai.v1.GetModelPerformanceStatsReply
	(*GetConversationTrendsRequest)(nil),    // 10: api.ai.v1.GetConversationTrendsRequest
	(*GetConversationTrendsReply)(nil),      // 11: api.ai.v1.GetConversationTrendsReply
	(*GetTopicAnalysisRequest)(nil),         // 12: api.ai.v1.GetTopicAnalysisRequest
	(*GetTopicAnalysisReply)(nil),           // 13: api.ai.v1.GetTopicAnalysisReply
	(*GetSystemOverviewRequest)(nil),        // 14: api.ai.v1.GetSystemOverviewRequest
	(*GetSystemOverviewReply)(nil),          // 15: api.ai.v1.GetSystemOverviewReply
	(*ConversationAnalytics)(nil),           // 16: api.ai.v1.ConversationAnalytics
	(*UserUsageStats)(nil),                  // 17: api.ai.v1.UserUsageStats
	(*ModelPerformanceStats)(nil),           // 18: api.ai.v1.ModelPerformanceStats
	(*TrendData)(nil),                       // 19: api.ai.v1.TrendData
	(*TopicInsight)(nil),                    // 20: api.ai.v1.TopicInsight
	(*TopicDistribution)(nil),               // 21: api.ai.v1.TopicDistribution
	(*SystemOverviewStats)(nil),             // 22: api.ai.v1.SystemOverviewStats
	(*TimeSeriesPoint)(nil),                 // 23: api.ai.v1.TimeSeriesPoint
	(*UserEngagementMetrics)(nil),           // 24: api.ai.v1.UserEngagementMetrics
	(*ModelUsageStats)(nil),                 // 25: api.ai.v1.ModelUsageStats
	(*UsageTimePoint)(nil),                  // 26: api.ai.v1.UsageTimePoint
	(*UserBehaviorProfile)(nil),             // 27: api.ai.v1.UserBehaviorProfile
	(*PerformanceTimePoint)(nil),            // 28: api.ai.v1.PerformanceTimePoint
	(*ModelCapabilityMetrics)(nil),          // 29: api.ai.v1.ModelCapabilityMetrics
	(*SystemHealthMetrics)(nil),             // 30: api.ai.v1.SystemHealthMetrics
	(*ResourceUsageStats)(nil),              // 31: api.ai.v1.ResourceUsageStats
	(*ServiceStats)(nil),                    // 32: api.ai.v1.ServiceStats
	nil,                                     // 33: api.ai.v1.GetConversationAnalyticsRequest.FiltersEntry
	nil,                                     // 34: api.ai.v1.GetTopicAnalysisRequest.FiltersEntry
	nil,                                     // 35: api.ai.v1.ConversationAnalytics.ModelUsageDistributionEntry
	nil,                                     // 36: api.ai.v1.ConversationAnalytics.TimeDistributionEntry
	nil,                                     // 37: api.ai.v1.UserUsageStats.ModelUsageEntry
	nil,                                     // 38: api.ai.v1.UserUsageStats.CostBreakdownEntry
	nil,                                     // 39: api.ai.v1.ModelPerformanceStats.ErrorDistributionEntry
	nil,                                     // 40: api.ai.v1.TopicDistribution.TopicPercentagesEntry
	nil,                                     // 41: api.ai.v1.SystemOverviewStats.ServiceStatsEntry
	nil,                                     // 42: api.ai.v1.TimeSeriesPoint.DimensionsEntry
	nil,                                     // 43: api.ai.v1.UserBehaviorProfile.FeatureUsageEntry
	nil,                                     // 44: api.ai.v1.ModelCapabilityMetrics.TaskSpecificScoresEntry
	(*timestamppb.Timestamp)(nil),           // 45: google.protobuf.Timestamp
}
var file_api_ai_v1_ai_proto_depIdxs = []int32{
	45, // 0: api.ai.v1.GetConversationAnalyticsRequest.start_time:type_name -> google.protobuf.Timestamp
	45, // 1: api.ai.v1.GetConversationAnalyticsRequest.end_time:type_name -> google.protobuf.Timestamp
	0,  // 2: api.ai.v1.GetConversationAnalyticsRequest.granularity:type_name -> api.ai.v1.AnalyticsGranularity
	1,  // 3: api.ai.v1.GetConversationAnalyticsRequest.metrics:type_name -> api.ai.v1.AnalyticsMetric
	33, // 4: api.ai.v1.GetConversationAnalyticsRequest.filters:type_name -> api.ai.v1.GetConversationAnalyticsRequest.FiltersEntry
	16, // 5: api.ai.v1.GetConversationAnalyticsReply.analytics:type_name -> api.ai.v1.ConversationAnalytics
	45, // 6: api.ai.v1.GetUserUsageStatsRequest.start_time:type_name -> google.protobuf.Timestamp
	45, // 7: api.ai.v1.GetUserUsageStatsRequest.end_time:type_name -> google.protobuf.Timestamp
	17, // 8: api.ai.v1.GetUserUsageStatsReply.usage_stats:type_name -> api.ai.v1.UserUsageStats
	45, // 9: api.ai.v1.GetModelPerformanceStatsRequest.start_time:type_name -> google.protobuf.Timestamp
	45, // 10: api.ai.v1.GetModelPerformanceStatsRequest.end_time:type_name -> google.protobuf.Timestamp
	18, // 11: api.ai.v1.GetModelPerformanceStatsReply.model_stats:type_name -> api.ai.v1.ModelPerformanceStats
	45, // 12: api.ai.v1.GetConversationTrendsRequest.start_time:type_name -> google.protobuf.Timestamp
	45, // 13: api.ai.v1.GetConversationTrendsRequest.end_time:type_name -> google.protobuf.Timestamp
	0,  // 14: api.ai.v1.GetConversationTrendsRequest.granularity:type_name -> api.ai.v1.AnalyticsGranularity
	2,  // 15: api.ai.v1.GetConversationTrendsRequest.trend_metrics:type_name -> api.ai.v1.TrendMetric
	19, // 16: api.ai.v1.GetConversationTrendsReply.trends:type_name -> api.ai.v1.TrendData
	45, // 17: api.ai.v1.GetTopicAnalysisRequest.start_time:type_name -> google.protobuf.Timestamp
	45, // 18: api.ai.v1.GetTopicAnalysisRequest.end_time:type_name -> google.protobuf.Timestamp
	3,  // 19: api.ai.v1.GetTopicAnalysisRequest.method:type_name -> api.ai.v1.TopicAnalysisMethod
	34, // 20: api.ai.v1.GetTopicAnalysisRequest.filters:type_name -> api.ai.v1.GetTopicAnalysisRequest.FiltersEntry
	20, // 21: api.ai.v1.GetTopicAnalysisReply.topics:type_name -> api.ai.v1.TopicInsight
	21, // 22: api.ai.v1.GetTopicAnalysisReply.distribution:type_name -> api.ai.v1.TopicDistribution
	45, // 23: api.ai.v1.GetSystemOverviewRequest.start_time:type_name -> google.protobuf.Timestamp
	45, // 24: api.ai.v1.GetSystemOverviewRequest.end_time:type_name -> google.protobuf.Timestamp
	22, // 25: api.ai.v1.GetSystemOverviewReply.overview:type_name -> api.ai.v1.SystemOverviewStats
	35, // 26: api.ai.v1.ConversationAnalytics.model_usage_distribution:type_name -> api.ai.v1.ConversationAnalytics.ModelUsageDistributionEntry
	36, // 27: api.ai.v1.ConversationAnalytics.time_distribution:type_name -> api.ai.v1.ConversationAnalytics.TimeDistributionEntry
	23, // 28: api.ai.v1.ConversationAnalytics.time_series_data:type_name -> api.ai.v1.TimeSeriesPoint
	24, // 29: api.ai.v1.ConversationAnalytics.engagement:type_name -> api.ai.v1.UserEngagementMetrics
	37, // 30: api.ai.v1.UserUsageStats.model_usage:type_name -> api.ai.v1.UserUsageStats.ModelUsageEntry
	38, // 31: api.ai.v1.UserUsageStats.cost_breakdown:type_name -> api.ai.v1.UserUsageStats.CostBreakdownEntry
	26, // 32: api.ai.v1.UserUsageStats.usage_timeline:type_name -> api.ai.v1.UsageTimePoint
	27, // 33: api.ai.v1.UserUsageStats.behavior_profile:type_name -> api.ai.v1.UserBehaviorProfile
	39, // 34: api.ai.v1.ModelPerformanceStats.error_distribution:type_name -> api.ai.v1.ModelPerformanceStats.ErrorDistributionEntry
	28, // 35: api.ai.v1.ModelPerformanceStats.performance_timeline:type_name -> api.ai.v1.PerformanceTimePoint
	29, // 36: api.ai.v1.ModelPerformanceStats.capabilities:type_name -> api.ai.v1.ModelCapabilityMetrics
	2,  // 37: api.ai.v1.TrendData.metric:type_name -> api.ai.v1.TrendMetric
	23, // 38: api.ai.v1.TrendData.data_points:type_name -> api.ai.v1.TimeSeriesPoint
	45, // 39: api.ai.v1.TopicInsight.first_seen:type_name -> google.protobuf.Timestamp
	45, // 40: api.ai.v1.TopicInsight.last_seen:type_name -> google.protobuf.Timestamp
	40, // 41: api.ai.v1.TopicDistribution.topic_percentages:type_name -> api.ai.v1.TopicDistribution.TopicPercentagesEntry
	30, // 42: api.ai.v1.SystemOverviewStats.health:type_name -> api.ai.v1.SystemHealthMetrics
	31, // 43: api.ai.v1.SystemOverviewStats.resource_usage:type_name -> api.ai.v1.ResourceUsageStats
	41, // 44: api.ai.v1.SystemOverviewStats.service_stats:type_name -> api.ai.v1.SystemOverviewStats.ServiceStatsEntry
	45, // 45: api.ai.v1.TimeSeriesPoint.timestamp:type_name -> google.protobuf.Timestamp
	42, // 46: api.ai.v1.TimeSeriesPoint.dimensions:type_name -> api.ai.v1.TimeSeriesPoint.DimensionsEntry
	45, // 47: api.ai.v1.UsageTimePoint.timestamp:type_name -> google.protobuf.Timestamp
	43, // 48: api.ai.v1.UserBehaviorProfile.feature_usage:type_name -> api.ai.v1.UserBehaviorProfile.FeatureUsageEntry
	45, // 49: api.ai.v1.PerformanceTimePoint.timestamp:type_name -> google.protobuf.Timestamp
	44, // 50: api.ai.v1.ModelCapabilityMetrics.task_specific_scores:type_name -> api.ai.v1.ModelCapabilityMetrics.TaskSpecificScoresEntry
	25, // 51: api.ai.v1.UserUsageStats.ModelUsageEntry.value:type_name -> api.ai.v1.ModelUsageStats
	32, // 52: api.ai.v1.SystemOverviewStats.ServiceStatsEntry.value:type_name -> api.ai.v1.ServiceStats
	4,  // 53: api.ai.v1.Ai.GetConversationAnalytics:input_type -> api.ai.v1.GetConversationAnalyticsRequest
	6,  // 54: api.ai.v1.Ai.GetUserUsageStats:input_type -> api.ai.v1.GetUserUsageStatsRequest
	8,  // 55: api.ai.v1.Ai.GetModelPerformanceStats:input_type -> api.ai.v1.GetModelPerformanceStatsRequest
	10, // 56: api.ai.v1.Ai.GetConversationTrends:input_type -> api.ai.v1.GetConversationTrendsRequest
	12, // 57: api.ai.v1.Ai.GetTopicAnalysis:input_type -> api.ai.v1.GetTopicAnalysisRequest
	14, // 58: api.ai.v1.Ai.GetSystemOverview:input_type -> api.ai.v1.GetSystemOverviewRequest
	5,  // 59: api.ai.v1.Ai.GetConversationAnalytics:output_type -> api.ai.v1.GetConversationAnalyticsReply
	7,  // 60: api.ai.v1.Ai.GetUserUsageStats:output_type -> api.ai.v1.GetUserUsageStatsReply
	9,  // 61: api.ai.v1.Ai.GetModelPerformanceStats:output_type -> api.ai.v1.GetModelPerformanceStatsReply
	11, // 62: api.ai.v1.Ai.GetConversationTrends:output_type -> api.ai.v1.GetConversationTrendsReply
	13, // 63: api.ai.v1.Ai.GetTopicAnalysis:output_type -> api.ai.v1.GetTopicAnalysisReply
	15, // 64: api.ai.v1.Ai.GetSystemOverview:output_type -> api.ai.v1.GetSystemOverviewReply
	59, // [59:65] is the sub-list for method output_type
	53, // [53:59] is the sub-list for method input_type
	53, // [53:53] is the sub-list for extension type_name
	53, // [53:53] is the sub-list for extension extendee
	0,  // [0:53] is the sub-list for field type_name
}

func init() { file_api_ai_v1_ai_proto_init() }
func file_api_ai_v1_ai_proto_init() {
	if File_api_ai_v1_ai_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_ai_v1_ai_proto_rawDesc), len(file_api_ai_v1_ai_proto_rawDesc)),
			NumEnums:      4,
			NumMessages:   41,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_api_ai_v1_ai_proto_goTypes,
		DependencyIndexes: file_api_ai_v1_ai_proto_depIdxs,
		EnumInfos:         file_api_ai_v1_ai_proto_enumTypes,
		MessageInfos:      file_api_ai_v1_ai_proto_msgTypes,
	}.Build()
	File_api_ai_v1_ai_proto = out.File
	file_api_ai_v1_ai_proto_goTypes = nil
	file_api_ai_v1_ai_proto_depIdxs = nil
}
